{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation Using RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfZAz7L+Vi8TVqTeJlWSrr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souban1234/sou12345/blob/master/Text_Generation_Using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOg9TaZC7i5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43102fe1-7788-4852-9c6a-d1ef6621e676"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROBLEM STATEMENT"
      ],
      "metadata": {
        "id": "jn1Vtb2-sGAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the data from Lord of Rings file and create a generation of new textbased on the LORmethod.The objective is topredict the next 100 words of the given sentence from the training data set.Datacan be obtained fromthe following link:\n",
        "https://raw.githubusercontent.com/wess/iotr/master/lotr.txt"
      ],
      "metadata": {
        "id": "F5KPzS3xrw9p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh40MleI-flb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import string\n",
        "import requests\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/wess/iotr/master/lotr.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eoi6LzK9rnei",
        "outputId": "e8dc3296-b49f-4cca-924c-e7a91b1425c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-15 04:06:36--  https://raw.githubusercontent.com/wess/iotr/master/lotr.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3262595 (3.1M) [text/plain]\n",
            "Saving to: ‘lotr.txt’\n",
            "\n",
            "lotr.txt            100%[===================>]   3.11M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-08-15 04:06:37 (46.6 MB/s) - ‘lotr.txt’ saved [3262595/3262595]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHieMJbsLAX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b845dc-b72f-4e0c-f684-7bd4abec7fe1"
      },
      "source": [
        "tokenizer=Tokenizer()\n",
        "data=open(\"/content/lotr.txt\").read()\n",
        "corpus=data.lower().split(\"\\n\")[:1000]\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words=len(tokenizer.word_index)+1\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'and': 2, 'a': 3, 'to': 4, 'of': 5, 'he': 6, 'in': 7, 'was': 8, 'i': 9, 'it': 10, 'they': 11, 'on': 12, 'that': 13, 'you': 14, 'said': 15, 'for': 16, 'all': 17, 'had': 18, 'his': 19, 'have': 20, 'not': 21, 'as': 22, 'at': 23, 'with': 24, 'bilbo': 25, 'there': 26, 'is': 27, 'but': 28, 'were': 29, 'this': 30, 'what': 31, 'or': 32, 'up': 33, 'we': 34, 'out': 35, 'like': 36, 'very': 37, 'him': 38, 'gandalf': 39, 'one': 40, 'about': 41, 'if': 42, 'by': 43, 'be': 44, 'so': 45, 'hobbit': 46, 'thorin': 47, 'them': 48, 'door': 49, 'their': 50, 'when': 51, 'good': 52, 'are': 53, 'little': 54, 'me': 55, 'your': 56, 'from': 57, 'no': 58, 'then': 59, 'dwarves': 60, 'went': 61, 'could': 62, 'off': 63, 'after': 64, 'my': 65, 'been': 66, 'now': 67, 'before': 68, 'long': 69, \"don't\": 70, 'baggins': 71, 'time': 72, 'got': 73, 'down': 74, 'more': 75, 'any': 76, 'would': 77, 'just': 78, 'come': 79, 'go': 80, 'do': 81, 'our': 82, 'some': 83, 'far': 84, 'round': 85, 'without': 86, 'into': 87, 'over': 88, 'will': 89, 'us': 90, 'old': 91, 'never': 92, 'know': 93, 'came': 94, 'away': 95, 'who': 96, 'things': 97, 'most': 98, 'great': 99, 'an': 100, 'only': 101, 'than': 102, 'think': 103, 'even': 104, 'too': 105, 'dark': 106, 'mountain': 107, 'hill': 108, 'can': 109, 'morning': 110, 'back': 111, 'quite': 112, 'well': 113, 'which': 114, 'took': 115, 'fire': 116, 'under': 117, 'here': 118, 'dragon': 119, 'while': 120, 'green': 121, 'going': 122, 'say': 123, 'see': 124, 'made': 125, 'light': 126, 'day': 127, 'get': 128, 'way': 129, 'should': 130, 'map': 131, 'enough': 132, 'thought': 133, 'soon': 134, 'make': 135, 'may': 136, 'did': 137, 'anything': 138, 'how': 139, 'found': 140, 'must': 141, 'still': 142, 'breakfast': 143, 'am': 144, 'find': 145, 'mr': 146, 'again': 147, 'gold': 148, 'red': 149, 'people': 150, 'many': 151, 'these': 152, 'left': 153, 'adventures': 154, 'himself': 155, 'along': 156, 'once': 157, 'father': 158, 'behind': 159, 'used': 160, 'inside': 161, 'put': 162, 'burglar': 163, 'william': 164, 'first': 165, 'ring': 166, 'last': 167, 'hole': 168, 'lots': 169, 'side': 170, 'another': 171, 'dragons': 172, 'trees': 173, 'where': 174, 'poor': 175, 'right': 176, 'mountains': 177, 'deep': 178, 'big': 179, 'feet': 180, 'something': 181, 'days': 182, 'bit': 183, 'beautiful': 184, 'man': 185, 'mean': 186, 'sat': 187, 'remember': 188, 'two': 189, 'dwarf': 190, 'began': 191, 'through': 192, 'look': 193, 'room': 194, 'bert': 195, 'those': 196, 'smoke': 197, 'looking': 198, 'river': 199, 'mind': 200, 'also': 201, 'hear': 202, 'water': 203, 'other': 204, 'course': 205, 'fact': 206, 'ever': 207, 'heard': 208, 'yes': 209, 'wizard': 210, 'hood': 211, 'balin': 212, 'supper': 213, 'much': 214, 'others': 215, 'bad': 216, 'lands': 217, 'night': 218, 'dale': 219, 'hall': 220, 'called': 221, 'same': 222, 'hand': 223, 'end': 224, 'looked': 225, 'less': 226, 'almost': 227, 'business': 228, 'hung': 229, 'want': 230, 'fellow': 231, 'already': 232, 'tea': 233, 'break': 234, 'drink': 235, 'gone': 236, 'has': 237, 'pocket': 238, 'yer': 239, 'often': 240, 'best': 241, 'large': 242, 'head': 243, 'ago': 244, 'though': 245, 'until': 246, 'own': 247, 'saw': 248, 'blue': 249, 'parts': 250, 'till': 251, 'might': 252, 'asked': 253, 'cake': 254, 'front': 255, 'dwalin': 256, 'open': 257, 'gloin': 258, 'grandfather': 259, 'cook': 260, 'mutton': 261, 'gave': 262, 'told': 263, 'king': 264, 'yet': 265, 'coming': 266, 'lived': 267, 'indeed': 268, 'name': 269, 'adventure': 270, 'saying': 271, 'suppose': 272, 'hobbits': 273, 'half': 274, 'sort': 275, 'small': 276, 'pipe': 277, 'nearly': 278, 'forgotten': 279, 'hat': 280, 'silver': 281, 'beard': 282, 'stuck': 283, 'fine': 284, 'take': 285, 'notice': 286, 'thank': 287, 'let': 288, 'liked': 289, 'give': 290, 'turned': 291, 'seen': 292, 'service': 293, 'table': 294, 'beer': 295, 'hoods': 296, 'each': 297, 'kili': 298, 'fili': 299, 'bombur': 300, 'bring': 301, 'house': 302, 'everything': 303, 'none': 304, 'wind': 305, 'suddenly': 306, 'fierce': 307, 'seemed': 308, 'bed': 309, 'trolls': 310, 'note': 311, 'friends': 312, 'set': 313, 'rings': 314, 'thrain': 315, 'son': 316, 'north': 317, 'party': 318, 'nasty': 319, 'wet': 320, 'perfectly': 321, 'whole': 322, 'because': 323, 'quietly': 324, 'especially': 325, 'across': 326, 'money': 327, 'second': 328, 'quiet': 329, 'grey': 330, 'cloak': 331, 'white': 332, 'shining': 333, 'read': 334, 'try': 335, 'lot': 336, \"haven't\": 337, 'please': 338, 'why': 339, 'outside': 340, \"hobbit's\": 341, 'bell': 342, 'rushed': 343, 'moment': 344, 'hardly': 345, 'thing': 346, 'cakes': 347, 'talking': 348, 'four': 349, 'talked': 350, 'fell': 351, 'secret': 352, 'carefully': 353, 'mat': 354, 'bifur': 355, 'bofur': 356, \"what's\": 357, 'cold': 358, 'plates': 359, 'getting': 360, 'music': 361, \"that's\": 362, 'misty': 363, 'dungeons': 364, 'caverns': 365, 'sleep': 366, 'halls': 367, 'men': 368, 'mouth': 369, 'journey': 370, 'east': 371, 'smaug': 372, 'key': 373, 'hold': 374, 'pony': 375, 'runes': 376, 'important': 377, 'true': 378, 'story': 379, 'however': 380, 'explanation': 381, 'thror': 382, 'moria': 383, 'unexpected': 384, 'dry': 385, 'sit': 386, 'means': 387, 'yellow': 388, 'opened': 389, 'tunnel': 390, 'rooms': 391, 'dining': 392, 'passage': 393, 'respectable': 394, 'doing': 395, 'altogether': 396, 'whether': 397, 'since': 398, 'magic': 399, 'except': 400, 'folk': 401, 'noise': 402, 'faces': 403, 'belladonna': 404, 'three': 405, 'built': 406, 'being': 407, 'years': 408, 'standing': 409, 'toes': 410, 'wherever': 411, 'staff': 412, 'meant': 413, 'sun': 414, 'use': 415, 'uncomfortable': 416, 'late': 417, 'begin': 418, 'move': 419, 'stood': 420, 'stick': 421, \"won't\": 422, 'dear': 423, 'themselves': 424, 'such': 425, 'goblins': 426, 'pardon': 427, 'idea': 428, 'sorry': 429, 'shut': 430, 'ask': 431, 'fright': 432, 'beginning': 433, 'remembered': 434, 'keep': 435, 'waiting': 436, 'eyes': 437, 'yours': 438, 'perhaps': 439, 'knew': 440, 'taking': 441, 'breath': 442, 'both': 443, 'really': 444, 'trying': 445, 'hands': 446, 'oin': 447, 'fat': 448, 'stopped': 449, 'feeling': 450, 'kitchen': 451, 'least': 452, 'trouble': 453, 'quick': 454, 'turning': 455, \"gandalf's\": 456, 'brought': 457, 'walking': 458, 'struck': 459, 'song': 460, 'ere': 461, 'mighty': 462, 'beneath': 463, 'moon': 464, 'wished': 465, 'jewels': 466, 'wood': 467, 'probably': 468, 'start': 469, 'sure': 470, 'wrong': 471, 'done': 472, 'usual': 473, 'usually': 474, 'tried': 475, 'ought': 476, 'deal': 477, \"can't\": 478, 'gate': 479, 'south': 480, 'killed': 481, 'worse': 482, 'nice': 483, 'inn': 484, 'ponies': 485, 'rain': 486, 'owl': 487, 'exactly': 488, \"thror's\": 489, 'matter': 490, 'chapter': 491, 'book': 492, 'part': 493, 'added': 494, 'point': 495, 'names': 496, 'show': 497, 'br': 498, 'filled': 499, 'nothing': 500, 'eat': 501, 'comfortable': 502, 'chairs': 503, 'pegs': 504, 'straight': 505, 'clothes': 506, 'floor': 507, 'beyond': 508, 'tell': 509, 'bother': 510, 'lost': 511, 'become': 512, 'beards': 513, 'quickly': 514, 'bright': 515, 'brown': 516, 'hair': 517, 'twice': 518, 'ran': 519, 'taken': 520, 'bungo': 521, \"bilbo's\": 522, 'her': 523, 'either': 524, 'queer': 525, 'chance': 526, 'apparently': 527, 'settled': 528, 'world': 529, 'enormous': 530, 'reached': 531, 'tales': 532, 'friend': 533, 'feel': 534, 'mine': 535, \"there's\": 536, 'air': 537, 'anyone': 538, 'plain': 539, 'sir': 540, \"took's\": 541, 'wandering': 542, 'luck': 543, 'evening': 544, 'believe': 545, 'elves': 546, 'life': 547, 'badly': 548, 'beg': 549, 'else': 550, 'send': 551, 'likely': 552, 'pantry': 553, 'escape': 554, 'next': 555, 'unless': 556, 'wednesday': 557, 'yesterday': 558, 'flustered': 559, 'kind': 560, 'low': 561, 'surprised': 562, 'instead': 563, 'step': 564, 'arrive': 565, 'caught': 566, 'hanging': 567, 'run': 568, 'short': 569, 'better': 570, 'seed': 571, 'fetch': 572, 'loud': 573, 'bag': 574, 'throng': 575, 'mines': 576, 'understand': 577, 'dori': 578, 'nori': 579, 'ale': 580, 'coffee': 581, 'kept': 582, 'top': 583, 'mark': 584, 'row': 585, 'pale': 586, 'mention': 587, 'thirteen': 588, 'merry': 589, 'wine': 590, 'few': 591, 'myself': 592, 'glasses': 593, 'trays': 594, 'clear': 595, 'manage': 596, 'sing': 597, 'safe': 598, 'lightning': 599, 'forgot': 600, 'window': 601, 'played': 602, 'ringing': 603, 'bells': 604, 'lay': 605, 'laid': 606, 'sang': 607, 'felt': 608, 'above': 609, 'lamp': 610, 'speak': 611, 'shall': 612, 'known': 613, 'drawing': 614, 'hundred': 615, 'crept': 616, 'excitement': 617, 'fool': 618, 'walked': 619, 'job': 620, \"let's\": 621, 'chosen': 622, 'live': 623, 'rather': 624, 'maps': 625, 'everybody': 626, 'says': 627, 'barrel': 628, 'neck': 629, 'running': 630, 'valley': 631, 'warriors': 632, 'mostly': 633, \"didn't\": 634, 'professional': 635, 'expenses': 636, 'food': 637, 'work': 638, 'always': 639, 'woods': 640, 'proper': 641, 'handing': 642, 'early': 643, 'sitting': 644, 'company': 645, 'hills': 646, 'camp': 647, 'tree': 648, \"trolls'\": 649, 'tom': 650, 'several': 651, 'rune': 652, 'five': 653, 'game': 654, 'given': 655, 'place': 656, 'edition': 657, 'lore': 658, 'need': 659, 'its': 660, 'lord': 661, 'written': 662, 'repeated': 663, 'distant': 664, 'ancestor': 665, 'discovered': 666, 'moved': 667, 'ground': 668, 'worms': 669, 'smell': 670, 'comfort': 671, 'painted': 672, 'brass': 673, 'knob': 674, 'exact': 675, 'middle': 676, 'shaped': 677, 'coats': 678, 'fond': 679, 'visitors': 680, 'miles': 681, 'doors': 682, 'cellars': 683, 'pantries': 684, 'windows': 685, 'bagginses': 686, 'neighbourhood': 687, 'rich': 688, 'question': 689, 'gained': 690, 'mother': 691, 'call': 692, 'height': 693, 'smaller': 694, 'ordinary': 695, 'elephants': 696, 'mile': 697, 'wear': 698, 'grow': 699, 'thick': 700, 'warm': 701, 'fingers': 702, 'dinner': 703, 'remarkable': 704, 'foot': 705, 'absurd': 706, 'certainly': 707, 'family': 708, 'remained': 709, 'undoubtedly': 710, 'she': 711, 'became': 712, 'arrived': 713, 'curious': 714, 'smoking': 715, 'wooden': 716, 'fashion': 717, 'ages': 718, 'died': 719, 'tall': 720, 'bushy': 721, 'eyebrows': 722, 'further': 723, 'wish': 724, 'tobacco': 725, 'fill': 726, 'hurry': 727, 'legs': 728, 'blew': 729, 'sailed': 730, 'pretty': 731, 'someone': 732, \"it's\": 733, 'difficult': 734, 'disturbing': 735, 'decided': 736, 'leaning': 737, 'fastened': 738, 'ordered': 739, 'sons': 740, 'excellent': 741, 'fireworks': 742, 'splendid': 743, 'sailing': 744, 'bless': 745, 'upon': 746, 'pleased': 747, 'seem': 748, 'kindly': 749, 'rate': 750, 'hope': 751, 'sake': 752, 'today': 753, 'tomorrow': 754, 'wizards': 755, 'fast': 756, 'laughing': 757, 'sign': 758, 'kettle': 759, 'golden': 760, 'pushed': 761, 'bow': 762, 'questions': 763, 'pray': 764, 'louder': 765, 'excuse': 766, 'hopped': 767, 'begun': 768, 'cellar': 769, 'certain': 770, 'puffed': 771, 'belts': 772, 'carried': 773, 'tools': 774, 'swept': 775, 'join': 776, 'sound': 777, 'collect': 778, 'wits': 779, 'corner': 780, 'sounded': 781, 'adventurous': 782, \"'\": 783, 'rang': 784, 'boy': 785, 'pull': 786, 'handle': 787, 'blinking': 788, 'wondered': 789, 'happened': 790, 'stay': 791, 'wondering': 792, 'ori': 793, 'busy': 794, 'jug': 795, 'hearth': 796, 'starting': 797, 'somebody': 798, 'knocked': 799, 'pop': 800, 'sky': 801, 'flat': 802, 'immensely': 803, 'heavy': 804, 'pie': 805, 'eggs': 806, 'seems': 807, 'flummoxed': 808, 'wonder': 809, 'wretched': 810, 'bottles': 811, 'knives': 812, 'forks': 813, 'piled': 814, 'annoyed': 815, 'aloud': 816, 'lend': 817, 'parlour': 818, 'stool': 819, 'ate': 820, 'jumped': 821, 'piles': 822, 'careful': 823, 'blunt': 824, 'hates': 825, 'cut': 826, 'cloth': 827, 'pour': 828, 'bedroom': 829, 'every': 830, 'crocks': 831, 'thumping': 832, \"you've\": 833, 'finished': 834, 'fender': 835, 'clock': 836, 'sent': 837, \"thorin's\": 838, 'dim': 839, 'strange': 840, 'loved': 841, 'bags': 842, 'somewhere': 843, 'among': 844, 'harp': 845, 'april': 846, 'shadow': 847, 'shadows': 848, 'singing': 849, 'places': 850, 'ancient': 851, 'hide': 852, 'sword': 853, 'stars': 854, 'harps': 855, 'winds': 856, 'spread': 857, 'torches': 858, 'fall': 859, 'grim': 860, 'love': 861, 'woke': 862, 'pine': 863, 'caves': 864, 'flame': 865, 'pretend': 866, 'hours': 867, 'knocking': 868, 'together': 869, 'conspirator': 870, 'audacious': 871, 'remark': 872, 'plans': 873, 'ways': 874, 'return': 875, 'interrupted': 876, \"couldn't\": 877, 'longer': 878, 'shriek': 879, 'whistle': 880, 'shaking': 881, 'calling': 882, 'elbow': 883, 'funny': 884, 'pinch': 885, 'granduncle': 886, 'bullroarer': 887, 'horse': 888, 'battle': 889, 'rabbit': 890, 'won': 891, 'talk': 892, 'wake': 893, 'bobbing': 894, 'doubts': 895, 'afterwards': 896, 'signs': 897, 'walk': 898, 'fight': 899, 'wild': 900, '—': 901, 'plenty': 902, 'reward': 903, 'expert': 904, 'treasure': 905, 'arranged': 906, 'fourteenth': 907, 'chose': 908, 'stop': 909, 'comes': 910, 'guess': 911, 'piece': 912, \"dwarves'\": 913, 'excited': 914, 'help': 915, 'marked': 916, 'hidden': 917, 'size': 918, 'squeaked': 919, 'country': 920, \"isn't\": 921, 'handed': 922, 'chain': 923, 'lake': 924, 'town': 925, 'changed': 926, 'fighting': 927, 'scarce': 928, 'simply': 929, 'legendary': 930, 'putting': 931, 'alive': 932, 'wealth': 933, 'anyway': 934, 'grew': 935, \"grandfather's\": 936, 'full': 937, 'armour': 938, 'market': 939, 'flying': 940, 'specially': 941, 'wicked': 942, 'creaking': 943, 'escaped': 944, 'fog': 945, 'carry': 946, 'home': 947, 'paper': 948, 'explain': 949, 'near': 950, 'necromancer': 951, 'whatever': 952, 'towards': 953, \"'em\": 954, 'spare': 955, 'tired': 956, 'wearing': 957, 'dreams': 958, 'unwashed': 959, 'washing': 960, 'thinking': 961, 'washed': 962, 'having': 963, 'past': 964, 'ten': 965, 'message': 966, 'dusted': 967, 'fourteen': 968, 'bywater': 969, 'leaves': 970, 'but—': 971, 'furry': 972, 'handkerchief': 973, 'road': 974, 'village': 975, \"i'm\": 976, 'precise': 977, 'handkerchiefs': 978, 'jogging': 979, 'weather': 980, 'songs': 981, 'meals': 982, 'passed': 983, 'roads': 984, 'lone': 985, 'ahead': 986, 'higher': 987, 'turn': 988, 'burgling': 989, 'clouds': 990, 'between': 991, 'shook': 992, 'drip': 993, 'mischief': 994, 'seldom': 995, 'hoot': 996, 'pride': 997, 'toasting': 998, 'spite': 999, 'blimey': 1000, 'et': 1001, \"d'yer\": 1002, 'picked': 1003, 'pockets': 1004, 'picking': 1005, \"william's\": 1006, 'new': 1007, \"i've\": 1008, 'burrahobbit': 1009, 'blighter': 1010, \"you're\": 1011, 'special': 1012, 'reprint': 1013, 'minor': 1014, 'inaccuracies': 1015, 'noted': 1016, 'readers': 1017, 'corrected': 1018, 'example': 1019, 'text': 1020, 'corresponds': 1021, 'ending': 1022, 'riddle': 1023, 'eventually': 1024, 'revealed': 1025, 'pressure': 1026, 'according': 1027, 'version': 1028, 'actually': 1029, 'diary': 1030, 'departure': 1031, 'truth': 1032, 'honest': 1033, 'portent': 1034, 'significance': 1035, 'does': 1036, 'concern': 1037, 'present': 1038, 'acquaintance': 1039, 'troupe': 1040, 'lies': 1041, 'history': 1042, 'chronicles': 1043, 'westmarch': 1044, 'final': 1045, 'raised': 1046, 'students': 1047, 'period': 1048, 'error': 1049, 'dynasties': 1050, 'genealogies': 1051, 'referred': 1052, 'fugitive': 1053, 'lonely': 1054, 'erebor': 1055, 'ruled': 1056, 'remoter': 1057, 'dirty': 1058, 'ends': 1059, 'oozy': 1060, 'nor': 1061, 'bare': 1062, 'sandy': 1063, 'porthole': 1064, 'shiny': 1065, 'tube': 1066, 'panelled': 1067, 'walls': 1068, 'floors': 1069, 'tiled': 1070, 'carpeted': 1071, 'provided': 1072, 'polished': 1073, 'hats': 1074, 'wound': 1075, 'fairly': 1076, 'upstairs': 1077, 'bedrooms': 1078, 'bathrooms': 1079, 'wardrobes': 1080, 'devoted': 1081, 'kitchens': 1082, 'ones': 1083, 'garden': 1084, 'meadows': 1085, 'sloping': 1086, 'considered': 1087, 'asking': 1088, \"neighbours'\": 1089, 'respect': 1090, 'particular': 1091, '…': 1092, 'description': 1093, 'nowadays': 1094, 'rare': 1095, 'shy': 1096, 'bearded': 1097, 'everyday': 1098, 'helps': 1099, 'disappear': 1100, 'stupid': 1101, 'blundering': 1102, 'making': 1103, 'inclined': 1104, 'stomach': 1105, 'dress': 1106, 'colours': 1107, 'chiefly': 1108, 'shoes': 1109, 'natural': 1110, 'leathery': 1111, 'soles': 1112, 'stuff': 1113, 'heads': 1114, 'curly': 1115, 'clever': 1116, 'natured': 1117, 'laugh': 1118, 'fruity': 1119, 'laughs': 1120, 'fabulous': 1121, 'daughters': 1122, 'families': 1123, 'ancestors': 1124, 'fairy': 1125, 'wife': 1126, 'entirely': 1127, 'members': 1128, 'clan': 1129, 'discreetly': 1130, 'disappeared': 1131, 'hushed': 1132, 'tooks': 1133, 'richer': 1134, 'mrs': 1135, 'luxurious': 1136, 'partly': 1137, 'probable': 1138, 'although': 1139, 'behaved': 1140, 'solid': 1141, 'makeup': 1142, 'waited': 1143, 'grown': 1144, 'fifty': 1145, 'living': 1146, 'described': 1147, 'immovably': 1148, 'numerous': 1149, 'prosperous': 1150, 'woolly': 1151, 'neatly': 1152, 'brushed': 1153, 'quarter': 1154, 'prepared': 1155, 'tale': 1156, 'sprouted': 1157, 'extraordinary': 1158, 'boys': 1159, 'girls': 1160, 'unsuspecting': 1161, 'pointed': 1162, 'scarf': 1163, 'below': 1164, 'waist': 1165, 'immense': 1166, 'black': 1167, 'boots': 1168, 'grass': 1169, 'brim': 1170, 'shady': 1171, 'bargain': 1172, 'seat': 1173, 'crossed': 1174, 'breaking': 1175, 'floated': 1176, 'blow': 1177, 'share': 1178, 'arranging': 1179, '«i': 1180, 'can’t': 1181, 'anybody': 1182, 'sees': 1183, '»': 1184, 'thumb': 1185, 'braces': 1186, 'bigger': 1187, 'letters': 1188, 'pretending': 1189, 'wanted': 1190, 'gazing': 1191, 'cross': 1192, 'conversation': 1193, 'rid': 1194, 'belong': 1195, 'morninged': 1196, 'selling': 1197, 'buttons': 1198, 'gracious': 1199, 'pair': 1200, 'diamond': 1201, 'studs': 1202, 'undone': 1203, 'wonderful': 1204, 'parties': 1205, 'giants': 1206, 'rescue': 1207, 'princesses': 1208, \"widows'\": 1209, 'particularly': 1210, \"midsummer's\": 1211, 'eve': 1212, 'lilies': 1213, 'snapdragons': 1214, 'laburnums': 1215, 'hang': 1216, 'twilight': 1217, 'prosy': 1218, 'flowers': 1219, 'responsible': 1220, 'lads': 1221, 'lasses': 1222, 'mad': 1223, 'climbing': 1224, 'visiting': 1225, 'ships': 1226, 'shores': 1227, 'inter': 1228, 'upset': 1229, 'land': 1230, 'grand': 1231, 'amusing': 1232, 'profitable': 1233, 'bye': 1234, 'scuttled': 1235, 'dared': 1236, 'rude': 1237, 'earth': 1238, 'self': 1239, 'meantime': 1240, 'stepped': 1241, 'spike': 1242, 'scratched': 1243, 'strode': 1244, 'finishing': 1245, 'engagement': 1246, 'tablet': 1247, '’¥a': 1248, 'tremendous': 1249, 'cup': 1250, 'saucer': 1251, 'extra': 1252, 'tucked': 1253, 'belt': 1254, 'expected': 1255, 'hooded': 1256, 'nearest': 1257, 'peg': 1258, 'silence': 1259, 'followed': 1260, 'stiff': 1261, 'uninvited': 1262, 'word': 1263, 'third': 1264, 'scarlet': 1265, 'invited': 1266, 'sight': 1267, \"dwalin's\": 1268, 'breast': 1269, 'gasp': 1270, 'correct': 1271, 'preferred': 1272, 'horrible': 1273, 'host': 1274, 'duty': 1275, 'painful': 1276, 'managed': 1277, 'suit': 1278, 'answering': 1279, 'surprise': 1280, 'scuttling': 1281, 'pint': 1282, 'mug': 1283, 'baked': 1284, 'afternoon': 1285, 'morsel': 1286, 'brothers': 1287, 'plumped': 1288, 'spade': 1289, 'bowed': 1290, \"family's\": 1291, 'replied': 1292, 'remembering': 1293, 'manners': 1294, 'minute': 1295, 'sip': 1296, 'around': 1297, 'troubles': 1298, 'depredations': 1299, 'ding': 1300, 'dong': 1301, 'ling': 1302, 'dang': 1303, 'naughty': 1304, 'sides': 1305, 'distance': 1306, 'happen': 1307, 't': 1308, 'x': 1309, 're': 1310, 'bowing': 1311, 'purple': 1312, 'marched': 1313, 'broad': 1314, 'porter': 1315, 'buttered': 1316, 'scones': 1317, 'knock': 1318, 'hard': 1319, 'rat': 1320, 'tat': 1321, 'banging': 1322, 'angry': 1323, 'bewildered': 1324, 'bewuthered': 1325, 'awkward': 1326, 'pulled': 1327, 'jerk': 1328, 'dent': 1329, 'gun': 1330, 'introduce': 1331, 'tassel': 1332, 'belonged': 1333, 'enormously': 1334, 'oakenshield': 1335, 'falling': 1336, 'haughty': 1337, 'times': 1338, 'grunted': 1339, 'frowning': 1340, 'detachable': 1341, 'gathering': 1342, 'comers': 1343, 'raspberry': 1344, 'jam': 1345, 'apple': 1346, 'tart': 1347, 'mince': 1348, 'pies': 1349, 'cheese': 1350, 'pork': 1351, 'salad': 1352, 'stumped': 1353, 'chicken': 1354, 'pickles': 1355, 'larders': 1356, 'positively': 1357, 'dishes': 1358, 'spoons': 1359, 'hot': 1360, 'face': 1361, 'confusticate': 1362, 'bebother': 1363, 'lo': 1364, 'behold': 1365, 'knife': 1366, 'whisked': 1367, 'couple': 1368, 'tables': 1369, 'afresh': 1370, 'fireside': 1371, 'nibbling': 1372, 'biscuit': 1373, 'appetite': 1374, 'politest': 1375, 'unpressing': 1376, 'tones': 1377, \"shan't\": 1378, 'thereupon': 1379, 'twelve': 1380, 'stayed': 1381, 'balancing': 1382, 'columns': 1383, 'bottle': 1384, 'squeaking': 1385, 'started': 1386, 'chip': 1387, 'crack': 1388, 'bend': 1389, 'smash': 1390, 'burn': 1391, 'corks': 1392, 'tread': 1393, 'milk': 1394, 'leave': 1395, 'bones': 1396, 'splash': 1397, 'dump': 1398, 'boiling': 1399, 'bawl': 1400, 'pound': 1401, 'pole': 1402, 'roll': 1403, 'dreadful': 1404, 'cleaned': 1405, 'blowing': 1406, 'chimney': 1407, 'telpiece': 1408, 'ceiling': 1409, 'clay': 1410, 'hover': 1411, \"wizard's\": 1412, 'cloud': 1413, 'sorcerous': 1414, 'watched': 1415, 'blushed': 1416, 'proud': 1417, 'instruments': 1418, 'fiddles': 1419, 'flutes': 1420, 'produced': 1421, 'drum': 1422, 'clarinets': 1423, 'sticks': 1424, 'porch': 1425, 'viols': 1426, 'thorin’s': 1427, 'wrapped': 1428, 'en': 1429, 'sudden': 1430, 'sweet': 1431, 'moons': 1432, 'firelight': 1433, 'flickered': 1434, 'wagged': 1435, 'against': 1436, 'wall': 1437, 'throated': 1438, 'homes': 1439, 'fragment': 1440, 'seek': 1441, 'enchanted': 1442, 'yore': 1443, 'spells': 1444, 'hammers': 1445, 'hollow': 1446, 'fells': 1447, 'elvish': 1448, 'gloaming': 1449, 'hoard': 1450, 'wrought': 1451, 'gems': 1452, 'hilt': 1453, 'necklaces': 1454, 'strung': 1455, 'flowering': 1456, 'crowns': 1457, 'twisted': 1458, 'wire': 1459, 'meshed': 1460, 'claim': 1461, 'goblets': 1462, 'carved': 1463, 'delves': 1464, 'sung': 1465, 'unheard': 1466, 'pines': 1467, 'roaring': 1468, 'moaning': 1469, 'flaming': 1470, 'biased': 1471, \"dragon's\": 1472, 'ire': 1473, 'towers': 1474, 'houses': 1475, 'frail': 1476, 'smoked': 1477, 'tramp': 1478, 'doom': 1479, 'fled': 1480, 'dying': 1481, 'win': 1482, 'cunning': 1483, 'moving': 1484, 'jealous': 1485, 'desire': 1486, 'hearts': 1487, 'tookish': 1488, 'waterfalls': 1489, 'explore': 1490, 'leapt': 1491, 'lighting': 1492, 'plundering': 1493, 'settling': 1494, 'kindling': 1495, 'flames': 1496, 'shuddered': 1497, 'trembling': 1498, 'barrels': 1499, 'tone': 1500, 'guessed': 1501, 'halves': 1502, 'apologetically': 1503, 'dawn': 1504, 'missed': 1505, 'poker': 1506, 'shovel': 1507, 'crash': 1508, 'hush': 1509, 'praise': 1510, 'paused': 1511, 'polite': 1512, 'hob': 1513, 'compliments': 1514, 'wagging': 1515, 'protest': 1516, 'worst': 1517, 'met': 1518, 'discuss': 1519, 'policy': 1520, 'devices': 1521, 'counsellor': 1522, 'ingenious': 1523, 'solemn': 1524, 'object': 1525, 'estimable': 1526, 'younger': 1527, 'naming': 1528, 'instance': 1529, 'situation': 1530, 'require': 1531, 'brief': 1532, 'style': 1533, 'allowed': 1534, 'telling': 1535, \"'anything\": 1536, 'rudely': 1537, 'bear': 1538, 'burst': 1539, 'engine': 1540, 'sprang': 1541, 'bp': 1542, 'firework': 1543, 'glare': 1544, 'kneeling': 1545, 'rug': 1546, 'jelly': 1547, 'melting': 1548, 'sofa': 1549, 'excitable': 1550, 'gets': 1551, 'fits': 1552, 'realize': 1553, 'poetical': 1554, 'exaggeration': 1555, 'applied': 1556, 'huge': 1557, 'ride': 1558, 'charged': 1559, 'ranks': 1560, 'mount': 1561, 'gram': 1562, 'fields': 1563, 'gol': 1564, \"firnbul's\": 1565, 'clean': 1566, 'club': 1567, 'yards': 1568, 'golf': 1569, 'invented': 1570, 'meanwhile': 1571, \"bullroarer's\": 1572, 'gentler': 1573, 'descendant': 1574, 'reviving': 1575, 'nervously': 1576, 'speaking': 1577, 'humph': 1578, 'snort': 1579, 'relatives': 1580, 'kill': 1581, 'clapped': 1582, 'puffing': 1583, 'looks': 1584, 'grocer': 1585, 'regretted': 1586, 'overheard': 1587, 'words': 1588, 'reference': 1589, 'burglars': 1590, 'believing': 1591, 'dignity': 1592, 'week': 1593, 'treat': 1594, 'desert': 1595, 'assure': 1596, 'trade': 1597, 'wants': 1598, 'reasonable': 1599, 'hunter': 1600, 'meeting': 1601, 'reasons': 1602, 'expedition': 1603, 'digging': 1604, 'coal': 1605, 'scowled': 1606, 'angrily': 1607, 'huddled': 1608, 'chair': 1609, 'frowned': 1610, 'oat': 1611, 'tight': 1612, 'snap': 1613, 'argument': 1614, '6te': 1615, 'possibly': 1616, 'shad': 1617, 'parchment': 1618, 'answer': 1619, 'plan': 1620, 'disappointedly': 1621, 'glance': 1622, 'mirkwood': 1623, 'withered': 1624, 'heath': 1625, 'bred': 1626, 'easy': 1627, 'noticed': 1628, 'entrance': 1629, 'west': 1630, 'pointing': 1631, 'marks': 1632, 'lower': 1633, \"'five\": 1634, 'high': 1635, \"abreast'\": 1636, 'creep': 1637, 'young': 1638, 'devouring': 1639, 'experience': 1640, 'holes': 1641, 'interested': 1642, 'favourite': 1643, 'walks': 1644, 'ink': 1645, 'apart': 1646, 'closed': 1647, 'method': 1648, 'intricate': 1649, 'wards': 1650, 'jacket': 1651, 'hopeful': 1652, 'news': 1653, 'alters': 1654, 'loads': 1655, 'ruins': 1656, 'runs': 1657, 'cliff': 1658, 'warrior': 1659, 'hero': 1660, 'heroes': 1661, 'swords': 1662, 'axes': 1663, 'shields': 1664, 'cradles': 1665, 'dish': 1666, 'covers': 1667, 'comfortably': 1668, 'therefore': 1669, 'burglary': 1670, 'existence': 1671, 'selected': 1672, 'supposing': 1673, 'gives': 1674, 'ideas': 1675, 'suggestions': 1676, 'mock': 1677, 'politeness': 1678, 'confused': 1679, 'shaky': 1680, 'lookishly': 1681, 'determined': 1682, 'belongs': 1683, 'obstinately': 1684, 'manner': 1685, 'reserved': 1686, 'borrow': 1687, 'appear': 1688, 'wise': 1689, 'prudent': 1690, 'recommendation': 1691, 'risks': 1692, 'required': 1693, 'remuneration': 1694, 'forth': 1695, 'o': 1696, 'driven': 1697, 'mined': 1698, 'tunnelled': 1699, 'huger': 1700, 'greater': 1701, 'workshops': 1702, 'addition': 1703, 'famous': 1704, 'treated': 1705, 'reverence': 1706, 'mortal': 1707, 'gradually': 1708, 'spreading': 1709, 'overshadowed': 1710, 'kings': 1711, 'smiths': 1712, 'skilful': 1713, 'richly': 1714, 'fathers': 1715, 'apprentices': 1716, 'pay': 1717, 'handsomely': 1718, 'supplies': 1719, 'bothered': 1720, 'ourselves': 1721, 'poorest': 1722, 'spend': 1723, 'leisure': 1724, 'fun': 1725, 'marvellous': 1726, 'magical': 1727, 'toys': 1728, 'carvings': 1729, 'cups': 1730, 'toy': 1731, 'steal': 1732, 'guard': 1733, 'plunder': 1734, 'practically': 1735, 'forever': 1736, 'enjoy': 1737, 'notion': 1738, 'current': 1739, 'value': 1740, 'mend': 1741, 'loose': 1742, 'scale': 1743, 'general': 1744, 'waste': 1745, 'destruction': 1746, 'greedy': 1747, 'strong': 1748, 'worm': 1749, 'flew': 1750, 'hurricane': 1751, 'cracking': 1752, 'luckily': 1753, 'lad': 1754, 'saved': 1755, 'settle': 1756, 'spout': 1757, 'slopes': 1758, 'arming': 1759, 'steam': 1760, 'destroyed': 1761, 'unhappy': 1762, 'common': 1763, 'routed': 1764, 'lanes': 1765, 'tunnels': 1766, 'alleys': 1767, 'mansions': 1768, 'passages': 1769, \"dragons'\": 1770, 'heap': 1771, 'sleeps': 1772, 'later': 1773, 'crawl': 1774, 'maidens': 1775, 'ruined': 1776, 'dead': 1777, 'goes': 1778, 'lives': 1779, 'nearer': 1780, 'edge': 1781, 'wept': 1782, 'hiding': 1783, 'cursed': 1784, 'unexpectedly': 1785, 'joined': 1786, 'singed': 1787, 'tongue': 1788, 'earn': 1789, 'livings': 1790, 'sinking': 1791, 'blacksmith': 1792, 'coalmining': 1793, 'stolen': 1794, 'allow': 1795, 'stroked': 1796, 'curses': 1797, \"father's\": 1798, 'private': 1799, 'rightful': 1800, 'heir': 1801, \"'get\": 1802, 'azog': 1803, 'goblin': 1804, 'curse': 1805, 'twenty': 1806, 'thursday': 1807, 'since—': 1808, 'blame': 1809, 'considering': 1810, 'praised': 1811, 'thanked': 1812, 'slowly': 1813, 'grimly': 1814, 'safety': 1815, 'unpleasant': 1816, 'prisoner': 1817, 'shudder': 1818, 'shivered': 1819, 'finding': 1820, 'dangerous': 1821, 'save': 1822, 'witless': 1823, 'paid': 1824, 'enemy': 1825, 'powers': 1826, 'collected': 1827, 'corners': 1828, 'tasks': 1829, 'accidentally': 1830, 'answered': 1831, 'sometimes': 1832, 'doorstep': 1833, 'daresay': 1834, \"aren't\": 1835, 'agree': 1836, 'ham': 1837, 'fried': 1838, 'poached': 1839, 'breakfasts': 1840, 'beds': 1841, 'sofas': 1842, 'stowed': 1843, 'happy': 1844, \"else's\": 1845, 'tookishness': 1846, 'humming': 1847, 'ears': 1848, '2': 1849, 'roast': 1850, 'dressing': 1851, 'gown': 1852, 'nobody': 1853, 'hurried': 1854, 'fearful': 1855, 'mess': 1856, 'pot': 1857, 'pan': 1858, 'possessed': 1859, 'dismally': 1860, 'real': 1861, 'forced': 1862, 'hoped': 1863, 'relieved': 1864, 'bothering': 1865, 'trifle': 1866, 'disappointed': 1867, 'outlandish': 1868, 'nonsense': 1869, 'age': 1870, 'apron': 1871, 'lit': 1872, 'fires': 1873, 'boiled': 1874, 'letting': 1875, 'spring': 1876, 'breeze': 1877, 'loudly': 1878, 'forget': 1879, 'whenever': 1880, 'wait': 1881, 'fluster': 1882, 'yourself': 1883, 'mantel': 1884, 'mantelpiece': 1885, 'greeting': 1886, 'hospitality': 1887, 'sincerest': 1888, 'thanks': 1889, 'offer': 1890, 'assistance': 1891, 'grateful': 1892, 'acceptance': 1893, 'terms': 1894, 'cash': 1895, 'delivery': 1896, 'exceeding': 1897, 'total': 1898, 'profits': 1899, 'traveling': 1900, 'guaranteed': 1901, 'event': 1902, 'funeral': 1903, 'defrayed': 1904, 'representatives': 1905, 'occasion': 1906, 'arises': 1907, 'otherwise': 1908, 'unnecessary': 1909, 'disturb': 1910, 'esteemed': 1911, 'repose': 1912, 'proceeded': 1913, 'advance': 1914, 'requisite': 1915, 'preparations': 1916, 'await': 1917, 'respected': 1918, 'person': 1919, 'ii': 1920, 'm': 1921, 'sharp': 1922, 'trusting': 1923, 'punctual': 1924, 'honour': 1925, 'remain': 1926, 'deeply': 1927, 'co': 1928, 'minutes': 1929, 'leaving': 1930, 'pushing': 1931, 'keys': 1932, 'lane': 1933, 'mill': 1934, 'stroke': 1935, 'eleven': 1936, 'bravo': 1937, 'slung': 1938, 'kinds': 1939, 'baggages': 1940, 'packages': 1941, 'parcels': 1942, 'paraphernalia': 1943, 'awfully': 1944, '10': 1945, '45': 1946, 'worry': 1947, \"journey's\": 1948, 'luggage': 1949, 'laden': 1950, 'stained': 1951, 'borrowed': 1952, 'comic': 1953, \"daren't\": 1954, 'mistaken': 1955, 'riding': 1956, 'merrily': 1957, 'stories': 1958, 'rode': 1959, 'forward': 1960, 'inhabited': 1961, 'decent': 1962, 'farmer': 1963, 'ambling': 1964, 'spoke': 1965, 'strangely': 1966, 'inns': 1967, 'steadily': 1968, 'dreary': 1969, 'rising': 1970, 'castles': 1971, 'evil': 1972, 'gloomy': 1973, 'june': 1974, 'grumbled': 1975, 'splashed': 1976, 'muddy': 1977, 'track': 1978, 'pouring': 1979, 'dripping': 1980, 'stumbled': 1981, 'stones': 1982, 'grumpy': 1983, 'jogged': 1984, 'willows': 1985, 'bank': 1986, 'bent': 1987, 'sighed': 1988, 'rushing': 1989, 'swollen': 1990, 'rains': 1991, 'broke': 1992, 'waning': 1993, 'appeared': 1994, 'rags': 1995, 'muttered': 1996, 'patch': 1997, 'missing': 1998, 'merely': 1999, 'keeping': 2000, 'eaten': 2001, 'laughed': 2002, 'useful': 2003, 'groaned': 2004, 'shared': 2005, 'views': 2006, 'regular': 2007, 'camped': 2008, 'regularly': 2009, 'clump': 2010, 'drier': 2011, 'annoying': 2012, 'anywhere': 2013, 'bolted': 2014, 'catch': 2015, 'drowned': 2016, 'baggage': 2017, 'glum': 2018, 'muttering': 2019, 'quarrelling': 2020, 'sadly': 2021, 'reflecting': 2022, 'rides': 2023, 'sunshine': 2024, 'mass': 2025, 'reddish': 2026, 'twinkling': 2027, 'arguing': 2028, 'travellers': 2029, 'unguarded': 2030, 'inquisitive': 2031, 'leading': 2032, 'due': 2033, 'caution': 2034, 'direction': 2035, 'path': 2036, 'lead': 2037, 'farm': 2038, 'rustling': 2039, 'crackling': 2040, 'grumbling': 2041, 'drafting': 2042, 'pitch': 2043, 'shone': 2044, 'trunks': 2045, \"burglar's\": 2046, 'meaning': 2047, 'canny': 2048, 'scuttle': 2049, 'barn': 2050, 'screech': 2051, 'fly': 2052, 'bat': 2053, 'absolutely': 2054, 'sniffed': 2055, 'dwarvish': 2056, 'racket': 2057, 'sup': 2058, 'pose': 2059, 'windy': 2060, 'cavalcade': 2061, 'primly': 2062, 'weasel': 2063, 'stirred': 2064, 'whisker': 2065, 'naturally': 2066, 'persons': 2067, 'beech': 2068, 'logs': 2069, 'spits': 2070, 'licking': 2071, 'gravy': 2072, 'toothsome': 2073, 'drinking': 2074, 'jugs': 2075, 'obviously': 2076, 'sheltered': 2077, 'shape': 2078, 'language': 2079, 'tomorrer': 2080, 'manflesh': 2081, \"'ell\": 2082, \"thinkin'\": 2083, 'beats': 2084, \"runnin'\": 2085, 'choked': 2086, 'expect': 2087, \"time's\": 2088, \"yer'd\": 2089, \"'thank\": 2090, \"bill'\": 2091, \"o'\": 2092, 'bite': 2093, \"sheep's\": 2094, 'leg': 2095, 'wiped': 2096, 'lips': 2097, 'sleeve': 2098, 'afraid': 2099, 'behave': 2100, 'hearing': 2101, 'warned': 2102, 'fair': 2103, 'sized': 2104, 'mood': 2105, 'toasted': 2106, 'change': 2107, 'class': 2108, 'worthwhile': 2109, 'pinched': 2110, 'purloined': 2111, 'noticing': 2112, 'practical': 2113, 'dagger': 2114, 'observed': 2115, 'spent': 2116, 'cheerily': 2117, 'alarmed': 2118, 'disgusted': 2119, 'somehow': 2120, 'empty': 2121, 'hesitated': 2122, 'various': 2123, 'burglarious': 2124, 'proceedings': 2125, 'plucked': 2126, 'courage': 2127, 'purse': 2128, 'ha': 2129, 'warming': 2130, 'lifted': 2131, 'purses': 2132, 'exception': 2133, \"'ere\": 2134, \"'oo\": 2135, 'grabbed': 2136, 'duck': 2137, 'copped': 2138, 'lumme': 2139, 'knows': 2140, 'bur—': 2141, 'noises': 2142, 'throttled': 2143, 'startled': 2144, 'slow': 2145, 'uptake': 2146, 'suspicious': 2147, 'anyways': 2148, 'skewer': 2149, \"wouldn't\": 2150, 'mouthful': 2151, 'skinned': 2152, 'boned': 2153, \"p'raps\": 2154, \"sneakin'\": 2155, 'nassty': 2156, 'immediately': 2157, 'holding': 2158, 'gasping': 2159, 'sirs': 2160, 'bet': 2161, 'ter': 2162, \"i'll\": 2163, 'beautifully': 2164, 'throat': 2165, 'talks': 2166, 'afore': 2167, 'lout': 2168, 'bill': 2169, 'huggins': 2170, 'puts': 2171, 'fist': 2172, 'eye': 2173, 'gorgeous': 2174, 'dropped': 2175, 'scramble': 2176, 'dogs': 2177, 'sorts': 2178, 'applicable': 2179, 'voices': 2180, 'locked': 2181, \"another's\": 2182, 'arms': 2183, 'rolling': 2184, 'kicking': 2185, 'whacked': 2186, 'branch': 2187, 'senses': 2188, 'madder': 2189, 'squashed': 2190, \"bert's\": 2191, 'paw': 2192, 'body': 2193}\n",
            "2194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWVCQ7P8D_TW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b5f698-f2f6-4577-a296-aaa4081a6c3c"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame([tokenizer.word_index])\n",
        "words=df.columns\n",
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['the', 'and', 'a', 'to', 'of', 'he', 'in', 'was', 'i', 'it',\n",
              "       ...\n",
              "       'rolling', 'kicking', 'whacked', 'branch', 'senses', 'madder',\n",
              "       'squashed', 'bert's', 'paw', 'body'],\n",
              "      dtype='object', length=2193)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIte-K73qjEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303e8476-4b4b-48e4-8e67-766342b7617f"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(words))\n",
        "print ('{} unique characters'.format(len(vocab)))\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2193 unique characters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'\",\n",
              " \"'anything\",\n",
              " \"'ell\",\n",
              " \"'em\",\n",
              " \"'ere\",\n",
              " \"'five\",\n",
              " \"'get\",\n",
              " \"'oo\",\n",
              " \"'thank\",\n",
              " '10',\n",
              " '2',\n",
              " '45',\n",
              " '6te',\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " \"abreast'\",\n",
              " 'absolutely',\n",
              " 'absurd',\n",
              " 'acceptance',\n",
              " 'accidentally',\n",
              " 'according',\n",
              " 'acquaintance',\n",
              " 'across',\n",
              " 'actually',\n",
              " 'added',\n",
              " 'addition',\n",
              " 'advance',\n",
              " 'adventure',\n",
              " 'adventures',\n",
              " 'adventurous',\n",
              " 'afore',\n",
              " 'afraid',\n",
              " 'afresh',\n",
              " 'after',\n",
              " 'afternoon',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'age',\n",
              " 'ages',\n",
              " 'ago',\n",
              " 'agree',\n",
              " 'ahead',\n",
              " 'air',\n",
              " 'alarmed',\n",
              " 'ale',\n",
              " 'alive',\n",
              " 'all',\n",
              " 'alleys',\n",
              " 'allow',\n",
              " 'allowed',\n",
              " 'almost',\n",
              " 'along',\n",
              " 'aloud',\n",
              " 'already',\n",
              " 'also',\n",
              " 'alters',\n",
              " 'although',\n",
              " 'altogether',\n",
              " 'always',\n",
              " 'am',\n",
              " 'ambling',\n",
              " 'among',\n",
              " 'amusing',\n",
              " 'an',\n",
              " 'ancestor',\n",
              " 'ancestors',\n",
              " 'ancient',\n",
              " 'and',\n",
              " 'angrily',\n",
              " 'angry',\n",
              " 'annoyed',\n",
              " 'annoying',\n",
              " 'another',\n",
              " \"another's\",\n",
              " 'answer',\n",
              " 'answered',\n",
              " 'answering',\n",
              " 'any',\n",
              " 'anybody',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyway',\n",
              " 'anyways',\n",
              " 'anywhere',\n",
              " 'apart',\n",
              " 'apologetically',\n",
              " 'apparently',\n",
              " 'appear',\n",
              " 'appeared',\n",
              " 'appetite',\n",
              " 'apple',\n",
              " 'applicable',\n",
              " 'applied',\n",
              " 'apprentices',\n",
              " 'april',\n",
              " 'apron',\n",
              " 'are',\n",
              " \"aren't\",\n",
              " 'arguing',\n",
              " 'argument',\n",
              " 'arises',\n",
              " 'arming',\n",
              " 'armour',\n",
              " 'arms',\n",
              " 'around',\n",
              " 'arranged',\n",
              " 'arranging',\n",
              " 'arrive',\n",
              " 'arrived',\n",
              " 'as',\n",
              " 'ask',\n",
              " 'asked',\n",
              " 'asking',\n",
              " 'assistance',\n",
              " 'assure',\n",
              " 'at',\n",
              " 'ate',\n",
              " 'audacious',\n",
              " 'await',\n",
              " 'away',\n",
              " 'awfully',\n",
              " 'awkward',\n",
              " 'axes',\n",
              " 'azog',\n",
              " 'back',\n",
              " 'bad',\n",
              " 'badly',\n",
              " 'bag',\n",
              " 'baggage',\n",
              " 'baggages',\n",
              " 'baggins',\n",
              " 'bagginses',\n",
              " 'bags',\n",
              " 'baked',\n",
              " 'balancing',\n",
              " 'balin',\n",
              " 'banging',\n",
              " 'bank',\n",
              " 'bare',\n",
              " 'bargain',\n",
              " 'barn',\n",
              " 'barrel',\n",
              " 'barrels',\n",
              " 'bat',\n",
              " 'bathrooms',\n",
              " 'battle',\n",
              " 'bawl',\n",
              " 'be',\n",
              " 'bear',\n",
              " 'beard',\n",
              " 'bearded',\n",
              " 'beards',\n",
              " 'beats',\n",
              " 'beautiful',\n",
              " 'beautifully',\n",
              " 'bebother',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'bed',\n",
              " 'bedroom',\n",
              " 'bedrooms',\n",
              " 'beds',\n",
              " 'beech',\n",
              " 'been',\n",
              " 'beer',\n",
              " 'before',\n",
              " 'beg',\n",
              " 'began',\n",
              " 'begin',\n",
              " 'beginning',\n",
              " 'begun',\n",
              " 'behave',\n",
              " 'behaved',\n",
              " 'behind',\n",
              " 'behold',\n",
              " 'being',\n",
              " 'believe',\n",
              " 'believing',\n",
              " 'bell',\n",
              " 'belladonna',\n",
              " 'bells',\n",
              " 'belong',\n",
              " 'belonged',\n",
              " 'belongs',\n",
              " 'below',\n",
              " 'belt',\n",
              " 'belts',\n",
              " 'bend',\n",
              " 'beneath',\n",
              " 'bent',\n",
              " 'bert',\n",
              " \"bert's\",\n",
              " 'best',\n",
              " 'bet',\n",
              " 'better',\n",
              " 'between',\n",
              " 'bewildered',\n",
              " 'bewuthered',\n",
              " 'beyond',\n",
              " 'biased',\n",
              " 'bifur',\n",
              " 'big',\n",
              " 'bigger',\n",
              " 'bilbo',\n",
              " \"bilbo's\",\n",
              " 'bill',\n",
              " \"bill'\",\n",
              " 'biscuit',\n",
              " 'bit',\n",
              " 'bite',\n",
              " 'black',\n",
              " 'blacksmith',\n",
              " 'blame',\n",
              " 'bless',\n",
              " 'blew',\n",
              " 'blighter',\n",
              " 'blimey',\n",
              " 'blinking',\n",
              " 'blow',\n",
              " 'blowing',\n",
              " 'blue',\n",
              " 'blundering',\n",
              " 'blunt',\n",
              " 'blushed',\n",
              " 'bobbing',\n",
              " 'body',\n",
              " 'bofur',\n",
              " 'boiled',\n",
              " 'boiling',\n",
              " 'bolted',\n",
              " 'bombur',\n",
              " 'boned',\n",
              " 'bones',\n",
              " 'book',\n",
              " 'boots',\n",
              " 'borrow',\n",
              " 'borrowed',\n",
              " 'both',\n",
              " 'bother',\n",
              " 'bothered',\n",
              " 'bothering',\n",
              " 'bottle',\n",
              " 'bottles',\n",
              " 'bow',\n",
              " 'bowed',\n",
              " 'bowing',\n",
              " 'boy',\n",
              " 'boys',\n",
              " 'bp',\n",
              " 'br',\n",
              " 'braces',\n",
              " 'branch',\n",
              " 'brass',\n",
              " 'bravo',\n",
              " 'break',\n",
              " 'breakfast',\n",
              " 'breakfasts',\n",
              " 'breaking',\n",
              " 'breast',\n",
              " 'breath',\n",
              " 'bred',\n",
              " 'breeze',\n",
              " 'brief',\n",
              " 'bright',\n",
              " 'brim',\n",
              " 'bring',\n",
              " 'broad',\n",
              " 'broke',\n",
              " 'brothers',\n",
              " 'brought',\n",
              " 'brown',\n",
              " 'brushed',\n",
              " 'built',\n",
              " 'bullroarer',\n",
              " \"bullroarer's\",\n",
              " 'bungo',\n",
              " 'burglar',\n",
              " \"burglar's\",\n",
              " 'burglarious',\n",
              " 'burglars',\n",
              " 'burglary',\n",
              " 'burgling',\n",
              " 'burn',\n",
              " 'burrahobbit',\n",
              " 'burst',\n",
              " 'bur—',\n",
              " 'bushy',\n",
              " 'business',\n",
              " 'busy',\n",
              " 'but',\n",
              " 'buttered',\n",
              " 'buttons',\n",
              " 'but—',\n",
              " 'by',\n",
              " 'bye',\n",
              " 'bywater',\n",
              " 'cake',\n",
              " 'cakes',\n",
              " 'call',\n",
              " 'called',\n",
              " 'calling',\n",
              " 'came',\n",
              " 'camp',\n",
              " 'camped',\n",
              " 'can',\n",
              " \"can't\",\n",
              " 'canny',\n",
              " 'can’t',\n",
              " 'careful',\n",
              " 'carefully',\n",
              " 'carpeted',\n",
              " 'carried',\n",
              " 'carry',\n",
              " 'carved',\n",
              " 'carvings',\n",
              " 'cash',\n",
              " 'castles',\n",
              " 'catch',\n",
              " 'caught',\n",
              " 'caution',\n",
              " 'cavalcade',\n",
              " 'caverns',\n",
              " 'caves',\n",
              " 'ceiling',\n",
              " 'cellar',\n",
              " 'cellars',\n",
              " 'certain',\n",
              " 'certainly',\n",
              " 'chain',\n",
              " 'chair',\n",
              " 'chairs',\n",
              " 'chance',\n",
              " 'change',\n",
              " 'changed',\n",
              " 'chapter',\n",
              " 'charged',\n",
              " 'cheerily',\n",
              " 'cheese',\n",
              " 'chicken',\n",
              " 'chiefly',\n",
              " 'chimney',\n",
              " 'chip',\n",
              " 'choked',\n",
              " 'chose',\n",
              " 'chosen',\n",
              " 'chronicles',\n",
              " 'claim',\n",
              " 'clan',\n",
              " 'clapped',\n",
              " 'clarinets',\n",
              " 'class',\n",
              " 'clay',\n",
              " 'clean',\n",
              " 'cleaned',\n",
              " 'clear',\n",
              " 'clever',\n",
              " 'cliff',\n",
              " 'climbing',\n",
              " 'cloak',\n",
              " 'clock',\n",
              " 'closed',\n",
              " 'cloth',\n",
              " 'clothes',\n",
              " 'cloud',\n",
              " 'clouds',\n",
              " 'club',\n",
              " 'clump',\n",
              " 'co',\n",
              " 'coal',\n",
              " 'coalmining',\n",
              " 'coats',\n",
              " 'coffee',\n",
              " 'cold',\n",
              " 'collect',\n",
              " 'collected',\n",
              " 'colours',\n",
              " 'columns',\n",
              " 'come',\n",
              " 'comers',\n",
              " 'comes',\n",
              " 'comfort',\n",
              " 'comfortable',\n",
              " 'comfortably',\n",
              " 'comic',\n",
              " 'coming',\n",
              " 'common',\n",
              " 'company',\n",
              " 'compliments',\n",
              " 'concern',\n",
              " 'confused',\n",
              " 'confusticate',\n",
              " 'considered',\n",
              " 'considering',\n",
              " 'conspirator',\n",
              " 'conversation',\n",
              " 'cook',\n",
              " 'copped',\n",
              " 'corks',\n",
              " 'corner',\n",
              " 'corners',\n",
              " 'correct',\n",
              " 'corrected',\n",
              " 'corresponds',\n",
              " 'could',\n",
              " \"couldn't\",\n",
              " 'counsellor',\n",
              " 'country',\n",
              " 'couple',\n",
              " 'courage',\n",
              " 'course',\n",
              " 'covers',\n",
              " 'crack',\n",
              " 'cracking',\n",
              " 'crackling',\n",
              " 'cradles',\n",
              " 'crash',\n",
              " 'crawl',\n",
              " 'creaking',\n",
              " 'creep',\n",
              " 'crept',\n",
              " 'crocks',\n",
              " 'cross',\n",
              " 'crossed',\n",
              " 'crowns',\n",
              " 'cunning',\n",
              " 'cup',\n",
              " 'cups',\n",
              " 'curious',\n",
              " 'curly',\n",
              " 'current',\n",
              " 'curse',\n",
              " 'cursed',\n",
              " 'curses',\n",
              " 'cut',\n",
              " \"d'yer\",\n",
              " 'dagger',\n",
              " 'dale',\n",
              " 'dang',\n",
              " 'dangerous',\n",
              " 'dared',\n",
              " \"daren't\",\n",
              " 'daresay',\n",
              " 'dark',\n",
              " 'daughters',\n",
              " 'dawn',\n",
              " 'day',\n",
              " 'days',\n",
              " 'dead',\n",
              " 'deal',\n",
              " 'dear',\n",
              " 'decent',\n",
              " 'decided',\n",
              " 'deep',\n",
              " 'deeply',\n",
              " 'defrayed',\n",
              " 'delivery',\n",
              " 'delves',\n",
              " 'dent',\n",
              " 'departure',\n",
              " 'depredations',\n",
              " 'descendant',\n",
              " 'described',\n",
              " 'description',\n",
              " 'desert',\n",
              " 'desire',\n",
              " 'destroyed',\n",
              " 'destruction',\n",
              " 'detachable',\n",
              " 'determined',\n",
              " 'devices',\n",
              " 'devoted',\n",
              " 'devouring',\n",
              " 'diamond',\n",
              " 'diary',\n",
              " 'did',\n",
              " \"didn't\",\n",
              " 'died',\n",
              " 'difficult',\n",
              " 'digging',\n",
              " 'dignity',\n",
              " 'dim',\n",
              " 'ding',\n",
              " 'dining',\n",
              " 'dinner',\n",
              " 'direction',\n",
              " 'dirty',\n",
              " 'disappear',\n",
              " 'disappeared',\n",
              " 'disappointed',\n",
              " 'disappointedly',\n",
              " 'discovered',\n",
              " 'discreetly',\n",
              " 'discuss',\n",
              " 'disgusted',\n",
              " 'dish',\n",
              " 'dishes',\n",
              " 'dismally',\n",
              " 'distance',\n",
              " 'distant',\n",
              " 'disturb',\n",
              " 'disturbing',\n",
              " 'do',\n",
              " 'does',\n",
              " 'dogs',\n",
              " 'doing',\n",
              " \"don't\",\n",
              " 'done',\n",
              " 'dong',\n",
              " 'doom',\n",
              " 'door',\n",
              " 'doors',\n",
              " 'doorstep',\n",
              " 'dori',\n",
              " 'doubts',\n",
              " 'down',\n",
              " 'drafting',\n",
              " 'dragon',\n",
              " \"dragon's\",\n",
              " 'dragons',\n",
              " \"dragons'\",\n",
              " 'drawing',\n",
              " 'dreadful',\n",
              " 'dreams',\n",
              " 'dreary',\n",
              " 'dress',\n",
              " 'dressing',\n",
              " 'drier',\n",
              " 'drink',\n",
              " 'drinking',\n",
              " 'drip',\n",
              " 'dripping',\n",
              " 'driven',\n",
              " 'dropped',\n",
              " 'drowned',\n",
              " 'drum',\n",
              " 'dry',\n",
              " 'duck',\n",
              " 'due',\n",
              " 'dump',\n",
              " 'dungeons',\n",
              " 'dusted',\n",
              " 'duty',\n",
              " 'dwalin',\n",
              " \"dwalin's\",\n",
              " 'dwarf',\n",
              " 'dwarves',\n",
              " \"dwarves'\",\n",
              " 'dwarvish',\n",
              " 'dying',\n",
              " 'dynasties',\n",
              " 'each',\n",
              " 'early',\n",
              " 'earn',\n",
              " 'ears',\n",
              " 'earth',\n",
              " 'east',\n",
              " 'easy',\n",
              " 'eat',\n",
              " 'eaten',\n",
              " 'edge',\n",
              " 'edition',\n",
              " 'eggs',\n",
              " 'either',\n",
              " 'elbow',\n",
              " 'elephants',\n",
              " 'eleven',\n",
              " 'else',\n",
              " \"else's\",\n",
              " 'elves',\n",
              " 'elvish',\n",
              " 'empty',\n",
              " 'en',\n",
              " 'enchanted',\n",
              " 'end',\n",
              " 'ending',\n",
              " 'ends',\n",
              " 'enemy',\n",
              " 'engagement',\n",
              " 'engine',\n",
              " 'enjoy',\n",
              " 'enormous',\n",
              " 'enormously',\n",
              " 'enough',\n",
              " 'entirely',\n",
              " 'entrance',\n",
              " 'ere',\n",
              " 'erebor',\n",
              " 'error',\n",
              " 'escape',\n",
              " 'escaped',\n",
              " 'especially',\n",
              " 'esteemed',\n",
              " 'estimable',\n",
              " 'et',\n",
              " 'eve',\n",
              " 'even',\n",
              " 'evening',\n",
              " 'event',\n",
              " 'eventually',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everybody',\n",
              " 'everyday',\n",
              " 'everything',\n",
              " 'evil',\n",
              " 'exact',\n",
              " 'exactly',\n",
              " 'exaggeration',\n",
              " 'example',\n",
              " 'exceeding',\n",
              " 'excellent',\n",
              " 'except',\n",
              " 'exception',\n",
              " 'excitable',\n",
              " 'excited',\n",
              " 'excitement',\n",
              " 'excuse',\n",
              " 'existence',\n",
              " 'expect',\n",
              " 'expected',\n",
              " 'expedition',\n",
              " 'expenses',\n",
              " 'experience',\n",
              " 'expert',\n",
              " 'explain',\n",
              " 'explanation',\n",
              " 'explore',\n",
              " 'extra',\n",
              " 'extraordinary',\n",
              " 'eye',\n",
              " 'eyebrows',\n",
              " 'eyes',\n",
              " 'fabulous',\n",
              " 'face',\n",
              " 'faces',\n",
              " 'fact',\n",
              " 'fair',\n",
              " 'fairly',\n",
              " 'fairy',\n",
              " 'fall',\n",
              " 'falling',\n",
              " 'families',\n",
              " 'family',\n",
              " \"family's\",\n",
              " 'famous',\n",
              " 'far',\n",
              " 'farm',\n",
              " 'farmer',\n",
              " 'fashion',\n",
              " 'fast',\n",
              " 'fastened',\n",
              " 'fat',\n",
              " 'father',\n",
              " \"father's\",\n",
              " 'fathers',\n",
              " 'favourite',\n",
              " 'fearful',\n",
              " 'feel',\n",
              " 'feeling',\n",
              " 'feet',\n",
              " 'fell',\n",
              " 'fellow',\n",
              " 'fells',\n",
              " 'felt',\n",
              " 'fender',\n",
              " 'fetch',\n",
              " 'few',\n",
              " 'fiddles',\n",
              " 'fields',\n",
              " 'fierce',\n",
              " 'fifty',\n",
              " 'fight',\n",
              " 'fighting',\n",
              " 'fili',\n",
              " 'fill',\n",
              " 'filled',\n",
              " 'final',\n",
              " 'find',\n",
              " 'finding',\n",
              " 'fine',\n",
              " 'fingers',\n",
              " 'finished',\n",
              " 'finishing',\n",
              " 'fire',\n",
              " 'firelight',\n",
              " 'fires',\n",
              " 'fireside',\n",
              " 'firework',\n",
              " 'fireworks',\n",
              " \"firnbul's\",\n",
              " 'first',\n",
              " 'fist',\n",
              " 'fits',\n",
              " 'five',\n",
              " 'flame',\n",
              " 'flames',\n",
              " 'flaming',\n",
              " 'flat',\n",
              " 'fled',\n",
              " 'flew',\n",
              " 'flickered',\n",
              " 'floated',\n",
              " 'floor',\n",
              " 'floors',\n",
              " 'flowering',\n",
              " 'flowers',\n",
              " 'flummoxed',\n",
              " 'fluster',\n",
              " 'flustered',\n",
              " 'flutes',\n",
              " 'fly',\n",
              " 'flying',\n",
              " 'fog',\n",
              " 'folk',\n",
              " 'followed',\n",
              " 'fond',\n",
              " 'food',\n",
              " 'fool',\n",
              " 'foot',\n",
              " 'for',\n",
              " 'forced',\n",
              " 'forever',\n",
              " 'forget',\n",
              " 'forgot',\n",
              " 'forgotten',\n",
              " 'forks',\n",
              " 'forth',\n",
              " 'forward',\n",
              " 'found',\n",
              " 'four',\n",
              " 'fourteen',\n",
              " 'fourteenth',\n",
              " 'fragment',\n",
              " 'frail',\n",
              " 'fried',\n",
              " 'friend',\n",
              " 'friends',\n",
              " 'fright',\n",
              " 'from',\n",
              " 'front',\n",
              " 'frowned',\n",
              " 'frowning',\n",
              " 'fruity',\n",
              " 'fugitive',\n",
              " 'full',\n",
              " 'fun',\n",
              " 'funeral',\n",
              " 'funny',\n",
              " 'furry',\n",
              " 'further',\n",
              " 'gained',\n",
              " 'game',\n",
              " 'gandalf',\n",
              " \"gandalf's\",\n",
              " 'garden',\n",
              " 'gasp',\n",
              " 'gasping',\n",
              " 'gate',\n",
              " 'gathering',\n",
              " 'gave',\n",
              " 'gazing',\n",
              " 'gems',\n",
              " 'genealogies',\n",
              " 'general',\n",
              " 'gentler',\n",
              " 'get',\n",
              " 'gets',\n",
              " 'getting',\n",
              " 'giants',\n",
              " 'girls',\n",
              " 'give',\n",
              " 'given',\n",
              " 'gives',\n",
              " 'glance',\n",
              " 'glare',\n",
              " 'glasses',\n",
              " 'gloaming',\n",
              " 'gloin',\n",
              " 'gloomy',\n",
              " 'glum',\n",
              " 'go',\n",
              " 'goblets',\n",
              " 'goblin',\n",
              " 'goblins',\n",
              " 'goes',\n",
              " 'going',\n",
              " 'gol',\n",
              " 'gold',\n",
              " 'golden',\n",
              " 'golf',\n",
              " 'gone',\n",
              " 'good',\n",
              " 'gorgeous',\n",
              " 'got',\n",
              " 'gown',\n",
              " 'grabbed',\n",
              " 'gracious',\n",
              " 'gradually',\n",
              " 'gram',\n",
              " 'grand',\n",
              " 'grandfather',\n",
              " \"grandfather's\",\n",
              " 'granduncle',\n",
              " 'grass',\n",
              " 'grateful',\n",
              " 'gravy',\n",
              " 'great',\n",
              " 'greater',\n",
              " 'greedy',\n",
              " 'green',\n",
              " 'greeting',\n",
              " 'grew',\n",
              " 'grey',\n",
              " 'grim',\n",
              " 'grimly',\n",
              " 'groaned',\n",
              " 'grocer',\n",
              " 'ground',\n",
              " 'grow',\n",
              " 'grown',\n",
              " 'grumbled',\n",
              " 'grumbling',\n",
              " 'grumpy',\n",
              " 'grunted',\n",
              " 'guaranteed',\n",
              " 'guard',\n",
              " 'guess',\n",
              " 'guessed',\n",
              " 'gun',\n",
              " 'ha',\n",
              " 'had',\n",
              " 'hair',\n",
              " 'half',\n",
              " 'hall',\n",
              " 'halls',\n",
              " 'halves',\n",
              " 'ham',\n",
              " 'hammers',\n",
              " 'hand',\n",
              " 'handed',\n",
              " 'handing',\n",
              " 'handkerchief',\n",
              " 'handkerchiefs',\n",
              " 'handle',\n",
              " 'hands',\n",
              " 'handsomely',\n",
              " 'hang',\n",
              " 'hanging',\n",
              " 'happen',\n",
              " 'happened',\n",
              " 'happy',\n",
              " 'hard',\n",
              " 'hardly',\n",
              " 'harp',\n",
              " 'harps',\n",
              " 'has',\n",
              " 'hat',\n",
              " 'hates',\n",
              " 'hats',\n",
              " 'haughty',\n",
              " 'have',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'head',\n",
              " 'heads',\n",
              " 'heap',\n",
              " 'hear',\n",
              " 'heard',\n",
              " 'hearing',\n",
              " 'hearth',\n",
              " 'hearts',\n",
              " 'heath',\n",
              " 'heavy',\n",
              " 'height',\n",
              " 'heir',\n",
              " 'help',\n",
              " 'helps',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hero',\n",
              " 'heroes',\n",
              " 'hesitated',\n",
              " 'hidden',\n",
              " 'hide',\n",
              " 'hiding',\n",
              " 'high',\n",
              " 'higher',\n",
              " 'hill',\n",
              " 'hills',\n",
              " 'hilt',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'history',\n",
              " 'hoard',\n",
              " 'hob',\n",
              " 'hobbit',\n",
              " \"hobbit's\",\n",
              " 'hobbits',\n",
              " 'hold',\n",
              " 'holding',\n",
              " 'hole',\n",
              " 'holes',\n",
              " 'hollow',\n",
              " 'home',\n",
              " 'homes',\n",
              " 'honest',\n",
              " 'honour',\n",
              " 'hood',\n",
              " 'hooded',\n",
              " 'hoods',\n",
              " 'hoot',\n",
              " 'hope',\n",
              " 'hoped',\n",
              " 'hopeful',\n",
              " 'hopped',\n",
              " 'horrible',\n",
              " 'horse',\n",
              " 'hospitality',\n",
              " 'host',\n",
              " 'hot',\n",
              " 'hours',\n",
              " 'house',\n",
              " 'houses',\n",
              " 'hover',\n",
              " 'how',\n",
              " 'however',\n",
              " 'huddled',\n",
              " 'huge',\n",
              " 'huger',\n",
              " 'huggins',\n",
              " 'humming',\n",
              " 'humph',\n",
              " 'hundred',\n",
              " 'hung',\n",
              " 'hunter',\n",
              " 'hurricane',\n",
              " 'hurried',\n",
              " 'hurry',\n",
              " 'hush',\n",
              " 'hushed',\n",
              " 'i',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'idea',\n",
              " 'ideas',\n",
              " 'if',\n",
              " 'ii',\n",
              " 'immediately',\n",
              " 'immense',\n",
              " 'immensely',\n",
              " 'immovably',\n",
              " 'important',\n",
              " 'in',\n",
              " 'inaccuracies',\n",
              " 'inclined',\n",
              " 'indeed',\n",
              " 'ingenious',\n",
              " 'inhabited',\n",
              " 'ink',\n",
              " 'inn',\n",
              " 'inns',\n",
              " 'inquisitive',\n",
              " 'inside',\n",
              " 'instance',\n",
              " 'instead',\n",
              " 'instruments',\n",
              " 'inter',\n",
              " 'interested',\n",
              " 'interrupted',\n",
              " 'into',\n",
              " 'intricate',\n",
              " 'introduce',\n",
              " 'invented',\n",
              " 'invited',\n",
              " 'ire',\n",
              " 'is',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'jacket',\n",
              " 'jam',\n",
              " 'jealous',\n",
              " 'jelly',\n",
              " 'jerk',\n",
              " 'jewels',\n",
              " 'job',\n",
              " 'jogged',\n",
              " 'jogging',\n",
              " 'join',\n",
              " 'joined',\n",
              " 'journey',\n",
              " \"journey's\",\n",
              " 'jug',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCswnI9h7fx5"
      },
      "source": [
        "# creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = {i:u for i, u in enumerate(vocab)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtvMAAPCCQqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67f4474-103d-4162-cf78-d8b87e16a980"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDkSclbCgF_R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d800655-be25-44a8-d462-47768348df92"
      },
      "source": [
        "corpus[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'in this reprint several minor inaccuracies, most of them noted by readers, have '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJeuh19ZMj2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9325bd31-2066-4ca9-96db-eab978713c88"
      },
      "source": [
        "input_sequences=[]\n",
        "\n",
        "for line in corpus:\n",
        "  token_list=tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "print(len(input_sequences))\n",
        "len(token_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiTEYLUJFz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0de5f0-03b2-49ce-ca4d-20a7142b84ed"
      },
      "source": [
        "#passing some words and predicting next word .\n",
        "train_len = 20 # taking 25 words to predict 26th word..\n",
        "text_seq = []\n",
        "for i in range(train_len,len(vocab)):\n",
        "\tseq=vocab[i-train_len:i]\n",
        "\ttext_seq.append(seq)\n",
        "print(' '.join(text_seq[0])) # joining words to form sentences.."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "' 'anything 'ell 'em 'ere 'five 'get 'oo 'thank 10 2 45 6te a about above abreast' absolutely absurd acceptance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqqfJNF0QLXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023056fa-9f61-4e87-d512-233918ee51ea"
      },
      "source": [
        "#pad sequences\n",
        "max_sequence_len=max([len(seq) for seq in input_sequences])\n",
        "\n",
        "\n",
        "print(max_sequence_len, total_words)\n",
        "\n",
        "input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, padding=\"pre\", maxlen=max_sequence_len))\n",
        "\n",
        "#create predictions and lebels\n",
        "xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21 2194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zys8OJFkopGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a804a1-b3ee-4044-aafe-fc7ff5da296e"
      },
      "source": [
        "input_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0, 1012,  311],\n",
              "       [   0,    0,    0, ...,    0,    7,   30],\n",
              "       [   0,    0,    0, ...,    7,   30, 1013],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    6,  605,   16],\n",
              "       [   0,    0,    0, ...,  605,   16,    3],\n",
              "       [   0,    0,    0, ...,   16,    3,  120]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5SURlfSpjhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ceef44-6897-4918-ea77-7f3cbd9e4aec"
      },
      "source": [
        "seq_length=xs.shape[1]\n",
        "\n",
        "print(seq_length)\n",
        "\n",
        "ys.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11418, 2194)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuhxXlRaQmlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e515ed-2610-454e-8686-b09291fba30d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=total_words,output_dim=100,input_length=seq_length))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(96)))\n",
        "model.add(Dense(1097,activation=\"relu\"))\n",
        "model.add(Dense(2194,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 100)           219400    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 20, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 192)               304896    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1097)              211721    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2194)              2409012   \n",
            "=================================================================\n",
            "Total params: 3,446,229\n",
            "Trainable params: 3,446,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78pPVP7WPZ0E"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgxuz57NgC0p"
      },
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{accuracy:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsHuMwicQQGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67885f0-4285-4fb0-baff-e3459ad1bb4b"
      },
      "source": [
        "history=model.fit(xs,ys,batch_size=32,epochs=100,verbose=1,callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "357/357 [==============================] - 40s 13ms/step - loss: 6.5364 - accuracy: 0.0495\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 2/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 5.8872 - accuracy: 0.0605\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 3/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 5.7032 - accuracy: 0.0645\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 4/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 5.5518 - accuracy: 0.0760\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 5/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 5.2725 - accuracy: 0.0965\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 6/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 5.0621 - accuracy: 0.1129\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 7/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 4.8695 - accuracy: 0.1217\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 8/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 4.6732 - accuracy: 0.1338\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 9/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 4.4836 - accuracy: 0.1429\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 10/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 4.3092 - accuracy: 0.1477\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 11/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 4.1420 - accuracy: 0.1558\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 12/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 3.9033 - accuracy: 0.1804\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 13/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 3.6855 - accuracy: 0.1943\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 14/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 3.4405 - accuracy: 0.2223\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 15/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 3.1939 - accuracy: 0.2488\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 16/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 2.9620 - accuracy: 0.2880\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 17/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 2.6653 - accuracy: 0.3530\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 18/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 2.4221 - accuracy: 0.4001\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 19/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 2.1403 - accuracy: 0.4559\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 20/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.9255 - accuracy: 0.5107\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 21/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 1.7138 - accuracy: 0.5665\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 22/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 1.5035 - accuracy: 0.6139\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 23/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 1.3206 - accuracy: 0.6659\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 24/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 1.1838 - accuracy: 0.6999\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 25/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 1.0279 - accuracy: 0.7397\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 26/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.8918 - accuracy: 0.7709\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 27/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.8028 - accuracy: 0.7969\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 28/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.7339 - accuracy: 0.8168\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 29/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.6181 - accuracy: 0.8422\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 30/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.5678 - accuracy: 0.8566\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 31/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.5042 - accuracy: 0.8734\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 32/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.4394 - accuracy: 0.8887\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 33/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.4290 - accuracy: 0.8897\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 34/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3972 - accuracy: 0.8983\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 35/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3680 - accuracy: 0.9016\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 36/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3454 - accuracy: 0.9083\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 37/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3388 - accuracy: 0.9085\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 38/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.3312 - accuracy: 0.9091\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 39/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2992 - accuracy: 0.9196\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 40/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2830 - accuracy: 0.9226\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 41/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2591 - accuracy: 0.9327\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 42/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2862 - accuracy: 0.9227\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 43/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2614 - accuracy: 0.9270\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 44/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2528 - accuracy: 0.9263\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 45/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2439 - accuracy: 0.9302\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 46/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2581 - accuracy: 0.9237\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 47/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.2254 - accuracy: 0.9373\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 48/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2400 - accuracy: 0.9273\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 49/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2294 - accuracy: 0.9345\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 50/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2154 - accuracy: 0.9357\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 51/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2198 - accuracy: 0.9325\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 52/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2057 - accuracy: 0.9385\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 53/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2034 - accuracy: 0.9358\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 54/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2079 - accuracy: 0.9364\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 55/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1876 - accuracy: 0.9420\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 56/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1783 - accuracy: 0.9460\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 57/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1941 - accuracy: 0.9399\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 58/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2060 - accuracy: 0.9358\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 59/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2273 - accuracy: 0.9299\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 60/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2033 - accuracy: 0.9376\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 61/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1832 - accuracy: 0.9429\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 62/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1690 - accuracy: 0.9442\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 63/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1736 - accuracy: 0.9438\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 64/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1885 - accuracy: 0.9419\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 65/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1784 - accuracy: 0.9428\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 66/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1829 - accuracy: 0.9395\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 67/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1909 - accuracy: 0.9361\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 68/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1694 - accuracy: 0.9456\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 69/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1901 - accuracy: 0.9384\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 70/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1740 - accuracy: 0.9438\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 71/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1667 - accuracy: 0.9434\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 72/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1913 - accuracy: 0.9367\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 73/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1761 - accuracy: 0.9416\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 74/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1521 - accuracy: 0.9493\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 75/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1662 - accuracy: 0.9442\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 76/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1493 - accuracy: 0.9498\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 77/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1525 - accuracy: 0.9483\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 78/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1838 - accuracy: 0.9376\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 79/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2084 - accuracy: 0.9334\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 80/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1987 - accuracy: 0.9323\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 81/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1629 - accuracy: 0.9458\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 82/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1694 - accuracy: 0.9401\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 83/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1482 - accuracy: 0.9488\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 84/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1539 - accuracy: 0.9461\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 85/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1605 - accuracy: 0.9443\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 86/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1535 - accuracy: 0.9462\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 87/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1541 - accuracy: 0.9453\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 88/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1621 - accuracy: 0.9469\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 89/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1652 - accuracy: 0.9424\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 90/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1749 - accuracy: 0.9398\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 91/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1611 - accuracy: 0.9443\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 92/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1474 - accuracy: 0.9484\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 93/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1499 - accuracy: 0.9483\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 94/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1750 - accuracy: 0.9386\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 95/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1492 - accuracy: 0.9483\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 96/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1365 - accuracy: 0.9503\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 97/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1409 - accuracy: 0.9510\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 98/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1575 - accuracy: 0.9434\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 99/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1692 - accuracy: 0.9429\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 100/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1548 - accuracy: 0.9455\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvI3705MByWo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "bc7b69ca-b3fd-40f0-da6f-d6781196a235"
      },
      "source": [
        "import random\n",
        "def gen_text(model,tokenizer,seq_length,seed_text,num_gen_words):\n",
        "    output_text = []\n",
        "    input_text = seed_text # initial seeding texts\n",
        "    for i in range(num_gen_words):\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0] # it retuns a tuple of item\t\n",
        "        pad_encoded = tf.keras.preprocessing.sequence.pad_sequences([encoded_text],maxlen=seq_length,padding='pre') # as if user add a long or short text then it corrects it.\n",
        "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]   #pred prob for each words.\n",
        "        \n",
        "        pred_word=tokenizer.index_word[pred_word_ind]\n",
        "        \t\t\n",
        "        input_text += ' '+pred_word\n",
        "        output_text.append(pred_word)\n",
        "    \t\n",
        "    return ' '.join(output_text)\n",
        "\n",
        "random.seed(101)\n",
        "random_pick=random.randint(0,len(text_seq))\n",
        "random_seed_text=text_seq[random_pick]# choosing randomly words\n",
        "seed_text=' '.join(random_seed_text)\n",
        "print(seed_text)\n",
        "\n",
        "gen_text(model,tokenizer,seq_length,seed_text=seed_text,num_gen_words=1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gown grabbed gracious gradually gram grand grandfather grandfather's granduncle grass grateful gravy great greater greedy green greeting grew grey grim\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"with the wind inside the door how they went to the dragon in the to the dragon in the the the the dwarves were starting on the other of the dwarves from that hand and the other more than all a piece of flame the trees he spread a piece of red they spread a bad time they spread a error good sir under the dragon in the other way he descendant bad had not a dragon he bad a all he had only just enough wits came down but the lord of the trade or used to tell such to come what they found himself under the dark of his dark belt about the wind shook the village as the dragon the trees of him almost spread a piece of one the dwarves we have have all the other more sandy hole with nothing and as the other fields and to bring error names like a bad wet evening to begin to be arranged set out of the lord of the the the dragon were be staff but a valley there under the pantry at the hands and the side with the green fields and those introduce are bad used to spread a other knocking were dark it a jelly that them a beautiful grey ring a grey clouds the jelly were gone with a bad hand clean with the valley their bad green with a jelly from hands and by that time all the lord of the rings but the other runes the trees like all way one were an dark green dark head we had no names of an red looking off and the way to shook his pretending to way no firework glare set out another even bigger while he spread a dark brief explanation above the table or over the pantry to the trees he had got set out with the other more had gone but in trees and that the lord of the dragon the dragon in the dwarves from that time all the lord of the fields of the to the other were worms in the green gate the green fields and the fields of an hands and the jelly in the other town of the green more and gone with trees and as the other runes that time i all all to the other of the dwarves rushed down to the side with the last desert i bad a good more more and a fields and it have the all he had to find when he was used to be arranged just after all a lord of the dwarves put together if a most came and in its way from everybody way and glasses and to bring them to their mouth he said our own name when he gave me you the music said the key it a days as the dragon and in the hill the other had be spread that helps the piece of their dark smell nor an adventure all a piece of us not time one of the other more had gone with fire at all firework have all one he had had come about with a long of all the hobbit now it who was only too way he can my adventure of the error dark of yore made mighty spells he said with red i know of something some of all the fire of us had money to spend and what was to they found would will try it had to earn him out of the a hobbit was turning round far another had behind all way the way in dark way at all the lord of the world that opened in the last side he had an soon went back to their dark to walk very soon he was as the to in the way on them in this way the other gate and bend the trees he spread a piece of dark gram in and to the halls and were gone with trees and it had all a to to them dark way he spread a piece of moria had money to spend and to lend a wood like him a fog the fog the hobbit was quite most to be gone as it as the other runes that time i know i know i know they have only just had to earn boys and don't me notice but supper to the hill for old friends away very tired and very hobbit then a way he used to forks and glasses and paused for a good sir but a hobbit before they could ride a drink he had a dragon in the to remarkable richly jewels he was set out like the whistle of an head in the other gate and those days bilbo way to be parts a piece of those time but all the lord of the rings they had not in error names are spread a little brief explanation descendant was reviving in the side of the door nearly under the to the other fields and it in a hands and in his hands and in a piece of those all hands and to on that time the other runes that time i know i ought to be notice under the lord of the rings of the village hand side out of the dragon in the other gate and it in the other more had time in the to the other runes that time i know of ought to be played on while the dark mass of westmarch and is now told the wind shook the trees but there were a little brief far would a dragon to my names like not as hand and that in the lord of the rings he had not arranged knife me there was little second under the dragon in the fields and he talks but that in the way he can duck with fire and glasses the other more sandy one with a red\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEG3tiQPuPSU"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-4N4qbpuS16"
      },
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{accuracy:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY8QlvIYuyVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784e01a8-d82d-4a99-9ca0-a6a41c0424b9"
      },
      "source": [
        "history=model.fit(xs,ys,batch_size=32,epochs=100,verbose=1,callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "357/357 [==============================] - 9s 14ms/step - loss: 0.1518 - accuracy: 0.9478\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 2/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1375 - accuracy: 0.9494\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 3/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1482 - accuracy: 0.9466\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 4/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1475 - accuracy: 0.9498\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 5/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1467 - accuracy: 0.9475\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 6/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1776 - accuracy: 0.9396\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 7/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1602 - accuracy: 0.9416\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 8/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1418 - accuracy: 0.9494\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 9/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1502 - accuracy: 0.9469\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 10/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1420 - accuracy: 0.9480\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 11/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1413 - accuracy: 0.9493\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 12/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1429 - accuracy: 0.9477\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 13/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1421 - accuracy: 0.9469\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 14/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1367 - accuracy: 0.9474\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 15/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1311 - accuracy: 0.9498\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 16/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1459 - accuracy: 0.9445\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 17/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1534 - accuracy: 0.9445\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 18/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1761 - accuracy: 0.9358\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 19/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1455 - accuracy: 0.9460\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 20/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1499 - accuracy: 0.9444\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 21/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1363 - accuracy: 0.9483\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 22/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1362 - accuracy: 0.9491\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 23/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1360 - accuracy: 0.9466\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 24/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1415 - accuracy: 0.9471\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 25/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1472 - accuracy: 0.9455\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 26/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1572 - accuracy: 0.9446\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 27/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1421 - accuracy: 0.9444\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 28/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1320 - accuracy: 0.9479\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 29/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1438 - accuracy: 0.9494\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 30/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1254 - accuracy: 0.9521\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 31/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1370 - accuracy: 0.9487\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 32/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1550 - accuracy: 0.9453\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 33/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1421 - accuracy: 0.9464\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 34/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1394 - accuracy: 0.9502\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 35/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1500 - accuracy: 0.9443\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 36/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1358 - accuracy: 0.9489\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 37/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1412 - accuracy: 0.9452\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 38/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1382 - accuracy: 0.9471\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 39/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1467 - accuracy: 0.9452\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 40/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1458 - accuracy: 0.9446\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 41/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1371 - accuracy: 0.9512\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 42/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1421 - accuracy: 0.9466\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 43/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1357 - accuracy: 0.9475\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 44/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1468 - accuracy: 0.9465\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 45/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1370 - accuracy: 0.9474\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 46/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1244 - accuracy: 0.9525\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 47/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1282 - accuracy: 0.9518\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 48/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1447 - accuracy: 0.9478\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 49/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1340 - accuracy: 0.9488\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 50/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1393 - accuracy: 0.9453\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 51/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1490 - accuracy: 0.9436\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 52/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1250 - accuracy: 0.9538\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 53/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1353 - accuracy: 0.9474\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 54/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1399 - accuracy: 0.9495\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 55/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1373 - accuracy: 0.9462\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 56/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1254 - accuracy: 0.9509\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 57/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1489 - accuracy: 0.9430\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 58/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1337 - accuracy: 0.9483\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 59/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1401 - accuracy: 0.9458\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 60/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1302 - accuracy: 0.9541\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 61/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1211 - accuracy: 0.9494\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 62/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1385 - accuracy: 0.9465\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 63/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1506 - accuracy: 0.9448\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 64/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1473 - accuracy: 0.9481\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 65/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1361 - accuracy: 0.9485\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 66/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1262 - accuracy: 0.9497\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 67/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1357 - accuracy: 0.9485\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 68/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1395 - accuracy: 0.9494\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 69/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1295 - accuracy: 0.9494\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 70/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1342 - accuracy: 0.9483\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 71/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1253 - accuracy: 0.9530\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 72/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1226 - accuracy: 0.9502\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 73/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1361 - accuracy: 0.9474\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 74/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1336 - accuracy: 0.9496\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 75/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1412 - accuracy: 0.9486\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 76/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1234 - accuracy: 0.9539\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 77/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1253 - accuracy: 0.9514\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 78/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1351 - accuracy: 0.9480\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 79/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1491 - accuracy: 0.9414\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 80/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1384 - accuracy: 0.9471\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 81/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1255 - accuracy: 0.9491\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 82/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1333 - accuracy: 0.9496\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 83/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1282 - accuracy: 0.9496\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 84/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1178 - accuracy: 0.9526\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 85/100\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1337 - accuracy: 0.9465\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 86/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1491 - accuracy: 0.9428\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 87/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1422 - accuracy: 0.9459\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 88/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1266 - accuracy: 0.9520\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 89/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1311 - accuracy: 0.9489\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 90/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1203 - accuracy: 0.9506\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 91/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1216 - accuracy: 0.9520\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 92/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1200 - accuracy: 0.9510\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 93/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1198 - accuracy: 0.9527\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 94/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1250 - accuracy: 0.9508\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 95/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1256 - accuracy: 0.9522\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 96/100\n",
            "357/357 [==============================] - 5s 13ms/step - loss: 0.1332 - accuracy: 0.9476\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 97/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1550 - accuracy: 0.9437\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 98/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1383 - accuracy: 0.9462\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 99/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1324 - accuracy: 0.9532\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 100/100\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1183 - accuracy: 0.9558\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWnbUceqoe6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "debc5ef9-e8cf-4552-f18c-630ff0ea7ab8"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERhTVy_gMQbO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "8b82d7e2-2ad6-4e63-f9e2-4de890ff704f"
      },
      "source": [
        "import random\n",
        "def gen_text(model,tokenizer,seq_length,seed_text,num_gen_words):\n",
        "    output_text = []\n",
        "    input_text = seed_text # initial seeding text s\n",
        "    for i in range(num_gen_words):\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0] # it retuns a tuple of item\t\n",
        "        pad_encoded = tf.keras.preprocessing.sequence.pad_sequences([encoded_text],maxlen=seq_length,padding='pre') # as if user add a long or short text then it corrects it.\n",
        "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]   #pred prob for each words.\n",
        "        \n",
        "        pred_word=tokenizer.index_word[pred_word_ind]\n",
        "        \t\t\n",
        "        input_text += ' '+pred_word\n",
        "        output_text.append(pred_word)\n",
        "    \t\n",
        "    return ' '.join(output_text)\n",
        "\n",
        "random.seed(101)\n",
        "random_pick=random.randint(0,len(text_seq))\n",
        "random_seed_text=text_seq[random_pick]# choosing randomly words\n",
        "seed_text=' '.join(random_seed_text)\n",
        "print(seed_text)\n",
        "\n",
        "gen_text(model,tokenizer,seq_length,seed_text=seed_text,num_gen_words=1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gown grabbed gracious gradually gram grand grandfather grandfather's granduncle grass grateful gravy great greater greedy green greeting grew grey grim\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the sun must have gone down for it and a while he had eaten swept at an adventure some or even he said and the gorgeous row bilbo had just enough wits left when bert they came and a dragon marked in red on the mountain said balin but it will be a big lamp with a red shad he spread a piece of it said bert and after we shan't get through the business till late the usual had sat down in the kitchen nearly down and the shadows were arming the dwarves rushed at the fire more head with the goblins and the moon and talked and talked and time got up trembling and the in rug shaking like a jelly bawl south on the fat and mountains in front of them when loud came a ring at the deep places of their little loose scale of their armour there were lots of dragons in the north in those quick gandalf made a bad wet evening to begin on they even the gandalf's hobbit bred off a silver scarf over which a white mat i do myself you remember the poorest of us had money to spend and to lend a long journey a journey from which country the key we have long ago paid the goblins of mount gram in the battle of the green fields and talked about and the green fields and the green fields and a moon and kill the battle of the dwarves who all the dwarves who used to tell such wonderful tales at his eyes was full of water the pony was tired and stumbled on stones the others had ordered their breakfasts without so much as a please don't say you can say expert treasure hunter instead of burglar a fierce and jealous love the desire of his magic staff and in its firework glare when he got back balin and dwalin were talking at the table like old friends out for their noticing him short after his walking hobbit some and worst in all fellow conspirator though no noise came out he was slung up into the fire for fire it was without as he saw that it was mostly little left for supper and he said a burglar whether off you go on bed and breakfast to the fire one fine morning for a nasty dirty wet hole filled with a tube his appetite was quite not a north he went in the took side had won he a portent of dale and the warriors were arming the dwarves rushed at the hill or across the water and there they were brothers bilbo plumped down the old maps the and desert i the fire of us that is not without hope indeed for them and wept in hiding and cursed balin and careful as you ever meant it and a bad though they usually have a good notion of the way of their feet before they could say knife they stopped for one another's muttering while oin and gloin they looking said one with a while he had eaten most talked most and laughed most and and thorin indeed for the stool before he could duck behind the dwarves a dry and a thinkin' of to bring us into these parts at all hope anyway him and without bothering to be outside i was one luckily a fine adventurous lad in those days then he went back and crept in through the bargain if you have a pipe about you sit down and the most awkward we still but i know only just escaped i tried to save your father but i know i suppose they made a deal of gold and then and even mend a bad though they usually have a good notion of the deep places of an adventure panelled well for you the dwarves ate and ate and talked and talked and time got into the bargain if you have a pipe about you sit down and the road when bilbo came down on the pantry floor and destruction that dragons make a trees he came out another cup and in the north with this book and you will see the runes there were lots of dragons in the wind some of the north with a crash there came a dry bare sandy hole with nothing and bolted he got into the river running went on thorin taking a nasty mood quite likely to hold and sailing in an evil look as if they can hear a bit startled trolls are slow in the uptake and do what you want done and i will try it if i have to walk from the mountain creaking and cracking in the north and came out another cup and destruction that and make hours or two or he said kili at your service said the wizard not without a mighty warrior days that is the side door and dragons must sleep sometimes i suppose if you sit on the hall bifur and bofur went out more of burglar if you want there time for what they had gone on far into the north and the music and use the old maps the door and off they went to the kitchen nearly down and the shadows were arming the dwarves rushed at the fire of the long lake now a days so in the village ate and talked and time and one and fierce many slung about a hat with a m mood quite likely to hold else's wretched breakfast the old took died in fact and the hobbits had but he thought of going east as quiet and careful as we could as far as the long time for bilbo aloud been most or did anything unexpected the key we have long ago paid the goblins of mount gram in the battle of the green fields and talked about and the green fields and the green fields\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}