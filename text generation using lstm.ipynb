{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment 5.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdOT/Lp7by7A+D0l4l4ZFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souban1234/sou12345/blob/master/text%20generation%20using%20lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOg9TaZC7i5H",
        "outputId": "05a83ce3-5a1e-4f66-eb1b-88bd7416ca6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh40MleI-flb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import string\n",
        "import requests\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHieMJbsLAX1",
        "outputId": "fb43e3e2-84d8-473c-f1e7-3781977aeaf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tokenizer=Tokenizer()\n",
        "data=open(\"/gdrive/My Drive/lotr.txt\").read()\n",
        "corpus=data.lower().split(\"\\n\")[:1000]\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words=len(tokenizer.word_index)+1\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'and': 2, 'a': 3, 'to': 4, 'of': 5, 'he': 6, 'in': 7, 'was': 8, 'i': 9, 'it': 10, 'they': 11, 'on': 12, 'that': 13, 'you': 14, 'said': 15, 'for': 16, 'all': 17, 'had': 18, 'his': 19, 'have': 20, 'not': 21, 'as': 22, 'at': 23, 'with': 24, 'bilbo': 25, 'there': 26, 'is': 27, 'but': 28, 'were': 29, 'this': 30, 'what': 31, 'or': 32, 'up': 33, 'we': 34, 'out': 35, 'like': 36, 'very': 37, 'him': 38, 'gandalf': 39, 'one': 40, 'about': 41, 'if': 42, 'by': 43, 'be': 44, 'so': 45, 'hobbit': 46, 'thorin': 47, 'them': 48, 'door': 49, 'their': 50, 'when': 51, 'good': 52, 'are': 53, 'little': 54, 'me': 55, 'your': 56, 'from': 57, 'no': 58, 'then': 59, 'dwarves': 60, 'went': 61, 'could': 62, 'off': 63, 'after': 64, 'my': 65, 'been': 66, 'now': 67, 'before': 68, 'long': 69, \"don't\": 70, 'baggins': 71, 'time': 72, 'got': 73, 'down': 74, 'more': 75, 'any': 76, 'would': 77, 'just': 78, 'come': 79, 'go': 80, 'do': 81, 'our': 82, 'some': 83, 'far': 84, 'round': 85, 'without': 86, 'into': 87, 'over': 88, 'will': 89, 'us': 90, 'old': 91, 'never': 92, 'know': 93, 'came': 94, 'away': 95, 'who': 96, 'things': 97, 'most': 98, 'great': 99, 'an': 100, 'only': 101, 'than': 102, 'think': 103, 'even': 104, 'too': 105, 'dark': 106, 'mountain': 107, 'hill': 108, 'can': 109, 'morning': 110, 'back': 111, 'quite': 112, 'well': 113, 'which': 114, 'took': 115, 'fire': 116, 'under': 117, 'here': 118, 'dragon': 119, 'while': 120, 'green': 121, 'going': 122, 'say': 123, 'see': 124, 'made': 125, 'light': 126, 'day': 127, 'get': 128, 'way': 129, 'should': 130, 'map': 131, 'enough': 132, 'thought': 133, 'soon': 134, 'make': 135, 'may': 136, 'did': 137, 'anything': 138, 'how': 139, 'found': 140, 'must': 141, 'still': 142, 'breakfast': 143, 'am': 144, 'find': 145, 'mr': 146, 'again': 147, 'gold': 148, 'red': 149, 'people': 150, 'many': 151, 'these': 152, 'left': 153, 'adventures': 154, 'himself': 155, 'along': 156, 'once': 157, 'father': 158, 'behind': 159, 'used': 160, 'inside': 161, 'put': 162, 'burglar': 163, 'william': 164, 'first': 165, 'ring': 166, 'last': 167, 'hole': 168, 'lots': 169, 'side': 170, 'another': 171, 'dragons': 172, 'trees': 173, 'where': 174, 'poor': 175, 'right': 176, 'mountains': 177, 'deep': 178, 'big': 179, 'feet': 180, 'something': 181, 'days': 182, 'bit': 183, 'beautiful': 184, 'man': 185, 'mean': 186, 'sat': 187, 'remember': 188, 'two': 189, 'dwarf': 190, 'began': 191, 'through': 192, 'look': 193, 'room': 194, 'bert': 195, 'those': 196, 'smoke': 197, 'looking': 198, 'river': 199, 'mind': 200, 'also': 201, 'hear': 202, 'water': 203, 'other': 204, 'course': 205, 'fact': 206, 'ever': 207, 'heard': 208, 'yes': 209, 'wizard': 210, 'hood': 211, 'balin': 212, 'supper': 213, 'much': 214, 'others': 215, 'bad': 216, 'lands': 217, 'night': 218, 'dale': 219, 'hall': 220, 'called': 221, 'same': 222, 'hand': 223, 'end': 224, 'looked': 225, 'less': 226, 'almost': 227, 'business': 228, 'hung': 229, 'want': 230, 'fellow': 231, 'already': 232, 'tea': 233, 'break': 234, 'drink': 235, 'gone': 236, 'has': 237, 'pocket': 238, 'yer': 239, 'often': 240, 'best': 241, 'large': 242, 'head': 243, 'ago': 244, 'though': 245, 'until': 246, 'own': 247, 'saw': 248, 'blue': 249, 'parts': 250, 'till': 251, 'might': 252, 'asked': 253, 'cake': 254, 'front': 255, 'dwalin': 256, 'open': 257, 'gloin': 258, 'grandfather': 259, 'cook': 260, 'mutton': 261, 'gave': 262, 'told': 263, 'king': 264, 'yet': 265, 'coming': 266, 'lived': 267, 'indeed': 268, 'name': 269, 'adventure': 270, 'saying': 271, 'suppose': 272, 'hobbits': 273, 'half': 274, 'sort': 275, 'small': 276, 'pipe': 277, 'nearly': 278, 'forgotten': 279, 'hat': 280, 'silver': 281, 'beard': 282, 'stuck': 283, 'fine': 284, 'take': 285, 'notice': 286, 'thank': 287, 'let': 288, 'liked': 289, 'give': 290, 'turned': 291, 'seen': 292, 'service': 293, 'table': 294, 'beer': 295, 'hoods': 296, 'each': 297, 'kili': 298, 'fili': 299, 'bombur': 300, 'bring': 301, 'house': 302, 'everything': 303, 'none': 304, 'wind': 305, 'suddenly': 306, 'fierce': 307, 'seemed': 308, 'bed': 309, 'trolls': 310, 'note': 311, 'friends': 312, 'set': 313, 'rings': 314, 'thrain': 315, 'son': 316, 'north': 317, 'party': 318, 'nasty': 319, 'wet': 320, 'perfectly': 321, 'whole': 322, 'because': 323, 'quietly': 324, 'especially': 325, 'across': 326, 'money': 327, 'second': 328, 'quiet': 329, 'grey': 330, 'cloak': 331, 'white': 332, 'shining': 333, 'read': 334, 'try': 335, 'lot': 336, \"haven't\": 337, 'please': 338, 'why': 339, 'outside': 340, \"hobbit's\": 341, 'bell': 342, 'rushed': 343, 'moment': 344, 'hardly': 345, 'thing': 346, 'cakes': 347, 'talking': 348, 'four': 349, 'talked': 350, 'fell': 351, 'secret': 352, 'carefully': 353, 'mat': 354, 'bifur': 355, 'bofur': 356, \"what's\": 357, 'cold': 358, 'plates': 359, 'getting': 360, 'music': 361, \"that's\": 362, 'misty': 363, 'dungeons': 364, 'caverns': 365, 'sleep': 366, 'halls': 367, 'men': 368, 'mouth': 369, 'journey': 370, 'east': 371, 'smaug': 372, 'key': 373, 'hold': 374, 'pony': 375, 'runes': 376, 'important': 377, 'true': 378, 'story': 379, 'however': 380, 'explanation': 381, 'thror': 382, 'moria': 383, 'unexpected': 384, 'dry': 385, 'sit': 386, 'means': 387, 'yellow': 388, 'opened': 389, 'tunnel': 390, 'rooms': 391, 'dining': 392, 'passage': 393, 'respectable': 394, 'doing': 395, 'altogether': 396, 'whether': 397, 'since': 398, 'magic': 399, 'except': 400, 'folk': 401, 'noise': 402, 'faces': 403, 'belladonna': 404, 'three': 405, 'built': 406, 'being': 407, 'years': 408, 'standing': 409, 'toes': 410, 'wherever': 411, 'staff': 412, 'meant': 413, 'sun': 414, 'use': 415, 'uncomfortable': 416, 'late': 417, 'begin': 418, 'move': 419, 'stood': 420, 'stick': 421, \"won't\": 422, 'dear': 423, 'themselves': 424, 'such': 425, 'goblins': 426, 'pardon': 427, 'idea': 428, 'sorry': 429, 'shut': 430, 'ask': 431, 'fright': 432, 'beginning': 433, 'remembered': 434, 'keep': 435, 'waiting': 436, 'eyes': 437, 'yours': 438, 'perhaps': 439, 'knew': 440, 'taking': 441, 'breath': 442, 'both': 443, 'really': 444, 'trying': 445, 'hands': 446, 'oin': 447, 'fat': 448, 'stopped': 449, 'feeling': 450, 'kitchen': 451, 'least': 452, 'trouble': 453, 'quick': 454, 'turning': 455, \"gandalf's\": 456, 'brought': 457, 'walking': 458, 'struck': 459, 'song': 460, 'ere': 461, 'mighty': 462, 'beneath': 463, 'moon': 464, 'wished': 465, 'jewels': 466, 'wood': 467, 'probably': 468, 'start': 469, 'sure': 470, 'wrong': 471, 'done': 472, 'usual': 473, 'usually': 474, 'tried': 475, 'ought': 476, 'deal': 477, \"can't\": 478, 'gate': 479, 'south': 480, 'killed': 481, 'worse': 482, 'nice': 483, 'inn': 484, 'ponies': 485, 'rain': 486, 'owl': 487, 'exactly': 488, \"thror's\": 489, 'matter': 490, 'chapter': 491, 'book': 492, 'part': 493, 'added': 494, 'point': 495, 'names': 496, 'show': 497, 'br': 498, 'filled': 499, 'nothing': 500, 'eat': 501, 'comfortable': 502, 'chairs': 503, 'pegs': 504, 'straight': 505, 'clothes': 506, 'floor': 507, 'beyond': 508, 'tell': 509, 'bother': 510, 'lost': 511, 'become': 512, 'beards': 513, 'quickly': 514, 'bright': 515, 'brown': 516, 'hair': 517, 'twice': 518, 'ran': 519, 'taken': 520, 'bungo': 521, \"bilbo's\": 522, 'her': 523, 'either': 524, 'queer': 525, 'chance': 526, 'apparently': 527, 'settled': 528, 'world': 529, 'enormous': 530, 'reached': 531, 'tales': 532, 'friend': 533, 'feel': 534, 'mine': 535, \"there's\": 536, 'air': 537, 'anyone': 538, 'plain': 539, 'sir': 540, \"took's\": 541, 'wandering': 542, 'luck': 543, 'evening': 544, 'believe': 545, 'elves': 546, 'life': 547, 'badly': 548, 'beg': 549, 'else': 550, 'send': 551, 'likely': 552, 'pantry': 553, 'escape': 554, 'next': 555, 'unless': 556, 'wednesday': 557, 'yesterday': 558, 'flustered': 559, 'kind': 560, 'low': 561, 'surprised': 562, 'instead': 563, 'step': 564, 'arrive': 565, 'caught': 566, 'hanging': 567, 'run': 568, 'short': 569, 'better': 570, 'seed': 571, 'fetch': 572, 'loud': 573, 'bag': 574, 'throng': 575, 'mines': 576, 'understand': 577, 'dori': 578, 'nori': 579, 'ale': 580, 'coffee': 581, 'kept': 582, 'top': 583, 'mark': 584, 'row': 585, 'pale': 586, 'mention': 587, 'thirteen': 588, 'merry': 589, 'wine': 590, 'few': 591, 'myself': 592, 'glasses': 593, 'trays': 594, 'clear': 595, 'manage': 596, 'sing': 597, 'safe': 598, 'lightning': 599, 'forgot': 600, 'window': 601, 'played': 602, 'ringing': 603, 'bells': 604, 'lay': 605, 'laid': 606, 'sang': 607, 'felt': 608, 'above': 609, 'lamp': 610, 'speak': 611, 'shall': 612, 'known': 613, 'drawing': 614, 'hundred': 615, 'crept': 616, 'excitement': 617, 'fool': 618, 'walked': 619, 'job': 620, \"let's\": 621, 'chosen': 622, 'live': 623, 'rather': 624, 'maps': 625, 'everybody': 626, 'says': 627, 'barrel': 628, 'neck': 629, 'running': 630, 'valley': 631, 'warriors': 632, 'mostly': 633, \"didn't\": 634, 'professional': 635, 'expenses': 636, 'food': 637, 'work': 638, 'always': 639, 'woods': 640, 'proper': 641, 'handing': 642, 'early': 643, 'sitting': 644, 'company': 645, 'hills': 646, 'camp': 647, 'tree': 648, \"trolls'\": 649, 'tom': 650, 'several': 651, 'rune': 652, 'five': 653, 'game': 654, 'given': 655, 'place': 656, 'edition': 657, 'lore': 658, 'need': 659, 'its': 660, 'lord': 661, 'written': 662, 'repeated': 663, 'distant': 664, 'ancestor': 665, 'discovered': 666, 'moved': 667, 'ground': 668, 'worms': 669, 'smell': 670, 'comfort': 671, 'painted': 672, 'brass': 673, 'knob': 674, 'exact': 675, 'middle': 676, 'shaped': 677, 'coats': 678, 'fond': 679, 'visitors': 680, 'miles': 681, 'doors': 682, 'cellars': 683, 'pantries': 684, 'windows': 685, 'bagginses': 686, 'neighbourhood': 687, 'rich': 688, 'question': 689, 'gained': 690, 'mother': 691, 'call': 692, 'height': 693, 'smaller': 694, 'ordinary': 695, 'elephants': 696, 'mile': 697, 'wear': 698, 'grow': 699, 'thick': 700, 'warm': 701, 'fingers': 702, 'dinner': 703, 'remarkable': 704, 'foot': 705, 'absurd': 706, 'certainly': 707, 'family': 708, 'remained': 709, 'undoubtedly': 710, 'she': 711, 'became': 712, 'arrived': 713, 'curious': 714, 'smoking': 715, 'wooden': 716, 'fashion': 717, 'ages': 718, 'died': 719, 'tall': 720, 'bushy': 721, 'eyebrows': 722, 'further': 723, 'wish': 724, 'tobacco': 725, 'fill': 726, 'hurry': 727, 'legs': 728, 'blew': 729, 'sailed': 730, 'pretty': 731, 'someone': 732, \"it's\": 733, 'difficult': 734, 'disturbing': 735, 'decided': 736, 'leaning': 737, 'fastened': 738, 'ordered': 739, 'sons': 740, 'excellent': 741, 'fireworks': 742, 'splendid': 743, 'sailing': 744, 'bless': 745, 'upon': 746, 'pleased': 747, 'seem': 748, 'kindly': 749, 'rate': 750, 'hope': 751, 'sake': 752, 'today': 753, 'tomorrow': 754, 'wizards': 755, 'fast': 756, 'laughing': 757, 'sign': 758, 'kettle': 759, 'golden': 760, 'pushed': 761, 'bow': 762, 'questions': 763, 'pray': 764, 'louder': 765, 'excuse': 766, 'hopped': 767, 'begun': 768, 'cellar': 769, 'certain': 770, 'puffed': 771, 'belts': 772, 'carried': 773, 'tools': 774, 'swept': 775, 'join': 776, 'sound': 777, 'collect': 778, 'wits': 779, 'corner': 780, 'sounded': 781, 'adventurous': 782, \"'\": 783, 'rang': 784, 'boy': 785, 'pull': 786, 'handle': 787, 'blinking': 788, 'wondered': 789, 'happened': 790, 'stay': 791, 'wondering': 792, 'ori': 793, 'busy': 794, 'jug': 795, 'hearth': 796, 'starting': 797, 'somebody': 798, 'knocked': 799, 'pop': 800, 'sky': 801, 'flat': 802, 'immensely': 803, 'heavy': 804, 'pie': 805, 'eggs': 806, 'seems': 807, 'flummoxed': 808, 'wonder': 809, 'wretched': 810, 'bottles': 811, 'knives': 812, 'forks': 813, 'piled': 814, 'annoyed': 815, 'aloud': 816, 'lend': 817, 'parlour': 818, 'stool': 819, 'ate': 820, 'jumped': 821, 'piles': 822, 'careful': 823, 'blunt': 824, 'hates': 825, 'cut': 826, 'cloth': 827, 'pour': 828, 'bedroom': 829, 'every': 830, 'crocks': 831, 'thumping': 832, \"you've\": 833, 'finished': 834, 'fender': 835, 'clock': 836, 'sent': 837, \"thorin's\": 838, 'dim': 839, 'strange': 840, 'loved': 841, 'bags': 842, 'somewhere': 843, 'among': 844, 'harp': 845, 'april': 846, 'shadow': 847, 'shadows': 848, 'singing': 849, 'places': 850, 'ancient': 851, 'hide': 852, 'sword': 853, 'stars': 854, 'harps': 855, 'winds': 856, 'spread': 857, 'torches': 858, 'fall': 859, 'grim': 860, 'love': 861, 'woke': 862, 'pine': 863, 'caves': 864, 'flame': 865, 'pretend': 866, 'hours': 867, 'knocking': 868, 'together': 869, 'conspirator': 870, 'audacious': 871, 'remark': 872, 'plans': 873, 'ways': 874, 'return': 875, 'interrupted': 876, \"couldn't\": 877, 'longer': 878, 'shriek': 879, 'whistle': 880, 'shaking': 881, 'calling': 882, 'elbow': 883, 'funny': 884, 'pinch': 885, 'granduncle': 886, 'bullroarer': 887, 'horse': 888, 'battle': 889, 'rabbit': 890, 'won': 891, 'talk': 892, 'wake': 893, 'bobbing': 894, 'doubts': 895, 'afterwards': 896, 'signs': 897, 'walk': 898, 'fight': 899, 'wild': 900, '—': 901, 'plenty': 902, 'reward': 903, 'expert': 904, 'treasure': 905, 'arranged': 906, 'fourteenth': 907, 'chose': 908, 'stop': 909, 'comes': 910, 'guess': 911, 'piece': 912, \"dwarves'\": 913, 'excited': 914, 'help': 915, 'marked': 916, 'hidden': 917, 'size': 918, 'squeaked': 919, 'country': 920, \"isn't\": 921, 'handed': 922, 'chain': 923, 'lake': 924, 'town': 925, 'changed': 926, 'fighting': 927, 'scarce': 928, 'simply': 929, 'legendary': 930, 'putting': 931, 'alive': 932, 'wealth': 933, 'anyway': 934, 'grew': 935, \"grandfather's\": 936, 'full': 937, 'armour': 938, 'market': 939, 'flying': 940, 'specially': 941, 'wicked': 942, 'creaking': 943, 'escaped': 944, 'fog': 945, 'carry': 946, 'home': 947, 'paper': 948, 'explain': 949, 'near': 950, 'necromancer': 951, 'whatever': 952, 'towards': 953, \"'em\": 954, 'spare': 955, 'tired': 956, 'wearing': 957, 'dreams': 958, 'unwashed': 959, 'washing': 960, 'thinking': 961, 'washed': 962, 'having': 963, 'past': 964, 'ten': 965, 'message': 966, 'dusted': 967, 'fourteen': 968, 'bywater': 969, 'leaves': 970, 'but—': 971, 'furry': 972, 'handkerchief': 973, 'road': 974, 'village': 975, \"i'm\": 976, 'precise': 977, 'handkerchiefs': 978, 'jogging': 979, 'weather': 980, 'songs': 981, 'meals': 982, 'passed': 983, 'roads': 984, 'lone': 985, 'ahead': 986, 'higher': 987, 'turn': 988, 'burgling': 989, 'clouds': 990, 'between': 991, 'shook': 992, 'drip': 993, 'mischief': 994, 'seldom': 995, 'hoot': 996, 'pride': 997, 'toasting': 998, 'spite': 999, 'blimey': 1000, 'et': 1001, \"d'yer\": 1002, 'picked': 1003, 'pockets': 1004, 'picking': 1005, \"william's\": 1006, 'new': 1007, \"i've\": 1008, 'burrahobbit': 1009, 'blighter': 1010, \"you're\": 1011, 'special': 1012, 'reprint': 1013, 'minor': 1014, 'inaccuracies': 1015, 'noted': 1016, 'readers': 1017, 'corrected': 1018, 'example': 1019, 'text': 1020, 'corresponds': 1021, 'ending': 1022, 'riddle': 1023, 'eventually': 1024, 'revealed': 1025, 'pressure': 1026, 'according': 1027, 'version': 1028, 'actually': 1029, 'diary': 1030, 'departure': 1031, 'truth': 1032, 'honest': 1033, 'portent': 1034, 'significance': 1035, 'does': 1036, 'concern': 1037, 'present': 1038, 'acquaintance': 1039, 'troupe': 1040, 'lies': 1041, 'history': 1042, 'chronicles': 1043, 'westmarch': 1044, 'final': 1045, 'raised': 1046, 'students': 1047, 'period': 1048, 'error': 1049, 'dynasties': 1050, 'genealogies': 1051, 'referred': 1052, 'fugitive': 1053, 'lonely': 1054, 'erebor': 1055, 'ruled': 1056, 'remoter': 1057, 'dirty': 1058, 'ends': 1059, 'oozy': 1060, 'nor': 1061, 'bare': 1062, 'sandy': 1063, 'porthole': 1064, 'shiny': 1065, 'tube': 1066, 'panelled': 1067, 'walls': 1068, 'floors': 1069, 'tiled': 1070, 'carpeted': 1071, 'provided': 1072, 'polished': 1073, 'hats': 1074, 'wound': 1075, 'fairly': 1076, 'upstairs': 1077, 'bedrooms': 1078, 'bathrooms': 1079, 'wardrobes': 1080, 'devoted': 1081, 'kitchens': 1082, 'ones': 1083, 'garden': 1084, 'meadows': 1085, 'sloping': 1086, 'considered': 1087, 'asking': 1088, \"neighbours'\": 1089, 'respect': 1090, 'particular': 1091, '…': 1092, 'description': 1093, 'nowadays': 1094, 'rare': 1095, 'shy': 1096, 'bearded': 1097, 'everyday': 1098, 'helps': 1099, 'disappear': 1100, 'stupid': 1101, 'blundering': 1102, 'making': 1103, 'inclined': 1104, 'stomach': 1105, 'dress': 1106, 'colours': 1107, 'chiefly': 1108, 'shoes': 1109, 'natural': 1110, 'leathery': 1111, 'soles': 1112, 'stuff': 1113, 'heads': 1114, 'curly': 1115, 'clever': 1116, 'natured': 1117, 'laugh': 1118, 'fruity': 1119, 'laughs': 1120, 'fabulous': 1121, 'daughters': 1122, 'families': 1123, 'ancestors': 1124, 'fairy': 1125, 'wife': 1126, 'entirely': 1127, 'members': 1128, 'clan': 1129, 'discreetly': 1130, 'disappeared': 1131, 'hushed': 1132, 'tooks': 1133, 'richer': 1134, 'mrs': 1135, 'luxurious': 1136, 'partly': 1137, 'probable': 1138, 'although': 1139, 'behaved': 1140, 'solid': 1141, 'makeup': 1142, 'waited': 1143, 'grown': 1144, 'fifty': 1145, 'living': 1146, 'described': 1147, 'immovably': 1148, 'numerous': 1149, 'prosperous': 1150, 'woolly': 1151, 'neatly': 1152, 'brushed': 1153, 'quarter': 1154, 'prepared': 1155, 'tale': 1156, 'sprouted': 1157, 'extraordinary': 1158, 'boys': 1159, 'girls': 1160, 'unsuspecting': 1161, 'pointed': 1162, 'scarf': 1163, 'below': 1164, 'waist': 1165, 'immense': 1166, 'black': 1167, 'boots': 1168, 'grass': 1169, 'brim': 1170, 'shady': 1171, 'bargain': 1172, 'seat': 1173, 'crossed': 1174, 'breaking': 1175, 'floated': 1176, 'blow': 1177, 'share': 1178, 'arranging': 1179, '«i': 1180, 'can’t': 1181, 'anybody': 1182, 'sees': 1183, '»': 1184, 'thumb': 1185, 'braces': 1186, 'bigger': 1187, 'letters': 1188, 'pretending': 1189, 'wanted': 1190, 'gazing': 1191, 'cross': 1192, 'conversation': 1193, 'rid': 1194, 'belong': 1195, 'morninged': 1196, 'selling': 1197, 'buttons': 1198, 'gracious': 1199, 'pair': 1200, 'diamond': 1201, 'studs': 1202, 'undone': 1203, 'wonderful': 1204, 'parties': 1205, 'giants': 1206, 'rescue': 1207, 'princesses': 1208, \"widows'\": 1209, 'particularly': 1210, \"midsummer's\": 1211, 'eve': 1212, 'lilies': 1213, 'snapdragons': 1214, 'laburnums': 1215, 'hang': 1216, 'twilight': 1217, 'prosy': 1218, 'flowers': 1219, 'responsible': 1220, 'lads': 1221, 'lasses': 1222, 'mad': 1223, 'climbing': 1224, 'visiting': 1225, 'ships': 1226, 'shores': 1227, 'inter': 1228, 'upset': 1229, 'land': 1230, 'grand': 1231, 'amusing': 1232, 'profitable': 1233, 'bye': 1234, 'scuttled': 1235, 'dared': 1236, 'rude': 1237, 'earth': 1238, 'self': 1239, 'meantime': 1240, 'stepped': 1241, 'spike': 1242, 'scratched': 1243, 'strode': 1244, 'finishing': 1245, 'engagement': 1246, 'tablet': 1247, '’¥a': 1248, 'tremendous': 1249, 'cup': 1250, 'saucer': 1251, 'extra': 1252, 'tucked': 1253, 'belt': 1254, 'expected': 1255, 'hooded': 1256, 'nearest': 1257, 'peg': 1258, 'silence': 1259, 'followed': 1260, 'stiff': 1261, 'uninvited': 1262, 'word': 1263, 'third': 1264, 'scarlet': 1265, 'invited': 1266, 'sight': 1267, \"dwalin's\": 1268, 'breast': 1269, 'gasp': 1270, 'correct': 1271, 'preferred': 1272, 'horrible': 1273, 'host': 1274, 'duty': 1275, 'painful': 1276, 'managed': 1277, 'suit': 1278, 'answering': 1279, 'surprise': 1280, 'scuttling': 1281, 'pint': 1282, 'mug': 1283, 'baked': 1284, 'afternoon': 1285, 'morsel': 1286, 'brothers': 1287, 'plumped': 1288, 'spade': 1289, 'bowed': 1290, \"family's\": 1291, 'replied': 1292, 'remembering': 1293, 'manners': 1294, 'minute': 1295, 'sip': 1296, 'around': 1297, 'troubles': 1298, 'depredations': 1299, 'ding': 1300, 'dong': 1301, 'ling': 1302, 'dang': 1303, 'naughty': 1304, 'sides': 1305, 'distance': 1306, 'happen': 1307, 't': 1308, 'x': 1309, 're': 1310, 'bowing': 1311, 'purple': 1312, 'marched': 1313, 'broad': 1314, 'porter': 1315, 'buttered': 1316, 'scones': 1317, 'knock': 1318, 'hard': 1319, 'rat': 1320, 'tat': 1321, 'banging': 1322, 'angry': 1323, 'bewildered': 1324, 'bewuthered': 1325, 'awkward': 1326, 'pulled': 1327, 'jerk': 1328, 'dent': 1329, 'gun': 1330, 'introduce': 1331, 'tassel': 1332, 'belonged': 1333, 'enormously': 1334, 'oakenshield': 1335, 'falling': 1336, 'haughty': 1337, 'times': 1338, 'grunted': 1339, 'frowning': 1340, 'detachable': 1341, 'gathering': 1342, 'comers': 1343, 'raspberry': 1344, 'jam': 1345, 'apple': 1346, 'tart': 1347, 'mince': 1348, 'pies': 1349, 'cheese': 1350, 'pork': 1351, 'salad': 1352, 'stumped': 1353, 'chicken': 1354, 'pickles': 1355, 'larders': 1356, 'positively': 1357, 'dishes': 1358, 'spoons': 1359, 'hot': 1360, 'face': 1361, 'confusticate': 1362, 'bebother': 1363, 'lo': 1364, 'behold': 1365, 'knife': 1366, 'whisked': 1367, 'couple': 1368, 'tables': 1369, 'afresh': 1370, 'fireside': 1371, 'nibbling': 1372, 'biscuit': 1373, 'appetite': 1374, 'politest': 1375, 'unpressing': 1376, 'tones': 1377, \"shan't\": 1378, 'thereupon': 1379, 'twelve': 1380, 'stayed': 1381, 'balancing': 1382, 'columns': 1383, 'bottle': 1384, 'squeaking': 1385, 'started': 1386, 'chip': 1387, 'crack': 1388, 'bend': 1389, 'smash': 1390, 'burn': 1391, 'corks': 1392, 'tread': 1393, 'milk': 1394, 'leave': 1395, 'bones': 1396, 'splash': 1397, 'dump': 1398, 'boiling': 1399, 'bawl': 1400, 'pound': 1401, 'pole': 1402, 'roll': 1403, 'dreadful': 1404, 'cleaned': 1405, 'blowing': 1406, 'chimney': 1407, 'telpiece': 1408, 'ceiling': 1409, 'clay': 1410, 'hover': 1411, \"wizard's\": 1412, 'cloud': 1413, 'sorcerous': 1414, 'watched': 1415, 'blushed': 1416, 'proud': 1417, 'instruments': 1418, 'fiddles': 1419, 'flutes': 1420, 'produced': 1421, 'drum': 1422, 'clarinets': 1423, 'sticks': 1424, 'porch': 1425, 'viols': 1426, 'thorin’s': 1427, 'wrapped': 1428, 'en': 1429, 'sudden': 1430, 'sweet': 1431, 'moons': 1432, 'firelight': 1433, 'flickered': 1434, 'wagged': 1435, 'against': 1436, 'wall': 1437, 'throated': 1438, 'homes': 1439, 'fragment': 1440, 'seek': 1441, 'enchanted': 1442, 'yore': 1443, 'spells': 1444, 'hammers': 1445, 'hollow': 1446, 'fells': 1447, 'elvish': 1448, 'gloaming': 1449, 'hoard': 1450, 'wrought': 1451, 'gems': 1452, 'hilt': 1453, 'necklaces': 1454, 'strung': 1455, 'flowering': 1456, 'crowns': 1457, 'twisted': 1458, 'wire': 1459, 'meshed': 1460, 'claim': 1461, 'goblets': 1462, 'carved': 1463, 'delves': 1464, 'sung': 1465, 'unheard': 1466, 'pines': 1467, 'roaring': 1468, 'moaning': 1469, 'flaming': 1470, 'biased': 1471, \"dragon's\": 1472, 'ire': 1473, 'towers': 1474, 'houses': 1475, 'frail': 1476, 'smoked': 1477, 'tramp': 1478, 'doom': 1479, 'fled': 1480, 'dying': 1481, 'win': 1482, 'cunning': 1483, 'moving': 1484, 'jealous': 1485, 'desire': 1486, 'hearts': 1487, 'tookish': 1488, 'waterfalls': 1489, 'explore': 1490, 'leapt': 1491, 'lighting': 1492, 'plundering': 1493, 'settling': 1494, 'kindling': 1495, 'flames': 1496, 'shuddered': 1497, 'trembling': 1498, 'barrels': 1499, 'tone': 1500, 'guessed': 1501, 'halves': 1502, 'apologetically': 1503, 'dawn': 1504, 'missed': 1505, 'poker': 1506, 'shovel': 1507, 'crash': 1508, 'hush': 1509, 'praise': 1510, 'paused': 1511, 'polite': 1512, 'hob': 1513, 'compliments': 1514, 'wagging': 1515, 'protest': 1516, 'worst': 1517, 'met': 1518, 'discuss': 1519, 'policy': 1520, 'devices': 1521, 'counsellor': 1522, 'ingenious': 1523, 'solemn': 1524, 'object': 1525, 'estimable': 1526, 'younger': 1527, 'naming': 1528, 'instance': 1529, 'situation': 1530, 'require': 1531, 'brief': 1532, 'style': 1533, 'allowed': 1534, 'telling': 1535, \"'anything\": 1536, 'rudely': 1537, 'bear': 1538, 'burst': 1539, 'engine': 1540, 'sprang': 1541, 'bp': 1542, 'firework': 1543, 'glare': 1544, 'kneeling': 1545, 'rug': 1546, 'jelly': 1547, 'melting': 1548, 'sofa': 1549, 'excitable': 1550, 'gets': 1551, 'fits': 1552, 'realize': 1553, 'poetical': 1554, 'exaggeration': 1555, 'applied': 1556, 'huge': 1557, 'ride': 1558, 'charged': 1559, 'ranks': 1560, 'mount': 1561, 'gram': 1562, 'fields': 1563, 'gol': 1564, \"firnbul's\": 1565, 'clean': 1566, 'club': 1567, 'yards': 1568, 'golf': 1569, 'invented': 1570, 'meanwhile': 1571, \"bullroarer's\": 1572, 'gentler': 1573, 'descendant': 1574, 'reviving': 1575, 'nervously': 1576, 'speaking': 1577, 'humph': 1578, 'snort': 1579, 'relatives': 1580, 'kill': 1581, 'clapped': 1582, 'puffing': 1583, 'looks': 1584, 'grocer': 1585, 'regretted': 1586, 'overheard': 1587, 'words': 1588, 'reference': 1589, 'burglars': 1590, 'believing': 1591, 'dignity': 1592, 'week': 1593, 'treat': 1594, 'desert': 1595, 'assure': 1596, 'trade': 1597, 'wants': 1598, 'reasonable': 1599, 'hunter': 1600, 'meeting': 1601, 'reasons': 1602, 'expedition': 1603, 'digging': 1604, 'coal': 1605, 'scowled': 1606, 'angrily': 1607, 'huddled': 1608, 'chair': 1609, 'frowned': 1610, 'oat': 1611, 'tight': 1612, 'snap': 1613, 'argument': 1614, '6te': 1615, 'possibly': 1616, 'shad': 1617, 'parchment': 1618, 'answer': 1619, 'plan': 1620, 'disappointedly': 1621, 'glance': 1622, 'mirkwood': 1623, 'withered': 1624, 'heath': 1625, 'bred': 1626, 'easy': 1627, 'noticed': 1628, 'entrance': 1629, 'west': 1630, 'pointing': 1631, 'marks': 1632, 'lower': 1633, \"'five\": 1634, 'high': 1635, \"abreast'\": 1636, 'creep': 1637, 'young': 1638, 'devouring': 1639, 'experience': 1640, 'holes': 1641, 'interested': 1642, 'favourite': 1643, 'walks': 1644, 'ink': 1645, 'apart': 1646, 'closed': 1647, 'method': 1648, 'intricate': 1649, 'wards': 1650, 'jacket': 1651, 'hopeful': 1652, 'news': 1653, 'alters': 1654, 'loads': 1655, 'ruins': 1656, 'runs': 1657, 'cliff': 1658, 'warrior': 1659, 'hero': 1660, 'heroes': 1661, 'swords': 1662, 'axes': 1663, 'shields': 1664, 'cradles': 1665, 'dish': 1666, 'covers': 1667, 'comfortably': 1668, 'therefore': 1669, 'burglary': 1670, 'existence': 1671, 'selected': 1672, 'supposing': 1673, 'gives': 1674, 'ideas': 1675, 'suggestions': 1676, 'mock': 1677, 'politeness': 1678, 'confused': 1679, 'shaky': 1680, 'lookishly': 1681, 'determined': 1682, 'belongs': 1683, 'obstinately': 1684, 'manner': 1685, 'reserved': 1686, 'borrow': 1687, 'appear': 1688, 'wise': 1689, 'prudent': 1690, 'recommendation': 1691, 'risks': 1692, 'required': 1693, 'remuneration': 1694, 'forth': 1695, 'o': 1696, 'driven': 1697, 'mined': 1698, 'tunnelled': 1699, 'huger': 1700, 'greater': 1701, 'workshops': 1702, 'addition': 1703, 'famous': 1704, 'treated': 1705, 'reverence': 1706, 'mortal': 1707, 'gradually': 1708, 'spreading': 1709, 'overshadowed': 1710, 'kings': 1711, 'smiths': 1712, 'skilful': 1713, 'richly': 1714, 'fathers': 1715, 'apprentices': 1716, 'pay': 1717, 'handsomely': 1718, 'supplies': 1719, 'bothered': 1720, 'ourselves': 1721, 'poorest': 1722, 'spend': 1723, 'leisure': 1724, 'fun': 1725, 'marvellous': 1726, 'magical': 1727, 'toys': 1728, 'carvings': 1729, 'cups': 1730, 'toy': 1731, 'steal': 1732, 'guard': 1733, 'plunder': 1734, 'practically': 1735, 'forever': 1736, 'enjoy': 1737, 'notion': 1738, 'current': 1739, 'value': 1740, 'mend': 1741, 'loose': 1742, 'scale': 1743, 'general': 1744, 'waste': 1745, 'destruction': 1746, 'greedy': 1747, 'strong': 1748, 'worm': 1749, 'flew': 1750, 'hurricane': 1751, 'cracking': 1752, 'luckily': 1753, 'lad': 1754, 'saved': 1755, 'settle': 1756, 'spout': 1757, 'slopes': 1758, 'arming': 1759, 'steam': 1760, 'destroyed': 1761, 'unhappy': 1762, 'common': 1763, 'routed': 1764, 'lanes': 1765, 'tunnels': 1766, 'alleys': 1767, 'mansions': 1768, 'passages': 1769, \"dragons'\": 1770, 'heap': 1771, 'sleeps': 1772, 'later': 1773, 'crawl': 1774, 'maidens': 1775, 'ruined': 1776, 'dead': 1777, 'goes': 1778, 'lives': 1779, 'nearer': 1780, 'edge': 1781, 'wept': 1782, 'hiding': 1783, 'cursed': 1784, 'unexpectedly': 1785, 'joined': 1786, 'singed': 1787, 'tongue': 1788, 'earn': 1789, 'livings': 1790, 'sinking': 1791, 'blacksmith': 1792, 'coalmining': 1793, 'stolen': 1794, 'allow': 1795, 'stroked': 1796, 'curses': 1797, \"father's\": 1798, 'private': 1799, 'rightful': 1800, 'heir': 1801, \"'get\": 1802, 'azog': 1803, 'goblin': 1804, 'curse': 1805, 'twenty': 1806, 'thursday': 1807, 'since—': 1808, 'blame': 1809, 'considering': 1810, 'praised': 1811, 'thanked': 1812, 'slowly': 1813, 'grimly': 1814, 'safety': 1815, 'unpleasant': 1816, 'prisoner': 1817, 'shudder': 1818, 'shivered': 1819, 'finding': 1820, 'dangerous': 1821, 'save': 1822, 'witless': 1823, 'paid': 1824, 'enemy': 1825, 'powers': 1826, 'collected': 1827, 'corners': 1828, 'tasks': 1829, 'accidentally': 1830, 'answered': 1831, 'sometimes': 1832, 'doorstep': 1833, 'daresay': 1834, \"aren't\": 1835, 'agree': 1836, 'ham': 1837, 'fried': 1838, 'poached': 1839, 'breakfasts': 1840, 'beds': 1841, 'sofas': 1842, 'stowed': 1843, 'happy': 1844, \"else's\": 1845, 'tookishness': 1846, 'humming': 1847, 'ears': 1848, '2': 1849, 'roast': 1850, 'dressing': 1851, 'gown': 1852, 'nobody': 1853, 'hurried': 1854, 'fearful': 1855, 'mess': 1856, 'pot': 1857, 'pan': 1858, 'possessed': 1859, 'dismally': 1860, 'real': 1861, 'forced': 1862, 'hoped': 1863, 'relieved': 1864, 'bothering': 1865, 'trifle': 1866, 'disappointed': 1867, 'outlandish': 1868, 'nonsense': 1869, 'age': 1870, 'apron': 1871, 'lit': 1872, 'fires': 1873, 'boiled': 1874, 'letting': 1875, 'spring': 1876, 'breeze': 1877, 'loudly': 1878, 'forget': 1879, 'whenever': 1880, 'wait': 1881, 'fluster': 1882, 'yourself': 1883, 'mantel': 1884, 'mantelpiece': 1885, 'greeting': 1886, 'hospitality': 1887, 'sincerest': 1888, 'thanks': 1889, 'offer': 1890, 'assistance': 1891, 'grateful': 1892, 'acceptance': 1893, 'terms': 1894, 'cash': 1895, 'delivery': 1896, 'exceeding': 1897, 'total': 1898, 'profits': 1899, 'traveling': 1900, 'guaranteed': 1901, 'event': 1902, 'funeral': 1903, 'defrayed': 1904, 'representatives': 1905, 'occasion': 1906, 'arises': 1907, 'otherwise': 1908, 'unnecessary': 1909, 'disturb': 1910, 'esteemed': 1911, 'repose': 1912, 'proceeded': 1913, 'advance': 1914, 'requisite': 1915, 'preparations': 1916, 'await': 1917, 'respected': 1918, 'person': 1919, 'ii': 1920, 'm': 1921, 'sharp': 1922, 'trusting': 1923, 'punctual': 1924, 'honour': 1925, 'remain': 1926, 'deeply': 1927, 'co': 1928, 'minutes': 1929, 'leaving': 1930, 'pushing': 1931, 'keys': 1932, 'lane': 1933, 'mill': 1934, 'stroke': 1935, 'eleven': 1936, 'bravo': 1937, 'slung': 1938, 'kinds': 1939, 'baggages': 1940, 'packages': 1941, 'parcels': 1942, 'paraphernalia': 1943, 'awfully': 1944, '10': 1945, '45': 1946, 'worry': 1947, \"journey's\": 1948, 'luggage': 1949, 'laden': 1950, 'stained': 1951, 'borrowed': 1952, 'comic': 1953, \"daren't\": 1954, 'mistaken': 1955, 'riding': 1956, 'merrily': 1957, 'stories': 1958, 'rode': 1959, 'forward': 1960, 'inhabited': 1961, 'decent': 1962, 'farmer': 1963, 'ambling': 1964, 'spoke': 1965, 'strangely': 1966, 'inns': 1967, 'steadily': 1968, 'dreary': 1969, 'rising': 1970, 'castles': 1971, 'evil': 1972, 'gloomy': 1973, 'june': 1974, 'grumbled': 1975, 'splashed': 1976, 'muddy': 1977, 'track': 1978, 'pouring': 1979, 'dripping': 1980, 'stumbled': 1981, 'stones': 1982, 'grumpy': 1983, 'jogged': 1984, 'willows': 1985, 'bank': 1986, 'bent': 1987, 'sighed': 1988, 'rushing': 1989, 'swollen': 1990, 'rains': 1991, 'broke': 1992, 'waning': 1993, 'appeared': 1994, 'rags': 1995, 'muttered': 1996, 'patch': 1997, 'missing': 1998, 'merely': 1999, 'keeping': 2000, 'eaten': 2001, 'laughed': 2002, 'useful': 2003, 'groaned': 2004, 'shared': 2005, 'views': 2006, 'regular': 2007, 'camped': 2008, 'regularly': 2009, 'clump': 2010, 'drier': 2011, 'annoying': 2012, 'anywhere': 2013, 'bolted': 2014, 'catch': 2015, 'drowned': 2016, 'baggage': 2017, 'glum': 2018, 'muttering': 2019, 'quarrelling': 2020, 'sadly': 2021, 'reflecting': 2022, 'rides': 2023, 'sunshine': 2024, 'mass': 2025, 'reddish': 2026, 'twinkling': 2027, 'arguing': 2028, 'travellers': 2029, 'unguarded': 2030, 'inquisitive': 2031, 'leading': 2032, 'due': 2033, 'caution': 2034, 'direction': 2035, 'path': 2036, 'lead': 2037, 'farm': 2038, 'rustling': 2039, 'crackling': 2040, 'grumbling': 2041, 'drafting': 2042, 'pitch': 2043, 'shone': 2044, 'trunks': 2045, \"burglar's\": 2046, 'meaning': 2047, 'canny': 2048, 'scuttle': 2049, 'barn': 2050, 'screech': 2051, 'fly': 2052, 'bat': 2053, 'absolutely': 2054, 'sniffed': 2055, 'dwarvish': 2056, 'racket': 2057, 'sup': 2058, 'pose': 2059, 'windy': 2060, 'cavalcade': 2061, 'primly': 2062, 'weasel': 2063, 'stirred': 2064, 'whisker': 2065, 'naturally': 2066, 'persons': 2067, 'beech': 2068, 'logs': 2069, 'spits': 2070, 'licking': 2071, 'gravy': 2072, 'toothsome': 2073, 'drinking': 2074, 'jugs': 2075, 'obviously': 2076, 'sheltered': 2077, 'shape': 2078, 'language': 2079, 'tomorrer': 2080, 'manflesh': 2081, \"'ell\": 2082, \"thinkin'\": 2083, 'beats': 2084, \"runnin'\": 2085, 'choked': 2086, 'expect': 2087, \"time's\": 2088, \"yer'd\": 2089, \"'thank\": 2090, \"bill'\": 2091, \"o'\": 2092, 'bite': 2093, \"sheep's\": 2094, 'leg': 2095, 'wiped': 2096, 'lips': 2097, 'sleeve': 2098, 'afraid': 2099, 'behave': 2100, 'hearing': 2101, 'warned': 2102, 'fair': 2103, 'sized': 2104, 'mood': 2105, 'toasted': 2106, 'change': 2107, 'class': 2108, 'worthwhile': 2109, 'pinched': 2110, 'purloined': 2111, 'noticing': 2112, 'practical': 2113, 'dagger': 2114, 'observed': 2115, 'spent': 2116, 'cheerily': 2117, 'alarmed': 2118, 'disgusted': 2119, 'somehow': 2120, 'empty': 2121, 'hesitated': 2122, 'various': 2123, 'burglarious': 2124, 'proceedings': 2125, 'plucked': 2126, 'courage': 2127, 'purse': 2128, 'ha': 2129, 'warming': 2130, 'lifted': 2131, 'purses': 2132, 'exception': 2133, \"'ere\": 2134, \"'oo\": 2135, 'grabbed': 2136, 'duck': 2137, 'copped': 2138, 'lumme': 2139, 'knows': 2140, 'bur—': 2141, 'noises': 2142, 'throttled': 2143, 'startled': 2144, 'slow': 2145, 'uptake': 2146, 'suspicious': 2147, 'anyways': 2148, 'skewer': 2149, \"wouldn't\": 2150, 'mouthful': 2151, 'skinned': 2152, 'boned': 2153, \"p'raps\": 2154, \"sneakin'\": 2155, 'nassty': 2156, 'immediately': 2157, 'holding': 2158, 'gasping': 2159, 'sirs': 2160, 'bet': 2161, 'ter': 2162, \"i'll\": 2163, 'beautifully': 2164, 'throat': 2165, 'talks': 2166, 'afore': 2167, 'lout': 2168, 'bill': 2169, 'huggins': 2170, 'puts': 2171, 'fist': 2172, 'eye': 2173, 'gorgeous': 2174, 'dropped': 2175, 'scramble': 2176, 'dogs': 2177, 'sorts': 2178, 'applicable': 2179, 'voices': 2180, 'locked': 2181, \"another's\": 2182, 'arms': 2183, 'rolling': 2184, 'kicking': 2185, 'whacked': 2186, 'branch': 2187, 'senses': 2188, 'madder': 2189, 'squashed': 2190, \"bert's\": 2191, 'paw': 2192, 'body': 2193}\n",
            "2194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWVCQ7P8D_TW",
        "outputId": "15b863d9-53fa-4c50-d9a2-d47d4cd1eda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame([tokenizer.word_index])\n",
        "words=df.columns\n",
        "words"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['the', 'and', 'a', 'to', 'of', 'he', 'in', 'was', 'i', 'it',\n",
              "       ...\n",
              "       'rolling', 'kicking', 'whacked', 'branch', 'senses', 'madder',\n",
              "       'squashed', 'bert's', 'paw', 'body'],\n",
              "      dtype='object', length=2193)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIte-K73qjEf",
        "outputId": "ac581866-4882-4468-bcf4-24a7b931478e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(words))\n",
        "print ('{} unique characters'.format(len(vocab)))\n",
        "vocab"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2193 unique characters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'\",\n",
              " \"'anything\",\n",
              " \"'ell\",\n",
              " \"'em\",\n",
              " \"'ere\",\n",
              " \"'five\",\n",
              " \"'get\",\n",
              " \"'oo\",\n",
              " \"'thank\",\n",
              " '10',\n",
              " '2',\n",
              " '45',\n",
              " '6te',\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " \"abreast'\",\n",
              " 'absolutely',\n",
              " 'absurd',\n",
              " 'acceptance',\n",
              " 'accidentally',\n",
              " 'according',\n",
              " 'acquaintance',\n",
              " 'across',\n",
              " 'actually',\n",
              " 'added',\n",
              " 'addition',\n",
              " 'advance',\n",
              " 'adventure',\n",
              " 'adventures',\n",
              " 'adventurous',\n",
              " 'afore',\n",
              " 'afraid',\n",
              " 'afresh',\n",
              " 'after',\n",
              " 'afternoon',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'age',\n",
              " 'ages',\n",
              " 'ago',\n",
              " 'agree',\n",
              " 'ahead',\n",
              " 'air',\n",
              " 'alarmed',\n",
              " 'ale',\n",
              " 'alive',\n",
              " 'all',\n",
              " 'alleys',\n",
              " 'allow',\n",
              " 'allowed',\n",
              " 'almost',\n",
              " 'along',\n",
              " 'aloud',\n",
              " 'already',\n",
              " 'also',\n",
              " 'alters',\n",
              " 'although',\n",
              " 'altogether',\n",
              " 'always',\n",
              " 'am',\n",
              " 'ambling',\n",
              " 'among',\n",
              " 'amusing',\n",
              " 'an',\n",
              " 'ancestor',\n",
              " 'ancestors',\n",
              " 'ancient',\n",
              " 'and',\n",
              " 'angrily',\n",
              " 'angry',\n",
              " 'annoyed',\n",
              " 'annoying',\n",
              " 'another',\n",
              " \"another's\",\n",
              " 'answer',\n",
              " 'answered',\n",
              " 'answering',\n",
              " 'any',\n",
              " 'anybody',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyway',\n",
              " 'anyways',\n",
              " 'anywhere',\n",
              " 'apart',\n",
              " 'apologetically',\n",
              " 'apparently',\n",
              " 'appear',\n",
              " 'appeared',\n",
              " 'appetite',\n",
              " 'apple',\n",
              " 'applicable',\n",
              " 'applied',\n",
              " 'apprentices',\n",
              " 'april',\n",
              " 'apron',\n",
              " 'are',\n",
              " \"aren't\",\n",
              " 'arguing',\n",
              " 'argument',\n",
              " 'arises',\n",
              " 'arming',\n",
              " 'armour',\n",
              " 'arms',\n",
              " 'around',\n",
              " 'arranged',\n",
              " 'arranging',\n",
              " 'arrive',\n",
              " 'arrived',\n",
              " 'as',\n",
              " 'ask',\n",
              " 'asked',\n",
              " 'asking',\n",
              " 'assistance',\n",
              " 'assure',\n",
              " 'at',\n",
              " 'ate',\n",
              " 'audacious',\n",
              " 'await',\n",
              " 'away',\n",
              " 'awfully',\n",
              " 'awkward',\n",
              " 'axes',\n",
              " 'azog',\n",
              " 'back',\n",
              " 'bad',\n",
              " 'badly',\n",
              " 'bag',\n",
              " 'baggage',\n",
              " 'baggages',\n",
              " 'baggins',\n",
              " 'bagginses',\n",
              " 'bags',\n",
              " 'baked',\n",
              " 'balancing',\n",
              " 'balin',\n",
              " 'banging',\n",
              " 'bank',\n",
              " 'bare',\n",
              " 'bargain',\n",
              " 'barn',\n",
              " 'barrel',\n",
              " 'barrels',\n",
              " 'bat',\n",
              " 'bathrooms',\n",
              " 'battle',\n",
              " 'bawl',\n",
              " 'be',\n",
              " 'bear',\n",
              " 'beard',\n",
              " 'bearded',\n",
              " 'beards',\n",
              " 'beats',\n",
              " 'beautiful',\n",
              " 'beautifully',\n",
              " 'bebother',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'bed',\n",
              " 'bedroom',\n",
              " 'bedrooms',\n",
              " 'beds',\n",
              " 'beech',\n",
              " 'been',\n",
              " 'beer',\n",
              " 'before',\n",
              " 'beg',\n",
              " 'began',\n",
              " 'begin',\n",
              " 'beginning',\n",
              " 'begun',\n",
              " 'behave',\n",
              " 'behaved',\n",
              " 'behind',\n",
              " 'behold',\n",
              " 'being',\n",
              " 'believe',\n",
              " 'believing',\n",
              " 'bell',\n",
              " 'belladonna',\n",
              " 'bells',\n",
              " 'belong',\n",
              " 'belonged',\n",
              " 'belongs',\n",
              " 'below',\n",
              " 'belt',\n",
              " 'belts',\n",
              " 'bend',\n",
              " 'beneath',\n",
              " 'bent',\n",
              " 'bert',\n",
              " \"bert's\",\n",
              " 'best',\n",
              " 'bet',\n",
              " 'better',\n",
              " 'between',\n",
              " 'bewildered',\n",
              " 'bewuthered',\n",
              " 'beyond',\n",
              " 'biased',\n",
              " 'bifur',\n",
              " 'big',\n",
              " 'bigger',\n",
              " 'bilbo',\n",
              " \"bilbo's\",\n",
              " 'bill',\n",
              " \"bill'\",\n",
              " 'biscuit',\n",
              " 'bit',\n",
              " 'bite',\n",
              " 'black',\n",
              " 'blacksmith',\n",
              " 'blame',\n",
              " 'bless',\n",
              " 'blew',\n",
              " 'blighter',\n",
              " 'blimey',\n",
              " 'blinking',\n",
              " 'blow',\n",
              " 'blowing',\n",
              " 'blue',\n",
              " 'blundering',\n",
              " 'blunt',\n",
              " 'blushed',\n",
              " 'bobbing',\n",
              " 'body',\n",
              " 'bofur',\n",
              " 'boiled',\n",
              " 'boiling',\n",
              " 'bolted',\n",
              " 'bombur',\n",
              " 'boned',\n",
              " 'bones',\n",
              " 'book',\n",
              " 'boots',\n",
              " 'borrow',\n",
              " 'borrowed',\n",
              " 'both',\n",
              " 'bother',\n",
              " 'bothered',\n",
              " 'bothering',\n",
              " 'bottle',\n",
              " 'bottles',\n",
              " 'bow',\n",
              " 'bowed',\n",
              " 'bowing',\n",
              " 'boy',\n",
              " 'boys',\n",
              " 'bp',\n",
              " 'br',\n",
              " 'braces',\n",
              " 'branch',\n",
              " 'brass',\n",
              " 'bravo',\n",
              " 'break',\n",
              " 'breakfast',\n",
              " 'breakfasts',\n",
              " 'breaking',\n",
              " 'breast',\n",
              " 'breath',\n",
              " 'bred',\n",
              " 'breeze',\n",
              " 'brief',\n",
              " 'bright',\n",
              " 'brim',\n",
              " 'bring',\n",
              " 'broad',\n",
              " 'broke',\n",
              " 'brothers',\n",
              " 'brought',\n",
              " 'brown',\n",
              " 'brushed',\n",
              " 'built',\n",
              " 'bullroarer',\n",
              " \"bullroarer's\",\n",
              " 'bungo',\n",
              " 'burglar',\n",
              " \"burglar's\",\n",
              " 'burglarious',\n",
              " 'burglars',\n",
              " 'burglary',\n",
              " 'burgling',\n",
              " 'burn',\n",
              " 'burrahobbit',\n",
              " 'burst',\n",
              " 'bur—',\n",
              " 'bushy',\n",
              " 'business',\n",
              " 'busy',\n",
              " 'but',\n",
              " 'buttered',\n",
              " 'buttons',\n",
              " 'but—',\n",
              " 'by',\n",
              " 'bye',\n",
              " 'bywater',\n",
              " 'cake',\n",
              " 'cakes',\n",
              " 'call',\n",
              " 'called',\n",
              " 'calling',\n",
              " 'came',\n",
              " 'camp',\n",
              " 'camped',\n",
              " 'can',\n",
              " \"can't\",\n",
              " 'canny',\n",
              " 'can’t',\n",
              " 'careful',\n",
              " 'carefully',\n",
              " 'carpeted',\n",
              " 'carried',\n",
              " 'carry',\n",
              " 'carved',\n",
              " 'carvings',\n",
              " 'cash',\n",
              " 'castles',\n",
              " 'catch',\n",
              " 'caught',\n",
              " 'caution',\n",
              " 'cavalcade',\n",
              " 'caverns',\n",
              " 'caves',\n",
              " 'ceiling',\n",
              " 'cellar',\n",
              " 'cellars',\n",
              " 'certain',\n",
              " 'certainly',\n",
              " 'chain',\n",
              " 'chair',\n",
              " 'chairs',\n",
              " 'chance',\n",
              " 'change',\n",
              " 'changed',\n",
              " 'chapter',\n",
              " 'charged',\n",
              " 'cheerily',\n",
              " 'cheese',\n",
              " 'chicken',\n",
              " 'chiefly',\n",
              " 'chimney',\n",
              " 'chip',\n",
              " 'choked',\n",
              " 'chose',\n",
              " 'chosen',\n",
              " 'chronicles',\n",
              " 'claim',\n",
              " 'clan',\n",
              " 'clapped',\n",
              " 'clarinets',\n",
              " 'class',\n",
              " 'clay',\n",
              " 'clean',\n",
              " 'cleaned',\n",
              " 'clear',\n",
              " 'clever',\n",
              " 'cliff',\n",
              " 'climbing',\n",
              " 'cloak',\n",
              " 'clock',\n",
              " 'closed',\n",
              " 'cloth',\n",
              " 'clothes',\n",
              " 'cloud',\n",
              " 'clouds',\n",
              " 'club',\n",
              " 'clump',\n",
              " 'co',\n",
              " 'coal',\n",
              " 'coalmining',\n",
              " 'coats',\n",
              " 'coffee',\n",
              " 'cold',\n",
              " 'collect',\n",
              " 'collected',\n",
              " 'colours',\n",
              " 'columns',\n",
              " 'come',\n",
              " 'comers',\n",
              " 'comes',\n",
              " 'comfort',\n",
              " 'comfortable',\n",
              " 'comfortably',\n",
              " 'comic',\n",
              " 'coming',\n",
              " 'common',\n",
              " 'company',\n",
              " 'compliments',\n",
              " 'concern',\n",
              " 'confused',\n",
              " 'confusticate',\n",
              " 'considered',\n",
              " 'considering',\n",
              " 'conspirator',\n",
              " 'conversation',\n",
              " 'cook',\n",
              " 'copped',\n",
              " 'corks',\n",
              " 'corner',\n",
              " 'corners',\n",
              " 'correct',\n",
              " 'corrected',\n",
              " 'corresponds',\n",
              " 'could',\n",
              " \"couldn't\",\n",
              " 'counsellor',\n",
              " 'country',\n",
              " 'couple',\n",
              " 'courage',\n",
              " 'course',\n",
              " 'covers',\n",
              " 'crack',\n",
              " 'cracking',\n",
              " 'crackling',\n",
              " 'cradles',\n",
              " 'crash',\n",
              " 'crawl',\n",
              " 'creaking',\n",
              " 'creep',\n",
              " 'crept',\n",
              " 'crocks',\n",
              " 'cross',\n",
              " 'crossed',\n",
              " 'crowns',\n",
              " 'cunning',\n",
              " 'cup',\n",
              " 'cups',\n",
              " 'curious',\n",
              " 'curly',\n",
              " 'current',\n",
              " 'curse',\n",
              " 'cursed',\n",
              " 'curses',\n",
              " 'cut',\n",
              " \"d'yer\",\n",
              " 'dagger',\n",
              " 'dale',\n",
              " 'dang',\n",
              " 'dangerous',\n",
              " 'dared',\n",
              " \"daren't\",\n",
              " 'daresay',\n",
              " 'dark',\n",
              " 'daughters',\n",
              " 'dawn',\n",
              " 'day',\n",
              " 'days',\n",
              " 'dead',\n",
              " 'deal',\n",
              " 'dear',\n",
              " 'decent',\n",
              " 'decided',\n",
              " 'deep',\n",
              " 'deeply',\n",
              " 'defrayed',\n",
              " 'delivery',\n",
              " 'delves',\n",
              " 'dent',\n",
              " 'departure',\n",
              " 'depredations',\n",
              " 'descendant',\n",
              " 'described',\n",
              " 'description',\n",
              " 'desert',\n",
              " 'desire',\n",
              " 'destroyed',\n",
              " 'destruction',\n",
              " 'detachable',\n",
              " 'determined',\n",
              " 'devices',\n",
              " 'devoted',\n",
              " 'devouring',\n",
              " 'diamond',\n",
              " 'diary',\n",
              " 'did',\n",
              " \"didn't\",\n",
              " 'died',\n",
              " 'difficult',\n",
              " 'digging',\n",
              " 'dignity',\n",
              " 'dim',\n",
              " 'ding',\n",
              " 'dining',\n",
              " 'dinner',\n",
              " 'direction',\n",
              " 'dirty',\n",
              " 'disappear',\n",
              " 'disappeared',\n",
              " 'disappointed',\n",
              " 'disappointedly',\n",
              " 'discovered',\n",
              " 'discreetly',\n",
              " 'discuss',\n",
              " 'disgusted',\n",
              " 'dish',\n",
              " 'dishes',\n",
              " 'dismally',\n",
              " 'distance',\n",
              " 'distant',\n",
              " 'disturb',\n",
              " 'disturbing',\n",
              " 'do',\n",
              " 'does',\n",
              " 'dogs',\n",
              " 'doing',\n",
              " \"don't\",\n",
              " 'done',\n",
              " 'dong',\n",
              " 'doom',\n",
              " 'door',\n",
              " 'doors',\n",
              " 'doorstep',\n",
              " 'dori',\n",
              " 'doubts',\n",
              " 'down',\n",
              " 'drafting',\n",
              " 'dragon',\n",
              " \"dragon's\",\n",
              " 'dragons',\n",
              " \"dragons'\",\n",
              " 'drawing',\n",
              " 'dreadful',\n",
              " 'dreams',\n",
              " 'dreary',\n",
              " 'dress',\n",
              " 'dressing',\n",
              " 'drier',\n",
              " 'drink',\n",
              " 'drinking',\n",
              " 'drip',\n",
              " 'dripping',\n",
              " 'driven',\n",
              " 'dropped',\n",
              " 'drowned',\n",
              " 'drum',\n",
              " 'dry',\n",
              " 'duck',\n",
              " 'due',\n",
              " 'dump',\n",
              " 'dungeons',\n",
              " 'dusted',\n",
              " 'duty',\n",
              " 'dwalin',\n",
              " \"dwalin's\",\n",
              " 'dwarf',\n",
              " 'dwarves',\n",
              " \"dwarves'\",\n",
              " 'dwarvish',\n",
              " 'dying',\n",
              " 'dynasties',\n",
              " 'each',\n",
              " 'early',\n",
              " 'earn',\n",
              " 'ears',\n",
              " 'earth',\n",
              " 'east',\n",
              " 'easy',\n",
              " 'eat',\n",
              " 'eaten',\n",
              " 'edge',\n",
              " 'edition',\n",
              " 'eggs',\n",
              " 'either',\n",
              " 'elbow',\n",
              " 'elephants',\n",
              " 'eleven',\n",
              " 'else',\n",
              " \"else's\",\n",
              " 'elves',\n",
              " 'elvish',\n",
              " 'empty',\n",
              " 'en',\n",
              " 'enchanted',\n",
              " 'end',\n",
              " 'ending',\n",
              " 'ends',\n",
              " 'enemy',\n",
              " 'engagement',\n",
              " 'engine',\n",
              " 'enjoy',\n",
              " 'enormous',\n",
              " 'enormously',\n",
              " 'enough',\n",
              " 'entirely',\n",
              " 'entrance',\n",
              " 'ere',\n",
              " 'erebor',\n",
              " 'error',\n",
              " 'escape',\n",
              " 'escaped',\n",
              " 'especially',\n",
              " 'esteemed',\n",
              " 'estimable',\n",
              " 'et',\n",
              " 'eve',\n",
              " 'even',\n",
              " 'evening',\n",
              " 'event',\n",
              " 'eventually',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everybody',\n",
              " 'everyday',\n",
              " 'everything',\n",
              " 'evil',\n",
              " 'exact',\n",
              " 'exactly',\n",
              " 'exaggeration',\n",
              " 'example',\n",
              " 'exceeding',\n",
              " 'excellent',\n",
              " 'except',\n",
              " 'exception',\n",
              " 'excitable',\n",
              " 'excited',\n",
              " 'excitement',\n",
              " 'excuse',\n",
              " 'existence',\n",
              " 'expect',\n",
              " 'expected',\n",
              " 'expedition',\n",
              " 'expenses',\n",
              " 'experience',\n",
              " 'expert',\n",
              " 'explain',\n",
              " 'explanation',\n",
              " 'explore',\n",
              " 'extra',\n",
              " 'extraordinary',\n",
              " 'eye',\n",
              " 'eyebrows',\n",
              " 'eyes',\n",
              " 'fabulous',\n",
              " 'face',\n",
              " 'faces',\n",
              " 'fact',\n",
              " 'fair',\n",
              " 'fairly',\n",
              " 'fairy',\n",
              " 'fall',\n",
              " 'falling',\n",
              " 'families',\n",
              " 'family',\n",
              " \"family's\",\n",
              " 'famous',\n",
              " 'far',\n",
              " 'farm',\n",
              " 'farmer',\n",
              " 'fashion',\n",
              " 'fast',\n",
              " 'fastened',\n",
              " 'fat',\n",
              " 'father',\n",
              " \"father's\",\n",
              " 'fathers',\n",
              " 'favourite',\n",
              " 'fearful',\n",
              " 'feel',\n",
              " 'feeling',\n",
              " 'feet',\n",
              " 'fell',\n",
              " 'fellow',\n",
              " 'fells',\n",
              " 'felt',\n",
              " 'fender',\n",
              " 'fetch',\n",
              " 'few',\n",
              " 'fiddles',\n",
              " 'fields',\n",
              " 'fierce',\n",
              " 'fifty',\n",
              " 'fight',\n",
              " 'fighting',\n",
              " 'fili',\n",
              " 'fill',\n",
              " 'filled',\n",
              " 'final',\n",
              " 'find',\n",
              " 'finding',\n",
              " 'fine',\n",
              " 'fingers',\n",
              " 'finished',\n",
              " 'finishing',\n",
              " 'fire',\n",
              " 'firelight',\n",
              " 'fires',\n",
              " 'fireside',\n",
              " 'firework',\n",
              " 'fireworks',\n",
              " \"firnbul's\",\n",
              " 'first',\n",
              " 'fist',\n",
              " 'fits',\n",
              " 'five',\n",
              " 'flame',\n",
              " 'flames',\n",
              " 'flaming',\n",
              " 'flat',\n",
              " 'fled',\n",
              " 'flew',\n",
              " 'flickered',\n",
              " 'floated',\n",
              " 'floor',\n",
              " 'floors',\n",
              " 'flowering',\n",
              " 'flowers',\n",
              " 'flummoxed',\n",
              " 'fluster',\n",
              " 'flustered',\n",
              " 'flutes',\n",
              " 'fly',\n",
              " 'flying',\n",
              " 'fog',\n",
              " 'folk',\n",
              " 'followed',\n",
              " 'fond',\n",
              " 'food',\n",
              " 'fool',\n",
              " 'foot',\n",
              " 'for',\n",
              " 'forced',\n",
              " 'forever',\n",
              " 'forget',\n",
              " 'forgot',\n",
              " 'forgotten',\n",
              " 'forks',\n",
              " 'forth',\n",
              " 'forward',\n",
              " 'found',\n",
              " 'four',\n",
              " 'fourteen',\n",
              " 'fourteenth',\n",
              " 'fragment',\n",
              " 'frail',\n",
              " 'fried',\n",
              " 'friend',\n",
              " 'friends',\n",
              " 'fright',\n",
              " 'from',\n",
              " 'front',\n",
              " 'frowned',\n",
              " 'frowning',\n",
              " 'fruity',\n",
              " 'fugitive',\n",
              " 'full',\n",
              " 'fun',\n",
              " 'funeral',\n",
              " 'funny',\n",
              " 'furry',\n",
              " 'further',\n",
              " 'gained',\n",
              " 'game',\n",
              " 'gandalf',\n",
              " \"gandalf's\",\n",
              " 'garden',\n",
              " 'gasp',\n",
              " 'gasping',\n",
              " 'gate',\n",
              " 'gathering',\n",
              " 'gave',\n",
              " 'gazing',\n",
              " 'gems',\n",
              " 'genealogies',\n",
              " 'general',\n",
              " 'gentler',\n",
              " 'get',\n",
              " 'gets',\n",
              " 'getting',\n",
              " 'giants',\n",
              " 'girls',\n",
              " 'give',\n",
              " 'given',\n",
              " 'gives',\n",
              " 'glance',\n",
              " 'glare',\n",
              " 'glasses',\n",
              " 'gloaming',\n",
              " 'gloin',\n",
              " 'gloomy',\n",
              " 'glum',\n",
              " 'go',\n",
              " 'goblets',\n",
              " 'goblin',\n",
              " 'goblins',\n",
              " 'goes',\n",
              " 'going',\n",
              " 'gol',\n",
              " 'gold',\n",
              " 'golden',\n",
              " 'golf',\n",
              " 'gone',\n",
              " 'good',\n",
              " 'gorgeous',\n",
              " 'got',\n",
              " 'gown',\n",
              " 'grabbed',\n",
              " 'gracious',\n",
              " 'gradually',\n",
              " 'gram',\n",
              " 'grand',\n",
              " 'grandfather',\n",
              " \"grandfather's\",\n",
              " 'granduncle',\n",
              " 'grass',\n",
              " 'grateful',\n",
              " 'gravy',\n",
              " 'great',\n",
              " 'greater',\n",
              " 'greedy',\n",
              " 'green',\n",
              " 'greeting',\n",
              " 'grew',\n",
              " 'grey',\n",
              " 'grim',\n",
              " 'grimly',\n",
              " 'groaned',\n",
              " 'grocer',\n",
              " 'ground',\n",
              " 'grow',\n",
              " 'grown',\n",
              " 'grumbled',\n",
              " 'grumbling',\n",
              " 'grumpy',\n",
              " 'grunted',\n",
              " 'guaranteed',\n",
              " 'guard',\n",
              " 'guess',\n",
              " 'guessed',\n",
              " 'gun',\n",
              " 'ha',\n",
              " 'had',\n",
              " 'hair',\n",
              " 'half',\n",
              " 'hall',\n",
              " 'halls',\n",
              " 'halves',\n",
              " 'ham',\n",
              " 'hammers',\n",
              " 'hand',\n",
              " 'handed',\n",
              " 'handing',\n",
              " 'handkerchief',\n",
              " 'handkerchiefs',\n",
              " 'handle',\n",
              " 'hands',\n",
              " 'handsomely',\n",
              " 'hang',\n",
              " 'hanging',\n",
              " 'happen',\n",
              " 'happened',\n",
              " 'happy',\n",
              " 'hard',\n",
              " 'hardly',\n",
              " 'harp',\n",
              " 'harps',\n",
              " 'has',\n",
              " 'hat',\n",
              " 'hates',\n",
              " 'hats',\n",
              " 'haughty',\n",
              " 'have',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'head',\n",
              " 'heads',\n",
              " 'heap',\n",
              " 'hear',\n",
              " 'heard',\n",
              " 'hearing',\n",
              " 'hearth',\n",
              " 'hearts',\n",
              " 'heath',\n",
              " 'heavy',\n",
              " 'height',\n",
              " 'heir',\n",
              " 'help',\n",
              " 'helps',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hero',\n",
              " 'heroes',\n",
              " 'hesitated',\n",
              " 'hidden',\n",
              " 'hide',\n",
              " 'hiding',\n",
              " 'high',\n",
              " 'higher',\n",
              " 'hill',\n",
              " 'hills',\n",
              " 'hilt',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'history',\n",
              " 'hoard',\n",
              " 'hob',\n",
              " 'hobbit',\n",
              " \"hobbit's\",\n",
              " 'hobbits',\n",
              " 'hold',\n",
              " 'holding',\n",
              " 'hole',\n",
              " 'holes',\n",
              " 'hollow',\n",
              " 'home',\n",
              " 'homes',\n",
              " 'honest',\n",
              " 'honour',\n",
              " 'hood',\n",
              " 'hooded',\n",
              " 'hoods',\n",
              " 'hoot',\n",
              " 'hope',\n",
              " 'hoped',\n",
              " 'hopeful',\n",
              " 'hopped',\n",
              " 'horrible',\n",
              " 'horse',\n",
              " 'hospitality',\n",
              " 'host',\n",
              " 'hot',\n",
              " 'hours',\n",
              " 'house',\n",
              " 'houses',\n",
              " 'hover',\n",
              " 'how',\n",
              " 'however',\n",
              " 'huddled',\n",
              " 'huge',\n",
              " 'huger',\n",
              " 'huggins',\n",
              " 'humming',\n",
              " 'humph',\n",
              " 'hundred',\n",
              " 'hung',\n",
              " 'hunter',\n",
              " 'hurricane',\n",
              " 'hurried',\n",
              " 'hurry',\n",
              " 'hush',\n",
              " 'hushed',\n",
              " 'i',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'idea',\n",
              " 'ideas',\n",
              " 'if',\n",
              " 'ii',\n",
              " 'immediately',\n",
              " 'immense',\n",
              " 'immensely',\n",
              " 'immovably',\n",
              " 'important',\n",
              " 'in',\n",
              " 'inaccuracies',\n",
              " 'inclined',\n",
              " 'indeed',\n",
              " 'ingenious',\n",
              " 'inhabited',\n",
              " 'ink',\n",
              " 'inn',\n",
              " 'inns',\n",
              " 'inquisitive',\n",
              " 'inside',\n",
              " 'instance',\n",
              " 'instead',\n",
              " 'instruments',\n",
              " 'inter',\n",
              " 'interested',\n",
              " 'interrupted',\n",
              " 'into',\n",
              " 'intricate',\n",
              " 'introduce',\n",
              " 'invented',\n",
              " 'invited',\n",
              " 'ire',\n",
              " 'is',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'jacket',\n",
              " 'jam',\n",
              " 'jealous',\n",
              " 'jelly',\n",
              " 'jerk',\n",
              " 'jewels',\n",
              " 'job',\n",
              " 'jogged',\n",
              " 'jogging',\n",
              " 'join',\n",
              " 'joined',\n",
              " 'journey',\n",
              " \"journey's\",\n",
              " 'jug',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCswnI9h7fx5"
      },
      "source": [
        "# creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = {i:u for i, u in enumerate(vocab)}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtvMAAPCCQqe",
        "outputId": "4362b50c-92dd-4212-b761-2b266692269a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDkSclbCgF_R",
        "outputId": "ebe127de-ee69-45a2-c810-54f09f5014e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'####-special note: '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJeuh19ZMj2x",
        "outputId": "bd35c7e8-ab4e-4cf3-bfe0-7121e2f6147d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_sequences=[]\n",
        "\n",
        "for line in corpus:\n",
        "  token_list=tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "print(len(input_sequences))\n",
        "len(token_list)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiTEYLUJFz_",
        "outputId": "80568957-6fa5-43fa-acb6-cbc978d573fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#passing some words and predicting next word .\n",
        "train_len = 20 # taking 25 words to predict 26th word..\n",
        "text_seq = []\n",
        "for i in range(train_len,len(vocab)):\n",
        "\tseq=vocab[i-train_len:i]\n",
        "\ttext_seq.append(seq)\n",
        "print(' '.join(text_seq[0])) # joining words to form sentences.."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "' 'anything 'ell 'em 'ere 'five 'get 'oo 'thank 10 2 45 6te a about above abreast' absolutely absurd acceptance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqqfJNF0QLXF",
        "outputId": "f45d9d2d-ca1b-4ab8-ce44-970242ca5c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#p\n",
        "ad sequences\n",
        " 4 =max([len(seq) for seq in input_sequences])\n",
        "\n",
        "\n",
        "print(max_sequence_len, total_words)\n",
        "\n",
        "input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, padding=\"pre\", maxlen=max_sequence_len))\n",
        "\n",
        "#create predictions and lebels\n",
        "xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21 2194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zys8OJFkopGX",
        "outputId": "1ccaf20b-9683-4b77-993c-76b5734c8ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "input_sequences"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0, 1012,  311],\n",
              "       [   0,    0,    0, ...,    0,    7,   30],\n",
              "       [   0,    0,    0, ...,    7,   30, 1013],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    6,  605,   16],\n",
              "       [   0,    0,    0, ...,  605,   16,    3],\n",
              "       [   0,    0,    0, ...,   16,    3,  120]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5SURlfSpjhA",
        "outputId": "2438683d-df6b-4706-b08e-5f25009c77db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "seq_length=xs.shape[1]\n",
        "\n",
        "print(seq_length)\n",
        "\n",
        "ys.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11418, 2194)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuhxXlRaQmlA",
        "outputId": "b270bd5d-a004-4467-a424-1a1e114c8419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=total_words,output_dim=100,input_length=seq_length))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(96)))\n",
        "model.add(Dense(1097,activation=\"relu\"))\n",
        "model.add(Dense(2194,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 100)           219400    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 20, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 192)               304896    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1097)              211721    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2194)              2409012   \n",
            "=================================================================\n",
            "Total params: 3,446,229\n",
            "Trainable params: 3,446,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78pPVP7WPZ0E"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgxuz57NgC0p"
      },
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{accuracy:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsHuMwicQQGS",
        "outputId": "891dcabc-a2d5-4f3b-f8ed-35ddcbb48618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit(xs,ys,batch_size=32,epochs=100,verbose=1,callbacks=callbacks_list)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 6.3368 - accuracy: 0.0532WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 6.3380 - accuracy: 0.0532\n",
            "Epoch 2/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 5.9269 - accuracy: 0.0623WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 5.9276 - accuracy: 0.0624\n",
            "Epoch 3/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 5.7304 - accuracy: 0.0692WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 5.7302 - accuracy: 0.0690\n",
            "Epoch 4/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 5.5327 - accuracy: 0.0838WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 5.5328 - accuracy: 0.0836\n",
            "Epoch 5/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 5.3216 - accuracy: 0.1005WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 5.3222 - accuracy: 0.1005\n",
            "Epoch 6/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 5.1522 - accuracy: 0.1125WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 5.1522 - accuracy: 0.1125\n",
            "Epoch 7/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 4.9920 - accuracy: 0.1207WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 4.9916 - accuracy: 0.1202\n",
            "Epoch 8/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 4.8408 - accuracy: 0.1291WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 4.8377 - accuracy: 0.1296\n",
            "Epoch 9/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 4.6928 - accuracy: 0.1364WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 4.6914 - accuracy: 0.1365\n",
            "Epoch 10/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 4.5379 - accuracy: 0.1422WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 4.5379 - accuracy: 0.1422\n",
            "Epoch 11/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 4.3894 - accuracy: 0.1546WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 4.3885 - accuracy: 0.1545\n",
            "Epoch 12/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 4.2343 - accuracy: 0.1613WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 4.2332 - accuracy: 0.1616\n",
            "Epoch 13/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 4.0762 - accuracy: 0.1717WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 4.0749 - accuracy: 0.1721\n",
            "Epoch 14/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 3.9038 - accuracy: 0.1836WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 3.9038 - accuracy: 0.1836\n",
            "Epoch 15/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 3.7383 - accuracy: 0.1975WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 3.7402 - accuracy: 0.1971\n",
            "Epoch 16/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 3.5663 - accuracy: 0.2094WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 3.5685 - accuracy: 0.2094\n",
            "Epoch 17/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 3.3906 - accuracy: 0.2316WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 3.3876 - accuracy: 0.2324\n",
            "Epoch 18/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 3.2040 - accuracy: 0.2567WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 3.2062 - accuracy: 0.2561\n",
            "Epoch 19/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 3.0264 - accuracy: 0.2873WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 3.0283 - accuracy: 0.2867\n",
            "Epoch 20/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 2.8487 - accuracy: 0.3208WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 2.8476 - accuracy: 0.3212\n",
            "Epoch 21/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 2.6680 - accuracy: 0.3534WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 2.6700 - accuracy: 0.3534\n",
            "Epoch 22/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 2.4928 - accuracy: 0.3893WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 2.4928 - accuracy: 0.3893\n",
            "Epoch 23/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 2.3279 - accuracy: 0.4227WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 2.3279 - accuracy: 0.4227\n",
            "Epoch 24/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 2.1772 - accuracy: 0.4578WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 2.1775 - accuracy: 0.4579\n",
            "Epoch 25/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 2.0198 - accuracy: 0.4918WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 2.0198 - accuracy: 0.4918\n",
            "Epoch 26/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 1.8925 - accuracy: 0.5185WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.8929 - accuracy: 0.5183\n",
            "Epoch 27/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 1.7515 - accuracy: 0.5575WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.7515 - accuracy: 0.5575\n",
            "Epoch 28/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 1.6274 - accuracy: 0.5848WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.6274 - accuracy: 0.5848\n",
            "Epoch 29/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 1.5222 - accuracy: 0.6115WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.5237 - accuracy: 0.6111\n",
            "Epoch 30/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 1.4402 - accuracy: 0.6290WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.4407 - accuracy: 0.6289\n",
            "Epoch 31/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 1.3192 - accuracy: 0.6620WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.3197 - accuracy: 0.6618\n",
            "Epoch 32/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 1.2383 - accuracy: 0.6746WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.2400 - accuracy: 0.6743\n",
            "Epoch 33/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 1.1418 - accuracy: 0.7044WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.1420 - accuracy: 0.7042\n",
            "Epoch 34/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 1.0753 - accuracy: 0.7180WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.0753 - accuracy: 0.7180\n",
            "Epoch 35/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 1.0175 - accuracy: 0.7323WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 1.0182 - accuracy: 0.7322\n",
            "Epoch 36/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.9542 - accuracy: 0.7429WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.9536 - accuracy: 0.7430\n",
            "Epoch 37/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.8725 - accuracy: 0.7690WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.8731 - accuracy: 0.7689\n",
            "Epoch 38/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.8173 - accuracy: 0.7849WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.8173 - accuracy: 0.7849\n",
            "Epoch 39/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.7633 - accuracy: 0.7967WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.7629 - accuracy: 0.7967\n",
            "Epoch 40/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.7308 - accuracy: 0.8031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.7319 - accuracy: 0.8027\n",
            "Epoch 41/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.6951 - accuracy: 0.8084WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.6954 - accuracy: 0.8082\n",
            "Epoch 42/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.6641 - accuracy: 0.8172WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.6642 - accuracy: 0.8171\n",
            "Epoch 43/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.6280 - accuracy: 0.8276WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.6271 - accuracy: 0.8281\n",
            "Epoch 44/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.8373WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.5836 - accuracy: 0.8373\n",
            "Epoch 45/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.8444WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.5575 - accuracy: 0.8444\n",
            "Epoch 46/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.5276 - accuracy: 0.8550WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.5265 - accuracy: 0.8551\n",
            "Epoch 47/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.5048 - accuracy: 0.8567WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.5057 - accuracy: 0.8565\n",
            "Epoch 48/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.4685 - accuracy: 0.8721WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.4685 - accuracy: 0.8721\n",
            "Epoch 49/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.4675 - accuracy: 0.8705WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.4672 - accuracy: 0.8706\n",
            "Epoch 50/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.4718 - accuracy: 0.8671WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.4717 - accuracy: 0.8671\n",
            "Epoch 51/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.8789WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.4290 - accuracy: 0.8789\n",
            "Epoch 52/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.8805WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.4180 - accuracy: 0.8805\n",
            "Epoch 53/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.8924WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3784 - accuracy: 0.8924\n",
            "Epoch 54/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.8920WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3763 - accuracy: 0.8920\n",
            "Epoch 55/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.3737 - accuracy: 0.8934WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3744 - accuracy: 0.8931\n",
            "Epoch 56/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.3692 - accuracy: 0.8910WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3706 - accuracy: 0.8908\n",
            "Epoch 57/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.3558 - accuracy: 0.8984WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.3559 - accuracy: 0.8985\n",
            "Epoch 58/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.8990WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3465 - accuracy: 0.8990\n",
            "Epoch 59/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.9066WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3240 - accuracy: 0.9066\n",
            "Epoch 60/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.9112WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3015 - accuracy: 0.9112\n",
            "Epoch 61/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.9090WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3105 - accuracy: 0.9084\n",
            "Epoch 62/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.3155 - accuracy: 0.9049WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3157 - accuracy: 0.9050\n",
            "Epoch 63/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.3129 - accuracy: 0.9047WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.3131 - accuracy: 0.9047\n",
            "Epoch 64/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.9134WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2976 - accuracy: 0.9134\n",
            "Epoch 65/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2775 - accuracy: 0.9176WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2775 - accuracy: 0.9176\n",
            "Epoch 66/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2724 - accuracy: 0.9181WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2735 - accuracy: 0.9177\n",
            "Epoch 67/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2754 - accuracy: 0.9165WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2763 - accuracy: 0.9164\n",
            "Epoch 68/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2792 - accuracy: 0.9154WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2792 - accuracy: 0.9154\n",
            "Epoch 69/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2632 - accuracy: 0.9210WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2631 - accuracy: 0.9210\n",
            "Epoch 70/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.9243WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2549 - accuracy: 0.9242\n",
            "Epoch 71/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.9211WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2606 - accuracy: 0.9211\n",
            "Epoch 72/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2589 - accuracy: 0.9214WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2590 - accuracy: 0.9214\n",
            "Epoch 73/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2599 - accuracy: 0.9214WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2600 - accuracy: 0.9214\n",
            "Epoch 74/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.9176WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2628 - accuracy: 0.9176\n",
            "Epoch 75/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.9204WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2577 - accuracy: 0.9204\n",
            "Epoch 76/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.9251WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2461 - accuracy: 0.9252\n",
            "Epoch 77/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2394 - accuracy: 0.9264WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2391 - accuracy: 0.9263\n",
            "Epoch 78/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.9298WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2205 - accuracy: 0.9298\n",
            "Epoch 79/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2089 - accuracy: 0.9349WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2087 - accuracy: 0.9350\n",
            "Epoch 80/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9243WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2349 - accuracy: 0.9243\n",
            "Epoch 81/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2321 - accuracy: 0.9285WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2321 - accuracy: 0.9286\n",
            "Epoch 82/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2425 - accuracy: 0.9239WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2435 - accuracy: 0.9235\n",
            "Epoch 83/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9258WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2380 - accuracy: 0.9258\n",
            "Epoch 84/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9300WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2193 - accuracy: 0.9300\n",
            "Epoch 85/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2155 - accuracy: 0.9297WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2153 - accuracy: 0.9298\n",
            "Epoch 86/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9303WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2141 - accuracy: 0.9302\n",
            "Epoch 87/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9328WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2106 - accuracy: 0.9329\n",
            "Epoch 88/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2188 - accuracy: 0.9287WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2198 - accuracy: 0.9284\n",
            "Epoch 89/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.9280WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2285 - accuracy: 0.9279\n",
            "Epoch 90/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2230 - accuracy: 0.9294WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2233 - accuracy: 0.9292\n",
            "Epoch 91/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9319WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2117 - accuracy: 0.9316\n",
            "Epoch 92/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9296WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2161 - accuracy: 0.9296\n",
            "Epoch 93/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2241 - accuracy: 0.9287WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2256 - accuracy: 0.9283\n",
            "Epoch 94/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.9291WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2130 - accuracy: 0.9291\n",
            "Epoch 95/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2117 - accuracy: 0.9293WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2125 - accuracy: 0.9291\n",
            "Epoch 96/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9283WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2211 - accuracy: 0.9286\n",
            "Epoch 97/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2156 - accuracy: 0.9285WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2164 - accuracy: 0.9284\n",
            "Epoch 98/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1889 - accuracy: 0.9371WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1894 - accuracy: 0.9371\n",
            "Epoch 99/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2005 - accuracy: 0.9342WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2008 - accuracy: 0.9341\n",
            "Epoch 100/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1915 - accuracy: 0.9339WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1913 - accuracy: 0.9341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvI3705MByWo",
        "outputId": "441018fd-f361-4947-f4a6-ee624d802102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "import random\n",
        "def gen_text(model,tokenizer,seq_length,seed_text,num_gen_words):\n",
        "    output_text = []\n",
        "    input_text = seed_text # initial seeding text s\n",
        "    for i in range(num_gen_words):\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0] # it retuns a tuple of item\t\n",
        "        pad_encoded = tf.keras.preprocessing.sequence.pad_sequences([encoded_text],maxlen=seq_length,padding='pre') # as if user add a long or short text then it corrects it.\n",
        "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]   #pred prob for each words.\n",
        "        \n",
        "        pred_word=tokenizer.index_word[pred_word_ind]\n",
        "        \t\t\n",
        "        input_text += ' '+pred_word\n",
        "        output_text.append(pred_word)\n",
        "    \t\n",
        "    return ' '.join(output_text)\n",
        "\n",
        "random.seed(101)\n",
        "random_pick=random.randint(0,len(text_seq))\n",
        "random_seed_text=text_seq[random_pick]# choosing randomly words\n",
        "seed_text=' '.join(random_seed_text)\n",
        "print(seed_text)\n",
        "\n",
        "gen_text(model,tokenizer,seq_length,seed_text=seed_text,num_gen_words=1000)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gown grabbed gracious gradually gram grand grandfather grandfather's granduncle grass grateful gravy great greater greedy green greeting grew grey grim\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"on the fat house as that gave it the door they came to the pantry to his elbow and they went back to their dark green front door then he strode away just about the time when bilbo saw that morning was an old town of the less trouble you the woods now there was no people left no inns and the roads grew steadily worse not 'get hold of it ' i was given it said the wizard not without a mighty warrior oakenshield himself doing by which you have heard only a quarter of coffee to the dwarves ate and ate and talked and talked and time got into the beer barrels in the chronicles places of the pine trees and the fire died down and the shadows were arming the fire of our noticing him a bit of good quick burgling a silver scarf over which a white beard was not gandalf at all it was a dwarf with a blue beard tucked into a golden belt days that he managed to have got into the fire dwarves can make a fire almost anywhere out of the way of their feet before they arrived and he preferred to ask them himself of the mines of moria by that in his waist and immense black boots and watched he loved map said apprentices and in the fog the flying rags then they stopped and thorin to the parlour and set out the grey clouds and a waning moon and destruction that dragons make his staff and under his woolly toes as they were toasting and gandalf means me to think that i should have lived to be good till they all came to take tea pray come and have some with me a little hand in william's enormous pocket gate and come by night to dale and carry away people suddenly got up into the air and came south the first we have long ago paid the goblins of mount gram in the battle of the green fields and to the green fields and to his elbow and they went back to their first acquaintance with hobbit lore need not troupe about an evil reference to burglars but he had baked that afternoon for his mouth and bilbo he had just about little fiddles dori nori fall out the dining room by that time the sun was shining and the front door bell and made beds and the dwarves and more he should have had a little many jewels as soon as a hobbit not a half between yer since we come down from the mountains how that gave a shudder and all the most enormous smoke rings and wherever he told one he said immediately afterwards the fog the fire died down and the rings and wherever it is a forks of worms and by the valley and wherever he got one of the best rooms were all on the left hand side going with very merrily and they told stories or so and living in the river that they had once had for me they had gone on far into the lone lands they had gone on like like this until he was out of breath without the wrong house as soon they could said kili to do this that we can hear a good job plenty of moria and in the runes there were lots bilbo found himself answering to his own surprise and he found and the matter of thror the river bank bent and do his names and i should know but i am no good i will show you i have no signs on my door it was not the correct thing to say but he never got near the mountain how he got them all stowed and went to his own little bed very tired and not come out again until all the dwarves had gone away suddenly he said to himself thinking of dragons and that the woods they all went away on the dragon and off his water the mountain how they could catch him and to the beautiful hobbit hole built by his father which i have just described for you a perfectly beautiful breakfast for you if only you won't have to camp when they could but at all it was a dwarf with a blue beard tucked into a golden belt days that he managed to have got into the fire dwarves can make a fire almost anywhere out of the way of their feet before they arrived and he preferred to ask them himself of the mines of moria by that in his waist and immense black boots and watched he loved map said apprentices and in the fog the flying rags then they stopped and thorin to the parlour and set out the grey clouds and a waning moon and destruction that dragons make his staff and under his woolly toes as they were toasting and gandalf means me to think that i should have lived to be good till they all came to take tea pray come and have some with me a little hand in william's enormous pocket gate and come by night to dale and carry away people suddenly got up into the air and came south the first we have long ago paid the goblins of mount gram in the battle of the green fields and to the green fields and to his elbow and they went back to their first acquaintance with hobbit lore need not troupe about an evil reference to burglars but he had baked that afternoon for his mouth and bilbo he had just about little fiddles dori nori fall out the dining room by that time the sun was shining and the front door bell and made beds and the dwarves and more he should have had a little many jewels as soon as a hobbit not a half between yer since we come down\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEG3tiQPuPSU"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-4N4qbpuS16"
      },
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{accuracy:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY8QlvIYuyVt",
        "outputId": "9f4ce137-c612-4ed9-a014-94beeb6d2279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit(xs,ys,batch_size=32,epochs=100,verbose=1,callbacks=callbacks_list)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9336WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2111 - accuracy: 0.9336\n",
            "Epoch 2/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.9373WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1868 - accuracy: 0.9372\n",
            "Epoch 3/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9380WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1803 - accuracy: 0.9380\n",
            "Epoch 4/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1903 - accuracy: 0.9363WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1906 - accuracy: 0.9361\n",
            "Epoch 5/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2206 - accuracy: 0.9299WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2210 - accuracy: 0.9298\n",
            "Epoch 6/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2113 - accuracy: 0.9275WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2111 - accuracy: 0.9276\n",
            "Epoch 7/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9314WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2074 - accuracy: 0.9316\n",
            "Epoch 8/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9318WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2078 - accuracy: 0.9318\n",
            "Epoch 9/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9335WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1914 - accuracy: 0.9335\n",
            "Epoch 10/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9360WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1840 - accuracy: 0.9358\n",
            "Epoch 11/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9362WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1821 - accuracy: 0.9362\n",
            "Epoch 12/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9314WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1968 - accuracy: 0.9314\n",
            "Epoch 13/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1988 - accuracy: 0.9335WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1985 - accuracy: 0.9337\n",
            "Epoch 14/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy: 0.9394WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1762 - accuracy: 0.9395\n",
            "Epoch 15/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9379WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1818 - accuracy: 0.9378\n",
            "Epoch 16/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9316WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2025 - accuracy: 0.9314\n",
            "Epoch 17/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2015 - accuracy: 0.9293WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2021 - accuracy: 0.9291\n",
            "Epoch 18/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1983 - accuracy: 0.9309WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1979 - accuracy: 0.9311\n",
            "Epoch 19/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.9378WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1869 - accuracy: 0.9376\n",
            "Epoch 20/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1797 - accuracy: 0.9369WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1802 - accuracy: 0.9367\n",
            "Epoch 21/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9367WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1822 - accuracy: 0.9363\n",
            "Epoch 22/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1853 - accuracy: 0.9361WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1851 - accuracy: 0.9362\n",
            "Epoch 23/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9365WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1835 - accuracy: 0.9366\n",
            "Epoch 24/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.2019 - accuracy: 0.9312WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2013 - accuracy: 0.9314\n",
            "Epoch 25/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9368WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1783 - accuracy: 0.9368\n",
            "Epoch 26/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9400WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1729 - accuracy: 0.9400\n",
            "Epoch 27/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9390WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1697 - accuracy: 0.9383\n",
            "Epoch 28/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.9363WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1809 - accuracy: 0.9363\n",
            "Epoch 29/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9339WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1957 - accuracy: 0.9339\n",
            "Epoch 30/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.9295WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.2044 - accuracy: 0.9296\n",
            "Epoch 31/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1730 - accuracy: 0.9390WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1738 - accuracy: 0.9388\n",
            "Epoch 32/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.9381WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1704 - accuracy: 0.9380\n",
            "Epoch 33/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9330WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1885 - accuracy: 0.9333\n",
            "Epoch 34/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9321WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1888 - accuracy: 0.9321\n",
            "Epoch 35/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9384WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1687 - accuracy: 0.9388\n",
            "Epoch 36/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9394WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1661 - accuracy: 0.9395\n",
            "Epoch 37/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9342WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1884 - accuracy: 0.9342\n",
            "Epoch 38/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9364WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1803 - accuracy: 0.9363\n",
            "Epoch 39/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9379WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1718 - accuracy: 0.9380\n",
            "Epoch 40/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.9367WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1769 - accuracy: 0.9369\n",
            "Epoch 41/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 0.9375WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1720 - accuracy: 0.9376\n",
            "Epoch 42/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9391WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1696 - accuracy: 0.9390\n",
            "Epoch 43/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.9365WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1689 - accuracy: 0.9366\n",
            "Epoch 44/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.9391WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1649 - accuracy: 0.9391\n",
            "Epoch 45/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9339WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1906 - accuracy: 0.9340\n",
            "Epoch 46/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9371WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1755 - accuracy: 0.9370\n",
            "Epoch 47/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1844 - accuracy: 0.9364WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1867 - accuracy: 0.9357\n",
            "Epoch 48/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9357WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1760 - accuracy: 0.9356\n",
            "Epoch 49/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9412WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1636 - accuracy: 0.9412\n",
            "Epoch 50/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9393WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1760 - accuracy: 0.9392\n",
            "Epoch 51/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1650 - accuracy: 0.9383WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1650 - accuracy: 0.9383\n",
            "Epoch 52/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9403WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1716 - accuracy: 0.9400\n",
            "Epoch 53/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9369WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1728 - accuracy: 0.9369\n",
            "Epoch 54/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1672 - accuracy: 0.9406\n",
            "Epoch 55/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9348WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1848 - accuracy: 0.9348\n",
            "Epoch 56/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1857 - accuracy: 0.9327WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1877 - accuracy: 0.9325\n",
            "Epoch 57/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9361WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1812 - accuracy: 0.9362\n",
            "Epoch 58/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9409WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1604 - accuracy: 0.9409\n",
            "Epoch 59/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9384WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1735 - accuracy: 0.9384\n",
            "Epoch 60/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9431WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1519 - accuracy: 0.9431\n",
            "Epoch 61/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9414WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1576 - accuracy: 0.9414\n",
            "Epoch 62/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9387WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1632 - accuracy: 0.9387\n",
            "Epoch 63/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9382WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1704 - accuracy: 0.9383\n",
            "Epoch 64/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9389WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1668 - accuracy: 0.9390\n",
            "Epoch 65/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9436WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1572 - accuracy: 0.9434\n",
            "Epoch 66/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9392WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1676 - accuracy: 0.9392\n",
            "Epoch 67/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1650 - accuracy: 0.9407WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1651 - accuracy: 0.9407\n",
            "Epoch 68/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9346WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1804 - accuracy: 0.9347\n",
            "Epoch 69/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9364WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1730 - accuracy: 0.9365\n",
            "Epoch 70/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9374WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1701 - accuracy: 0.9375\n",
            "Epoch 71/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9383WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1639 - accuracy: 0.9383\n",
            "Epoch 72/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9380WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1749 - accuracy: 0.9380\n",
            "Epoch 73/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9434WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1507 - accuracy: 0.9433\n",
            "Epoch 74/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9432WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1479 - accuracy: 0.9432\n",
            "Epoch 75/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9434WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1488 - accuracy: 0.9434\n",
            "Epoch 76/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1628 - accuracy: 0.9407WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1629 - accuracy: 0.9406\n",
            "Epoch 77/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1686 - accuracy: 0.9381WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1678 - accuracy: 0.9384\n",
            "Epoch 78/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 0.9376WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1707 - accuracy: 0.9376\n",
            "Epoch 79/100\n",
            "356/357 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9396WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1670 - accuracy: 0.9396\n",
            "Epoch 80/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9414WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1590 - accuracy: 0.9413\n",
            "Epoch 81/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9371WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1659 - accuracy: 0.9372\n",
            "Epoch 82/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9415WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1571 - accuracy: 0.9416\n",
            "Epoch 83/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9426WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 15ms/step - loss: 0.1489 - accuracy: 0.9425\n",
            "Epoch 84/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9404WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1540 - accuracy: 0.9404\n",
            "Epoch 85/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9414WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1506 - accuracy: 0.9412\n",
            "Epoch 86/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.9379WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1758 - accuracy: 0.9379\n",
            "Epoch 87/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9351WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1812 - accuracy: 0.9348\n",
            "Epoch 88/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9410WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1611 - accuracy: 0.9410\n",
            "Epoch 89/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.9390WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1696 - accuracy: 0.9390\n",
            "Epoch 90/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9430WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1528 - accuracy: 0.9426\n",
            "Epoch 91/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9464WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1443 - accuracy: 0.9462\n",
            "Epoch 92/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9425WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1509 - accuracy: 0.9425\n",
            "Epoch 93/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9417WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1576 - accuracy: 0.9418\n",
            "Epoch 94/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9401WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1577 - accuracy: 0.9402\n",
            "Epoch 95/100\n",
            "357/357 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.9404WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1606 - accuracy: 0.9404\n",
            "Epoch 96/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9422WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1554 - accuracy: 0.9423\n",
            "Epoch 97/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1611 - accuracy: 0.9393WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1612 - accuracy: 0.9393\n",
            "Epoch 98/100\n",
            "355/357 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9419WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1593 - accuracy: 0.9417\n",
            "Epoch 99/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1646 - accuracy: 0.9403WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1635 - accuracy: 0.9408\n",
            "Epoch 100/100\n",
            "354/357 [============================>.] - ETA: 0s - loss: 0.1565 - accuracy: 0.9424WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "357/357 [==============================] - 5s 14ms/step - loss: 0.1563 - accuracy: 0.9425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWnbUceqoe6e",
        "outputId": "debc5ef9-e8cf-4552-f18c-630ff0ea7ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERhTVy_gMQbO",
        "outputId": "8b82d7e2-2ad6-4e63-f9e2-4de890ff704f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "import random\n",
        "def gen_text(model,tokenizer,seq_length,seed_text,num_gen_words):\n",
        "    output_text = []\n",
        "    input_text = seed_text # initial seeding text s\n",
        "    for i in range(num_gen_words):\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0] # it retuns a tuple of item\t\n",
        "        pad_encoded = tf.keras.preprocessing.sequence.pad_sequences([encoded_text],maxlen=seq_length,padding='pre') # as if user add a long or short text then it corrects it.\n",
        "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]   #pred prob for each words.\n",
        "        \n",
        "        pred_word=tokenizer.index_word[pred_word_ind]\n",
        "        \t\t\n",
        "        input_text += ' '+pred_word\n",
        "        output_text.append(pred_word)\n",
        "    \t\n",
        "    return ' '.join(output_text)\n",
        "\n",
        "random.seed(101)\n",
        "random_pick=random.randint(0,len(text_seq))\n",
        "random_seed_text=text_seq[random_pick]# choosing randomly words\n",
        "seed_text=' '.join(random_seed_text)\n",
        "print(seed_text)\n",
        "\n",
        "gen_text(model,tokenizer,seq_length,seed_text=seed_text,num_gen_words=1000)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gown grabbed gracious gradually gram grand grandfather grandfather's granduncle grass grateful gravy great greater greedy green greeting grew grey grim\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the sun must have gone down for it and a while he had eaten swept at an adventure some or even he said and the gorgeous row bilbo had just enough wits left when bert they came and a dragon marked in red on the mountain said balin but it will be a big lamp with a red shad he spread a piece of it said bert and after we shan't get through the business till late the usual had sat down in the kitchen nearly down and the shadows were arming the dwarves rushed at the fire more head with the goblins and the moon and talked and talked and time got up trembling and the in rug shaking like a jelly bawl south on the fat and mountains in front of them when loud came a ring at the deep places of their little loose scale of their armour there were lots of dragons in the north in those quick gandalf made a bad wet evening to begin on they even the gandalf's hobbit bred off a silver scarf over which a white mat i do myself you remember the poorest of us had money to spend and to lend a long journey a journey from which country the key we have long ago paid the goblins of mount gram in the battle of the green fields and talked about and the green fields and the green fields and a moon and kill the battle of the dwarves who all the dwarves who used to tell such wonderful tales at his eyes was full of water the pony was tired and stumbled on stones the others had ordered their breakfasts without so much as a please don't say you can say expert treasure hunter instead of burglar a fierce and jealous love the desire of his magic staff and in its firework glare when he got back balin and dwalin were talking at the table like old friends out for their noticing him short after his walking hobbit some and worst in all fellow conspirator though no noise came out he was slung up into the fire for fire it was without as he saw that it was mostly little left for supper and he said a burglar whether off you go on bed and breakfast to the fire one fine morning for a nasty dirty wet hole filled with a tube his appetite was quite not a north he went in the took side had won he a portent of dale and the warriors were arming the dwarves rushed at the hill or across the water and there they were brothers bilbo plumped down the old maps the and desert i the fire of us that is not without hope indeed for them and wept in hiding and cursed balin and careful as you ever meant it and a bad though they usually have a good notion of the way of their feet before they could say knife they stopped for one another's muttering while oin and gloin they looking said one with a while he had eaten most talked most and laughed most and and thorin indeed for the stool before he could duck behind the dwarves a dry and a thinkin' of to bring us into these parts at all hope anyway him and without bothering to be outside i was one luckily a fine adventurous lad in those days then he went back and crept in through the bargain if you have a pipe about you sit down and the most awkward we still but i know only just escaped i tried to save your father but i know i suppose they made a deal of gold and then and even mend a bad though they usually have a good notion of the deep places of an adventure panelled well for you the dwarves ate and ate and talked and talked and time got into the bargain if you have a pipe about you sit down and the road when bilbo came down on the pantry floor and destruction that dragons make a trees he came out another cup and in the north with this book and you will see the runes there were lots of dragons in the wind some of the north with a crash there came a dry bare sandy hole with nothing and bolted he got into the river running went on thorin taking a nasty mood quite likely to hold and sailing in an evil look as if they can hear a bit startled trolls are slow in the uptake and do what you want done and i will try it if i have to walk from the mountain creaking and cracking in the north and came out another cup and destruction that and make hours or two or he said kili at your service said the wizard not without a mighty warrior days that is the side door and dragons must sleep sometimes i suppose if you sit on the hall bifur and bofur went out more of burglar if you want there time for what they had gone on far into the north and the music and use the old maps the door and off they went to the kitchen nearly down and the shadows were arming the dwarves rushed at the fire of the long lake now a days so in the village ate and talked and time and one and fierce many slung about a hat with a m mood quite likely to hold else's wretched breakfast the old took died in fact and the hobbits had but he thought of going east as quiet and careful as we could as far as the long time for bilbo aloud been most or did anything unexpected the key we have long ago paid the goblins of mount gram in the battle of the green fields and talked about and the green fields and the green fields\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}